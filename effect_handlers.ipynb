{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Poutine: Pyro 中使用 Effect Handlers 编程手册\n",
    "\n",
    "<big> Poutine: A Guide to Programming with Effect Handlers in Pyro </big> 其预备知识:\n",
    "\n",
    "- Effect Handlers(EH)，是效应句柄，或者效应处理程序。\n",
    "- [理解Python 中的 with 语句](https://blog.csdn.net/u012513525/article/details/70135898), 另外一篇文章关于 [python with](https://yikun.github.io/2016/04/15/%E7%90%86%E8%A7%A3Python%E4%B8%AD%E7%9A%84%E2%80%9Cwith%E2%80%9D/)\n",
    "- algebraic effects and handlers in programming language research\n",
    "\n",
    "\n",
    "\n",
    "（该教程是 Pyro 的 EH 库 [Poutine](http://docs.pyro.ai/en/dev/poutine.html) 的指导手册，推荐读者先阅读 [minipyro.py](https://github.com/pyro-ppl/pyro/blob/dev/pyro/contrib/minipyro.py) 会有所帮助，因为 Poutine 可视作它的推广。）This tutorial is a guide to the API details of Pyro’s effect handling library, Poutine. We recommend readers first orient themselves with the simplified minipyro.py which contains a minimal, readable implementation of Pyro’s runtime and the effect handler abstraction described here. Pyro’s effect handler library is more general than minipyro’s but also contains more layers of indirection; it helps to read them side-by-side.\n",
    "\n",
    "`Messenger` 是 mini-pyro 库的核心数据结构，`trace, replay, block, seed, PlateMessenger` 都是 `Messenger` 的子类。`Messenger`s are **stateful context manager objects** that are **placed on a global stack** and send messages (hence the name) up and down the stack at each effectful operation, like a `pyro.sample` call.\n",
    "\n",
    "- trace: trace records the inputs and outputs of any primitive site it encloses, and returns a dictionary containing that data to the user.\n",
    "- replay: an effect handler for setting the value at a sample site.\n",
    "- block: allows the selective application of effect handlers to different parts of a model. Sites hidden by block will only have the handlers below block on the PYRO_STACK applied, allowing inference or other effectful computations to be nested inside models.\n",
    "- seed: is used to fix the RNG state when calling a model.\n",
    "- PlateMessenger: This limited implementation of PlateMessenger only implements broadcasting.\n",
    "\n",
    "思考：`Messenger` 这个数据结构如何帮助 Pyro 实现其核心功能？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "from pyro.poutine.runtime import effectful\n",
    "pyro.set_rng_seed(101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "<big> 问题背景介绍 </big>\n",
    "\n",
    "概率编程中的推断会涉及到操作或者变换写成生成模型的概率程序。 例如，几乎所有近似推断算法都需要在某个生成模型下，计算非标准化的潜变量和观测变量的联合概率分布. 考虑以下示例模型 from the [introductory inference tutorial](http://pyro.ai/examples/intro_part_ii.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "mu = 8.5\n",
    "def scale(mu):\n",
    "    weight = pyro.sample(\"weight\", dist.Normal(mu, 1.0))\n",
    "    return pyro.sample(\"measurement\", dist.Normal(weight, 0.75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "该模型定义了 `\"weight\"` 和 `\"measurement\"` 的一个联合分布:\n",
    "\n",
    "$${\\sf weight} \\,  \\sim \\cal {\\sf Normal}({\\mu}, 1) $$\n",
    "$${\\sf measurement} \\, |  {\\sf weight} \\sim {\\sf Normal}({\\sf weight}, 0.75)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "如果我们知道每个 `pyro.sample` site 的输入和输出, 那么我们可以计算他们的 log-joint:\n",
    "\n",
    "```python\n",
    "logp = dist.Normal(mu, 1.0).log_prob(weight).sum() + dist.Normal(weight, 0.75).log_prob(measurement).sum()\n",
    "```\n",
    "\n",
    "但是，我们上面定义的  `scale` 并未展示这些中间分布对象, and rewriting it to return them would be intrusive 而且会违反分离模型和推理算法的初衷 that a probabilistic programming language like Pyro is designed to enforce.\n",
    "\n",
    "为了解决此冲突和方便推断算法的开发， Pyro 推出了 [Poutine](http://docs.pyro.ai/en/dev/poutine.html),  a library of *effect handlers* , or composable building blocks for examining and modifying the behavior of Pyro programs.  Pyro的大多数内部组件都是在Poutine之上实现的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "++++++ 下节预告:\n",
    "\n",
    "```python\n",
    "def make_log_joint(model):\n",
    "    def _log_joint(cond_data, *args, **kwargs):\n",
    "        conditioned_model = poutine.condition(model, data=cond_data)\n",
    "        trace = poutine.trace(conditioned_model).get_trace(*args, **kwargs)\n",
    "        return trace.log_prob_sum()\n",
    "    return _log_joint\n",
    "\n",
    "def make_log_joint_2(model):\n",
    "    def _log_joint(cond_data, *args, **kwargs):\n",
    "        with TraceMessenger() as tracer:\n",
    "            with ConditionMessenger(data=cond_data):\n",
    "                model(*args, **kwargs)\n",
    "        \n",
    "        trace = tracer.trace\n",
    "        logp = 0.\n",
    "        for name, node in trace.nodes.items():\n",
    "            if node[\"type\"] == \"sample\":\n",
    "                if node[\"is_observed\"]:\n",
    "                    assert node[\"value\"] is cond_data[name]\n",
    "                logp = logp + node[\"fn\"].log_prob(node[\"value\"]).sum()\n",
    "        return logp\n",
    "    return _log_joint\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Pyro 的算法构建基石库 Poutine\n",
    "\n",
    "\n",
    "<big> A first look at Poutine: Pyro's library of algorithmic building blocks </big>\n",
    "\n",
    "（什么是 EH？）Effect handlers, a common abstraction in the programming languages community, give nonstandard interpretations or side effects to the behavior of particular statements in a programming language, 例如 `pyro.sample` 或 `pyro.param`. 有关编程语言研究中的效应处理程序的背景知识，请参阅本教程最后一个小节。\n",
    "\n",
    "\n",
    "相对于查看更多定义，让我们看第一个例子来解释一下： 我们组合两个 EH, `poutine.condition` (它设定 `pyro.sample` 语句的输出值) 和 `poutine.trace` (它记录 `pyro.sample` 语句的输入，分布函数和输出), 来简单的定义一个新的 EH 用来计算对数似然。也就是说我们可以用两个现有的 EH 组成一个新的 EH 用于计算 log-joint："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.0203)\n"
     ]
    }
   ],
   "source": [
    "def make_log_joint(model):\n",
    "    def _log_joint(cond_data, *args, **kwargs):\n",
    "        conditioned_model = poutine.condition(model, data=cond_data)\n",
    "        trace = poutine.trace(conditioned_model).get_trace(*args, **kwargs)\n",
    "        return trace.log_prob_sum()\n",
    "    return _log_joint\n",
    "\n",
    "scale_log_joint = make_log_joint(scale)\n",
    "print(scale_log_joint({\"measurement\": 9.5, \"weight\": 8.23}, 8.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "该代码段很短，但仍然有些难懂 - `poutine.condition`, `poutine.trace`, 而且 `trace.log_prob_sum` 依然是黑盒.  Let's remove a layer of boilerplate from `poutine.condition` and `poutine.trace` and explicitly implement what `trace.log_prob_sum` is doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t': tensor(51)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {\"temp\": torch.tensor(51)}\n",
    "{\"t\":v for k, v in a.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: weight , value of node: 8.23\n",
      "name: measurement , value of node: 9.5\n",
      "tensor(-3.0203)\n"
     ]
    }
   ],
   "source": [
    "from pyro.poutine.trace_messenger import TraceMessenger\n",
    "from pyro.poutine.condition_messenger import ConditionMessenger\n",
    "\n",
    "def make_log_joint_2(model):\n",
    "    def _log_joint(cond_data, *args, **kwargs):\n",
    "#         conditioned_model = poutine.condition(model, data=cond_data)\n",
    "#         trace = poutine.trace(conditioned_model).get_trace(*args, **kwargs)\n",
    "#         return trace.log_prob_sum()\n",
    "        with TraceMessenger() as tracer:\n",
    "            with ConditionMessenger(data=cond_data):\n",
    "                model(*args, **kwargs)\n",
    "        \n",
    "        trace = tracer.trace\n",
    "        logp = 0.\n",
    "        for name, node in trace.nodes.items():\n",
    "            print('name:', name, ', value of node:', node['value'])\n",
    "            if node[\"type\"] == \"sample\":\n",
    "                if node[\"is_observed\"]:\n",
    "                    assert node[\"value\"] is cond_data[name]\n",
    "                logp = logp + node[\"fn\"].log_prob(node[\"value\"]).sum()\n",
    "        return logp\n",
    "    return _log_joint\n",
    "\n",
    "scale_log_joint = make_log_joint_2(scale)\n",
    "print(scale_log_joint({\"measurement\": 9.5, \"weight\": 8.23}, 8.5)) # mu=8.5 是模型的输入参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "这让我们对计算 log-joint 的机制更清楚一点点了: \n",
    "\n",
    "- 我们可以看到 `poutine.trace` and `poutine.condition` are wrappers for context managers that presumably communicate with the model through something inside `pyro.sample`. \n",
    "- 我们也可以看到 `poutine.trace`  produces a data structure (a [Trace](http://docs.pyro.ai/en/dev/poutine.html#trace)) containing a dictionary whose keys are `sample` site names and values are dictionaries containing the distribution (`\"fn\"`) and output (`\"value\"`) at each site, and that the output values at each site are exactly the values specified in `data`.\n",
    "- 最后, `TraceMessenger` 和 `ConditionMessenger` 是 Pyro 效应处理程序, or `Messenger`s: stateful context manager objects that are placed on a global stack and send messages (hence the name) up and down the stack at each effectful operation, like a `pyro.sample` call.  A `Messenger` is placed at the bottom of the stack when its `__enter__` method is called, i.e. when it is used in a \"with\" statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "我们将在本教程的后面部分详细介绍该过程。 参考 mini-pyro 中关于基类 `Messenger` 的内容, see [pyro.contrib.minipyro](https://github.com/pyro-ppl/pyro/blob/dev/pyro/contrib/minipyro.py).\n",
    "\n",
    "```python\n",
    "class Messenger:\n",
    "    def __init__(self, fn=None):\n",
    "        self.fn = fn\n",
    "\n",
    "    # Effect handlers push themselves onto the PYRO_STACK.\n",
    "    # Handlers earlier in the PYRO_STACK are applied first.\n",
    "    def __enter__(self):\n",
    "        PYRO_STACK.append(self)\n",
    "\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        assert PYRO_STACK[-1] is self\n",
    "        PYRO_STACK.pop()\n",
    "\n",
    "    def process_message(self, msg):\n",
    "        pass\n",
    "\n",
    "    def postprocess_message(self, msg):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        with self:\n",
    "            return self.fn(*args, **kwargs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 用 `Messenger` 构建新 EH\n",
    "\n",
    "尽管通过在`pyro.poutine`中组合现有的效应处理程序来构建新的效应处理程序是最容易的, 但是构建新效应处理程序作为 `pyro.poutine.messenger.Messenger` 子类实现非常更直接。在深入研究API之前，让我们看另一个例子：log-joint 计算的一个版本，在模型执行时执行求和。然后我们将回顾示例的每个部分的实际操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.0203)\n",
      "tensor(-3.0203)\n"
     ]
    }
   ],
   "source": [
    "class LogJointMessenger(poutine.messenger.Messenger):\n",
    "    \n",
    "    def __init__(self, cond_data):\n",
    "        self.data = cond_data\n",
    "    \n",
    "    # __call__ 是用于将 Messenger 用作高阶函数的语法糖。\n",
    "    # Messenger already defines __call__, 但是我们在这里重新定义\n",
    "    # for exposition and to change the return value:\n",
    "    def __call__(self, fn):\n",
    "        def _fn(*args, **kwargs):\n",
    "            with self:\n",
    "                fn(*args, **kwargs)\n",
    "                return self.logp.clone()\n",
    "        return _fn\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.logp = torch.tensor(0.)\n",
    "        # All Messenger subclasses must call the base Messenger.__enter__()\n",
    "        # in their __enter__ methods\n",
    "        return super().__enter__()\n",
    "    \n",
    "    # __exit__ takes the same arguments in all Python context managers\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.logp = torch.tensor(0.)\n",
    "        # All Messenger subclasses must call the base Messenger.__exit__ method\n",
    "        # in their __exit__ methods.\n",
    "        return super().__exit__(exc_type, exc_value, traceback)\n",
    "    \n",
    "    # _pyro_sample 对于每个 pyro.sample site 调用一次.\n",
    "    # It takes a dictionary msg containing the name, distribution,\n",
    "    # observation or sample value, and other metadata from the sample site.\n",
    "    def _pyro_sample(self, msg):\n",
    "        # Any unobserved random variables will trigger this assertion.\n",
    "        # In the next section, we'll learn how to also handle sampled values.\n",
    "        assert msg[\"name\"] in self.data\n",
    "        msg[\"value\"] = self.data[msg[\"name\"]]\n",
    "        # Since we've observed a value for this site, we set the \"is_observed\" flag to True\n",
    "        # This tells any other Messengers not to overwrite msg[\"value\"] with a sample.\n",
    "        msg[\"is_observed\"] = True\n",
    "        self.logp = self.logp + (msg[\"scale\"] * msg[\"fn\"].log_prob(msg[\"value\"])).sum()\n",
    "\n",
    "with LogJointMessenger(cond_data={\"measurement\": 9.5, \"weight\": 8.23}) as m:\n",
    "    scale(8.5)\n",
    "    print(m.logp.clone())\n",
    "    \n",
    "scale_log_joint = LogJointMessenger(cond_data={\"measurement\": 9.5, \"weight\": 8.23})(scale)\n",
    "print(scale_log_joint(8.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "（可以把 `LogJointMessenger` 当成上下文管理器，装饰器或者高阶函数使用）A convenient bit of boilerplate that allows the use of `LogJointMessenger` as a context manager, decorator, or higher-order function is the following.  Most of the existing effect handlers in `pyro.poutine`, including `poutine.trace` and `poutine.condition` which we used earlier, are `Messenger`s wrapped this way in `pyro.poutine.handlers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.0203)\n"
     ]
    }
   ],
   "source": [
    "def log_joint(model=None, cond_data=None):\n",
    "    msngr = LogJointMessenger(cond_data=cond_data)\n",
    "    return msngr(model) if model is not None else msngr\n",
    "\n",
    "scale_log_joint = log_joint(scale, cond_data={\"measurement\": 9.5, \"weight\": 8.23})\n",
    "print(scale_log_joint(8.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## `Messenger` 类的方法详解\n",
    "\n",
    "我 `LogJointMessenger` 的实现有三个主要方法: `__enter__`, `__exit__`, and `_pyro_sample`. \n",
    "\n",
    "`__enter__` 和 `__exit__` 是上下文管理器的特殊方法。When implementing new `Messenger` classes, if we override `__enter__` and `__exit__`, we always need to call the base `Messenger`'s `__enter__` and `__exit__` methods for the new `Messenger` to be applied correctly.\n",
    "\n",
    "\n",
    "\n",
    "（method `LogJointMessenger._pyro_sample` 用于读取和修改一条由字典组成的信息 `msg`。）The last method `LogJointMessenger._pyro_sample`, is called once at each sample site. It reads and modifies a *message*, which is a dictionary containing the sample site's name, distribution, sampled or observed value, and other metadata. We'll examine the contents of a message in more detail in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "（类 `Messenger` 具备两个信息操作的方法，包括 `_process_message`  和 `_postprocess_message`.）Instead of `_pyro_sample`, a generic `Messenger` actually contains two methods that are called once per operation where side effects are performed:\n",
    "\n",
    "1. `_process_message` modifies a message and sends the result to the `Messenger` just above on the stack\n",
    "2. `_postprocess_message` modifies a message and sends the result to the next `Messenger` down on the stack. It is always called after all active `Messenger`s have had their `_process_message` method applied to the message.\n",
    "\n",
    "Although custom `Messenger`s can override `_process_message` and `_postprocess_message`, it's convenient to avoid requiring all effect handlers to be aware of all possible effectful operation types. For this reason, by default `Messenger._process_message` will use `msg[\"type\"]` to dispatch to a corresponding method `Messenger._pyro_<type>`, e.g. `Messenger._pyro_sample` as in `LogJointMessenger`.  Just as exception handling code ignores unhandled exception types, this allows `Messenger`s to simply forward operations they don't know how to handle up to the next `Messenger` in the stack:\n",
    "\n",
    "```python\n",
    "class Messenger:\n",
    "    ...\n",
    "    def _process_message(self, msg):\n",
    "        method_name = \"_pyro_{}\".format(msg[\"type\"])  # e.g. _pyro_sample when msg[\"type\"] == \"sample\"\n",
    "        if hasattr(self, method_name):\n",
    "            getattr(self, method_name)(msg)\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 全局 `Messenger` 栈\n",
    "\n",
    "有关本部分中该机制的端到端实现，请参见 [pyro.contrib.minipyro](https://github.com/pyro-ppl/pyro/blob/dev/pyro/contrib/minipyro.py)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The order in which `Messenger`s are applied to an operation like a `pyro.sample` statement is determined by the order in which their `__enter__` methods are called.  `Messenger.__enter__` appends a `Messenger` to the end (the bottom) of the global handler stack:\n",
    "\n",
    "```python\n",
    "# 进入时候 append a 'Messenger' to the end of the stack, 而退出时候 pop self.\n",
    "class Messenger:\n",
    "    ...\n",
    "    # __enter__ pushes a Messenger onto the stack\n",
    "    def __enter__(self):\n",
    "        ...\n",
    "        _PYRO_STACK.append(self)\n",
    "        ...\n",
    "    \n",
    "    # __exit__ removes a Messenger from the stack\n",
    "    def __exit__(self, ...):\n",
    "        ...\n",
    "        assert _PYRO_STACK[-1] is self\n",
    "        _PYRO_STACK.pop()\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "`pyro.poutine.runtime.apply_stack` then traverses the stack twice at each operation, first from bottom to top to apply each `_process_message` and then from top to bottom to apply each `_postprocess_message`:\n",
    "```python\n",
    "# 从 bottom 到 top `_process_message`，然后从 top 到 bottom `_postprocess_message`\n",
    "def apply_stack(msg):  # simplified\n",
    "    for handler in reversed(_PYRO_STACK):\n",
    "        handler._process_message(msg)\n",
    "    ...\n",
    "    default_process_message(msg)\n",
    "    ...\n",
    "    for handler in _PYRO_STACK:\n",
    "        handler._postprocess_message(msg) \n",
    "    ...\n",
    "    return msg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 重写例子 `LogJointMessenger` \n",
    "\n",
    "The second method `_postprocess_message` is necessary because some effects can only be applied after all other effect handlers have had a chance to update the message once. In the case of `LogJointMessenger`, other effects, like enumeration, may modify a sample site's value or distribution (`msg[\"value\"]` or `msg[\"fn\"]`), so we move the log-probability computation to a new method, `_pyro_post_sample`, which is called by `_postprocess_message` (via a dispatch mechanism like the one used by `_process_message`) at each `sample` site after all active handlers' `_pyro_sample` methods have been applied:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false",
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.0203)\n"
     ]
    }
   ],
   "source": [
    "class LogJointMessenger2(poutine.messenger.Messenger):\n",
    "    \n",
    "    def __init__(self, cond_data):\n",
    "        self.data = cond_data\n",
    "    \n",
    "    def __call__(self, fn):\n",
    "        def _fn(*args, **kwargs):\n",
    "            with self:\n",
    "                fn(*args, **kwargs)\n",
    "                return self.logp.clone()\n",
    "        return _fn\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.logp = torch.tensor(0.)\n",
    "        return super().__enter__()\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.logp = torch.tensor(0.)\n",
    "        return super().__exit__(exc_type, exc_value, traceback)\n",
    "\n",
    "    def _pyro_sample(self, msg):\n",
    "        if msg[\"name\"] in self.data:\n",
    "            msg[\"value\"] = self.data[msg[\"name\"]]\n",
    "            msg[\"done\"] = True\n",
    "            \n",
    "    def _pyro_post_sample(self, msg):\n",
    "        assert msg[\"done\"]  # the \"done\" flag asserts that no more modifications to value and fn will be performed.\n",
    "        self.logp = self.logp + (msg[\"scale\"] * msg[\"fn\"].log_prob(msg[\"value\"])).sum()\n",
    "\n",
    "\n",
    "with LogJointMessenger2(cond_data={\"measurement\": 9.5, \"weight\": 8.23}) as m:\n",
    "    scale(8.5)\n",
    "    print(m.logp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "###  `Messenger` 发送的信息 msg\n",
    "\n",
    "如前两个示例所述，在堆栈上 sent up and down 的实际信息是带有特定键集的字典。考虑以下抽样语句：\n",
    "\n",
    "```python\n",
    "pyro.sample(\"x\", dist.Bernoulli(0.5), infer={\"enumerate\": \"parallel\"}, obs=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "This sample statement is converted into an initial message before any effects are applied, and each effect handler's `_process_message` and `_postprocess_message` may update fields in place or add new fields.  We write out the full initial message here for completeness:\n",
    "\n",
    "```python\n",
    "msg = {\n",
    "    # The following fields 包含样本点的名字, 输入, 分布函数, 和输出.\n",
    "    # These are generally the only fields you'll need to think about.\n",
    "    \"name\": \"x\",\n",
    "    \"fn\": dist.Bernoulli(0.5),\n",
    "    \"value\": None,  # msg[\"value\"] 会包含 pyro.sample 的返回值.\n",
    "    \"is_observed\": False,  # because obs=None by default; only used by sample sites\n",
    "    \"args\": (),  # positional arguments passed to \"fn\" when it is called; usually empty for sample sites\n",
    "    \"kwargs\": {},  # keyword arguments passed to \"fn\" when it is called; usually empty for sample sites\n",
    "    # 该字段通常包含特定推理算法所需或存储的元数据\n",
    "    \"infer\": {\"enumerate\": \"parallel\"},\n",
    "    # 其余字段通常仅由Pyro内部使用，或用于实现超出本教程范围的更高级效果\n",
    "    # The remaining fields are generally only used by Pyro's internals,\n",
    "    # or for implementing more advanced effects beyond the scope of this tutorial\n",
    "    \"type\": \"sample\",  # label used by Messenger._process_message to dispatch, in this case to _pyro_sample\n",
    "    \"done\": False,\n",
    "    \"stop\": False,\n",
    "    \"scale\": torch.tensor(1.),  # Multiplicative scale factor that can be applied to each site's log_prob\n",
    "    \"mask\": None,\n",
    "    \"continuation\": None,\n",
    "    \"cond_indep_stack\": (),  # Will contain metadata from each pyro.plate enclosing this sample site.\n",
    "}\n",
    "```\n",
    "Note that when we use `poutine.trace` or `TraceMessenger` as in our first two versions of `make_log_joint`, the contents of `msg` are exactly the information stored in the trace for each sample and param site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回顾和总结例子的处理\n",
    "\n",
    "我们回顾和总结一下例子的处理\n",
    "\n",
    "- 我们首先提出问题“如何计算对数似然”\n",
    "- 其次打开黑箱，使用 trace 来获得内部抽样节点，手动计算对数似然\n",
    "- 再而使用 `Messenger` 直接写一个 EH 来计算 log-joint\n",
    "- 最后改进了该子类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.4981)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = 8.5\n",
    "def scale(mu):\n",
    "    weight = pyro.sample(\"weight\", dist.Normal(mu, 1.0))\n",
    "    return pyro.sample(\"measurement\", dist.Normal(weight, 0.75))\n",
    "scale(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.0203)\n"
     ]
    }
   ],
   "source": [
    "from pyro.poutine.trace_messenger import TraceMessenger\n",
    "from pyro.poutine.condition_messenger import ConditionMessenger\n",
    "\n",
    "def make_log_joint(model):\n",
    "    def _log_joint(cond_data, *args, **kwargs):\n",
    "        conditioned_model = poutine.condition(model, data=cond_data)\n",
    "        trace = poutine.trace(conditioned_model).get_trace(*args, **kwargs)\n",
    "        return trace.log_prob_sum()\n",
    "    return _log_joint\n",
    "\n",
    "def make_log_joint_2(model):\n",
    "    def _log_joint(cond_data, *args, **kwargs):\n",
    "        with TraceMessenger() as tracer:\n",
    "            with ConditionMessenger(data=cond_data):\n",
    "                model(*args, **kwargs)\n",
    "\n",
    "        trace = tracer.trace\n",
    "        logp = 0.\n",
    "        for name, node in trace.nodes.items():\n",
    "            if node[\"type\"] == \"sample\":\n",
    "                if node[\"is_observed\"]:\n",
    "                    assert node[\"value\"] is cond_data[name]\n",
    "                logp = logp + node[\"fn\"].log_prob(node[\"value\"]).sum()\n",
    "        return logp\n",
    "    return _log_joint\n",
    "scale_log_joint = make_log_joint_2(scale)\n",
    "print(scale_log_joint({\"measurement\": 9.5, \"weight\": 8.23}, 8.5)) # mu=8.5 是模型的输入参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.0203)\n",
      "tensor(-3.0203)\n"
     ]
    }
   ],
   "source": [
    "class LogJointMessenger(poutine.messenger.Messenger):\n",
    "    \n",
    "    def __init__(self, cond_data):\n",
    "        self.data = cond_data\n",
    "    \n",
    "    # __call__ 是用于将 Messenger 用作高阶函数的语法糖。\n",
    "    # Messenger already defines __call__, 但是我们在这里重新定义 for exposition and to change the return value:\n",
    "    def __call__(self, fn):\n",
    "        def _fn(*args, **kwargs):\n",
    "            with self:\n",
    "                fn(*args, **kwargs)\n",
    "                return self.logp.clone()\n",
    "        return _fn\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.logp = torch.tensor(0.)\n",
    "        return super().__enter__()\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.logp = torch.tensor(0.)\n",
    "        return super().__exit__(exc_type, exc_value, traceback)\n",
    "    \n",
    "    # _pyro_sample 对于每个 pyro.sample site 调用一次.\n",
    "    def _pyro_sample(self, msg):\n",
    "        assert msg[\"name\"] in self.data\n",
    "        msg[\"value\"] = self.data[msg[\"name\"]]\n",
    "        # 由于我们已经观察到该样本点的值，因此将 “is_observed” 标志设置为 True\n",
    "        # This tells any other Messengers not to overwrite msg[\"value\"] with a sample.\n",
    "        msg[\"is_observed\"] = True\n",
    "        self.logp = self.logp + (msg[\"scale\"] * msg[\"fn\"].log_prob(msg[\"value\"])).sum()\n",
    "\n",
    "with LogJointMessenger(cond_data={\"measurement\": 9.5, \"weight\": 8.23}) as m:\n",
    "    scale(8.5)\n",
    "    print(m.logp.clone())\n",
    "    \n",
    "scale_log_joint = LogJointMessenger(cond_data={\"measurement\": 9.5, \"weight\": 8.23})(scale)\n",
    "print(scale_log_joint(8.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.0203)\n"
     ]
    }
   ],
   "source": [
    "class LogJointMessenger2(poutine.messenger.Messenger):\n",
    "    \n",
    "    def __init__(self, cond_data):\n",
    "        self.data = cond_data\n",
    "    \n",
    "    def __call__(self, fn):\n",
    "        def _fn(*args, **kwargs):\n",
    "            with self:\n",
    "                fn(*args, **kwargs)\n",
    "                return self.logp.clone()\n",
    "        return _fn\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.logp = torch.tensor(0.)\n",
    "        return super().__enter__()\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.logp = torch.tensor(0.)\n",
    "        return super().__exit__(exc_type, exc_value, traceback)\n",
    "\n",
    "    def _pyro_sample(self, msg):\n",
    "        if msg[\"name\"] in self.data:\n",
    "            msg[\"value\"] = self.data[msg[\"name\"]]\n",
    "            msg[\"done\"] = True\n",
    "            \n",
    "    def _pyro_post_sample(self, msg):\n",
    "        assert msg[\"done\"]  # the \"done\" flag asserts that no more modifications to value and fn will be performed.\n",
    "        self.logp = self.logp + (msg[\"scale\"] * msg[\"fn\"].log_prob(msg[\"value\"])).sum()\n",
    "\n",
    "\n",
    "with LogJointMessenger2(cond_data={\"measurement\": 9.5, \"weight\": 8.23}) as m:\n",
    "    scale(8.5)\n",
    "    print(m.logp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Mini-pyro 简介\n",
    "\n",
    "mini-pyro 的核心是 \n",
    "\n",
    "\n",
    "```python\n",
    "class Messenger:\n",
    "    def __init__(self, fn=None):\n",
    "        self.fn = fn # 表示节点的分布\n",
    "\n",
    "    def __enter__(self):\n",
    "        PYRO_STACK.append(self) #Effect handlers push themselves onto the PYRO_STACK.\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        assert PYRO_STACK[-1] is self\n",
    "        PYRO_STACK.pop()\n",
    "\n",
    "    def process_message(self, msg):\n",
    "        pass\n",
    "    def postprocess_message(self, msg):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        with self:\n",
    "            return self.fn(*args, **kwargs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 基类 Messenger\n",
    "\n",
    "`trace, replay, block, seed, PlateMessenger` 都是 `Messenger` 的子类。\n",
    "\n",
    "- trace: trace records the inputs and outputs of any primitive site it encloses, and returns a dictionary containing that data to the user.\n",
    "- replay: an effect handler for setting the value at a sample site.\n",
    "- block: allows the selective application of effect handlers to different parts of a model. Sites hidden by block will only have the handlers below block on the PYRO_STACK applied, allowing inference or other effectful computations to be nested inside models.\n",
    "- seed: is used to fix the RNG state when calling a model.\n",
    "- PlateMessenger: This limited implementation of PlateMessenger only implements broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "import weakref\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "from pyro.distributions import validation_enabled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "（Pyro跟踪两种全局状态，包括样本点 PYRO_STACK 和可训练参数 PARAM_STORE）Pyro keeps track of two kinds of global state:\n",
    "    \n",
    "- i)  The effect handler stack, which enables non-standard interpretations of\n",
    "    Pyro primitives like sample();\n",
    "    See http://docs.pyro.ai/en/0.3.1/poutine.html\n",
    "- ii) Trainable parameters in the Pyro ParamStore;\n",
    "    See http://docs.pyro.ai/en/0.3.1/parameters.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Messenger 类就是用来处理 PYRO_STACK \n",
    "PYRO_STACK = []\n",
    "PARAM_STORE = {}  # maps name -> (unconstrained_value, constraint)\n",
    "\n",
    "def get_param_store():\n",
    "    return PARAM_STORE\n",
    "\n",
    "# The base effect handler class (called Messenger here for consistency with Pyro).\n",
    "class Messenger:\n",
    "    def __init__(self, fn=None):\n",
    "        self.fn = fn\n",
    "\n",
    "    # Effect handlers push themselves onto the PYRO_STACK.\n",
    "    # Handlers earlier in the PYRO_STACK are applied first.\n",
    "    def __enter__(self):\n",
    "        PYRO_STACK.append(self)\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        assert PYRO_STACK[-1] is self\n",
    "        PYRO_STACK.pop()\n",
    "\n",
    "    def process_message(self, msg):\n",
    "        pass\n",
    "    def postprocess_message(self, msg):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        with self:\n",
    "            return self.fn(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "这里给出第一个有用的 effect handler 例子. `trace` records the inputs and outputs of any primitive site it encloses, and returns a dictionary containing that data to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class trace(Messenger):\n",
    "    def __enter__(self):\n",
    "        super().__enter__()\n",
    "        self.trace = OrderedDict()\n",
    "        return self.trace\n",
    "\n",
    "    # trace illustrates why we need postprocess_message in addition to process_message:\n",
    "    # We only want to record a value after all other effects have been applied\n",
    "    def postprocess_message(self, msg):\n",
    "        assert msg[\"type\"] != \"sample\" or msg[\"name\"] not in self.trace, \\\n",
    "            \"sample sites must have unique names\"\n",
    "        self.trace[msg[\"name\"]] = msg.copy()\n",
    "\n",
    "    def get_trace(self, *args, **kwargs):\n",
    "        self(*args, **kwargs)\n",
    "        return self.trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight Normal(loc: 8.5, scale: 1.0) tensor(7.6848) False\n",
      "measurement Normal(loc: 7.684762001037598, scale: 0.75) 9.5 True\n"
     ]
    }
   ],
   "source": [
    "import pyro.distributions as dist\n",
    "from pyro.poutine.trace_messenger import TraceMessenger\n",
    "mu = 8.5\n",
    "def scale_obs(mu):  \n",
    "    weight = pyro.sample(\"weight\", dist.Normal(mu, 1.))\n",
    "    return pyro.sample(\"measurement\", dist.Normal(weight, 0.75), obs=9.5)\n",
    "\n",
    "with TraceMessenger() as tracer:\n",
    "    scale_obs(mu)\n",
    "\n",
    "trace = tracer.trace\n",
    "logp = 0.\n",
    "for name, node in trace.nodes.items():\n",
    "    print(name, node['fn'], node['value'], node['is_observed'])\n",
    "    if node[\"type\"] == \"sample\":\n",
    "        logp = logp + node[\"fn\"].log_prob(node[\"value\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# %psource TraceMessenger\n",
    "# Return a handler that records the inputs and outputs of primitive calls and their dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "这里给出第二个有用的 effect handler 例子用于给某个样本点设置 value.\n",
    "This illustrates why effect handlers are a useful PPL implementation technique:\n",
    "We can compose trace and replay to replace values but preserve distributions,\n",
    "allowing us to compute the joint probability density of samples under a model.\n",
    "See the definition of elbo(...) below for an example of this pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class replay(Messenger):\n",
    "    def __init__(self, fn, guide_trace):\n",
    "        self.guide_trace = guide_trace\n",
    "        super().__init__(fn)\n",
    "\n",
    "    def process_message(self, msg):\n",
    "        if msg[\"name\"] in self.guide_trace:\n",
    "            msg[\"value\"] = self.guide_trace[msg[\"name\"]][\"value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "block allows the selective application of effect handlers to different parts of a model.\n",
    "Sites hidden by block will only have the handlers below block on the PYRO_STACK applied,\n",
    "allowing inference or other effectful computations to be nested inside models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class block(Messenger):\n",
    "    def __init__(self, fn=None, hide_fn=lambda msg: True):\n",
    "        self.hide_fn = hide_fn\n",
    "        super().__init__(fn)\n",
    "\n",
    "    def process_message(self, msg):\n",
    "        if self.hide_fn(msg):\n",
    "            msg[\"stop\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# seed is used to fix the RNG state when calling a model.\n",
    "class seed(Messenger):\n",
    "    def __init__(self, fn=None, rng_seed=None):\n",
    "        self.rng_seed = rng_seed\n",
    "        super().__init__(fn)\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.old_state = {'torch': torch.get_rng_state(), 'random': random.getstate()}\n",
    "        torch.manual_seed(self.rng_seed)\n",
    "        random.seed(self.rng_seed)\n",
    "        try:\n",
    "            import numpy as np\n",
    "            np.random.seed(self.rng_seed)\n",
    "            self.old_state['numpy'] = np.random.get_state()\n",
    "        except ImportError:\n",
    "            pass\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        torch.set_rng_state(self.old_state['torch'])\n",
    "        random.setstate(self.old_state['random'])\n",
    "        if 'numpy' in self.old_state:\n",
    "            import numpy as np\n",
    "            np.random.set_state(self.old_state['numpy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# This limited implementation of PlateMessenger only implements broadcasting.\n",
    "class PlateMessenger(Messenger):\n",
    "    def __init__(self, fn, size, dim):\n",
    "        assert dim < 0\n",
    "        self.size = size\n",
    "        self.dim = dim\n",
    "        super().__init__(fn)\n",
    "\n",
    "    def process_message(self, msg):\n",
    "        if msg[\"type\"] == \"sample\":\n",
    "            batch_shape = msg[\"fn\"].batch_shape\n",
    "            if len(batch_shape) < -self.dim or batch_shape[self.dim] != self.size:\n",
    "                batch_shape = [1] * (-self.dim - len(batch_shape)) + list(batch_shape)\n",
    "                batch_shape[self.dim] = self.size\n",
    "                msg[\"fn\"] = msg[\"fn\"].expand(torch.Size(batch_shape))\n",
    "\n",
    "    def __iter__(self):\n",
    "        return range(self.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 操作 Messenger\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "`apply_stack` is called by `pyro.sample` and `pyro.param`.\n",
    "It is responsible for applying each `Messenger` to each effectful operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def apply_stack(msg):\n",
    "    for pointer, handler in enumerate(reversed(PYRO_STACK)):\n",
    "        handler.process_message(msg)\n",
    "        # When a Messenger sets the \"stop\" field of a message,\n",
    "        # it prevents any Messengers above it on the stack from being applied.\n",
    "        if msg.get(\"stop\"):\n",
    "            break\n",
    "    if msg[\"value\"] is None:\n",
    "        msg[\"value\"] = msg[\"fn\"](*msg[\"args\"])\n",
    "\n",
    "    # A Messenger that sets msg[\"stop\"] == True also prevents application\n",
    "    # of postprocess_message by Messengers above it on the stack\n",
    "    # via the pointer variable from the process_message loop\n",
    "    for handler in PYRO_STACK[-pointer-1:]:\n",
    "        handler.postprocess_message(msg)\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# sample is an effectful version of Distribution.sample(...)\n",
    "# When any effect handlers are active, it constructs an initial message and calls apply_stack.\n",
    "def sample(name, fn, *args, **kwargs):\n",
    "    obs = kwargs.pop('obs', None)\n",
    "\n",
    "    # if there are no active Messengers, we just draw a sample and return it as expected:\n",
    "    if not PYRO_STACK:\n",
    "        return fn(*args, **kwargs)\n",
    "\n",
    "    # Otherwise, we initialize a message...\n",
    "    initial_msg = {\n",
    "        \"type\": \"sample\",\n",
    "        \"name\": name,\n",
    "        \"fn\": fn,\n",
    "        \"args\": args,\n",
    "        \"kwargs\": kwargs,\n",
    "        \"value\": obs,\n",
    "    }\n",
    "\n",
    "    # ...and use apply_stack to send it to the Messengers\n",
    "    msg = apply_stack(initial_msg)\n",
    "    return msg[\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# param is an effectful version of PARAM_STORE.setdefault that also handles constraints.\n",
    "# When any effect handlers are active, it constructs an initial message and calls apply_stack.\n",
    "def param(name, init_value=None, constraint=torch.distributions.constraints.real, event_dim=None):\n",
    "    if event_dim is not None:\n",
    "        raise NotImplementedError(\"minipyro.plate does not support the event_dim arg\")\n",
    "\n",
    "    def fn(init_value, constraint):\n",
    "        if name in PARAM_STORE:\n",
    "            unconstrained_value, constraint = PARAM_STORE[name]\n",
    "        else:\n",
    "            # Initialize with a constrained value.\n",
    "            assert init_value is not None\n",
    "            with torch.no_grad():\n",
    "                constrained_value = init_value.detach()\n",
    "                unconstrained_value = torch.distributions.transform_to(constraint).inv(constrained_value)\n",
    "            unconstrained_value.requires_grad_()\n",
    "            PARAM_STORE[name] = unconstrained_value, constraint\n",
    "\n",
    "        # Transform from unconstrained space to constrained space.\n",
    "        constrained_value = torch.distributions.transform_to(constraint)(unconstrained_value)\n",
    "        constrained_value.unconstrained = weakref.ref(unconstrained_value)\n",
    "        return constrained_value\n",
    "\n",
    "    # if there are no active Messengers, we just draw a sample and return it as expected:\n",
    "    if not PYRO_STACK:\n",
    "        return fn(init_value, constraint)\n",
    "\n",
    "    # Otherwise, we initialize a message...\n",
    "    initial_msg = {\n",
    "        \"type\": \"param\",\n",
    "        \"name\": name,\n",
    "        \"fn\": fn,\n",
    "        \"args\": (init_value, constraint),\n",
    "        \"value\": None,\n",
    "    }\n",
    "\n",
    "    # ...and use apply_stack to send it to the Messengers\n",
    "    msg = apply_stack(initial_msg)\n",
    "    return msg[\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false",
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# boilerplate to match the syntax of actual pyro.plate:\n",
    "def plate(name, size, dim=None):\n",
    "    if dim is None:\n",
    "        raise NotImplementedError(\"minipyro.plate requires a dim arg\")\n",
    "    return PlateMessenger(fn=None, size=size, dim=dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 推断和优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# This is a thin wrapper around the `torch.optim.Adam` class that\n",
    "# dynamically generates optimizers for dynamically generated parameters.\n",
    "# See http://docs.pyro.ai/en/0.3.1/optimization.html\n",
    "class Adam:\n",
    "    def __init__(self, optim_args):\n",
    "        self.optim_args = optim_args\n",
    "        # Each parameter will get its own optimizer, which we keep track\n",
    "        # of using this dictionary keyed on parameters.\n",
    "        self.optim_objs = {}\n",
    "\n",
    "    def __call__(self, params):\n",
    "        for param in params:\n",
    "            # If we've seen this parameter before, use the previously\n",
    "            # constructed optimizer.\n",
    "            if param in self.optim_objs:\n",
    "                optim = self.optim_objs[param]\n",
    "            # If we've never seen this parameter before, construct\n",
    "            # an Adam optimizer and keep track of it.\n",
    "            else:\n",
    "                optim = torch.optim.Adam([param], **self.optim_args)\n",
    "                self.optim_objs[param] = optim\n",
    "            # Take a gradient step for the parameter param.\n",
    "            optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "code_folding": [
     4,
     38
    ]
   },
   "outputs": [],
   "source": [
    "# This is a unified interface for stochastic variational inference in Pyro.\n",
    "# The actual construction of the loss is taken care of by `loss`.\n",
    "# See http://docs.pyro.ai/en/0.3.1/inference_algos.html\n",
    "class SVI:\n",
    "    def __init__(self, model, guide, optim, loss):\n",
    "        self.model = model\n",
    "        self.guide = guide\n",
    "        self.optim = optim\n",
    "        self.loss = loss\n",
    "\n",
    "    # This method handles running the model and guide, constructing the loss\n",
    "    # function, and taking a gradient step.\n",
    "    def step(self, *args, **kwargs):\n",
    "        # This wraps both the call to `model` and `guide` in a `trace` so that\n",
    "        # we can record all the parameters that are encountered. Note that\n",
    "        # further tracing occurs inside of `loss`.\n",
    "        with trace() as param_capture:\n",
    "            # We use block here to allow tracing to record parameters only.\n",
    "            with block(hide_fn=lambda msg: msg[\"type\"] == \"sample\"):\n",
    "                loss = self.loss(self.model, self.guide, *args, **kwargs)\n",
    "        # Differentiate the loss.\n",
    "        loss.backward()\n",
    "        # Grab all the parameters from the trace.\n",
    "        params = [site[\"value\"].unconstrained()\n",
    "                  for site in param_capture.values()]\n",
    "        # Take a step w.r.t. each parameter in params.\n",
    "        self.optim(params)\n",
    "        # Zero out the gradients so that they don't accumulate.\n",
    "        for p in params:\n",
    "            p.grad = torch.zeros_like(p)\n",
    "        return loss.item()\n",
    "\n",
    "    # This is a basic implementation of the Evidence Lower Bound, which is the\n",
    "    # fundamental objective in Variational Inference.\n",
    "    # See http://pyro.ai/examples/svi_part_i.html for details.\n",
    "    # This implementation has various limitations (for example it only supports\n",
    "    # random variables with reparameterized samplers), but all the ELBO\n",
    "    # implementations in Pyro share the same basic logic.\n",
    "    def elbo(model, guide, *args, **kwargs):\n",
    "        # Run the guide with the arguments passed to SVI.step() and trace the execution,\n",
    "        # i.e. record all the calls to Pyro primitives like sample() and param().\n",
    "        guide_trace = trace(guide).get_trace(*args, **kwargs)\n",
    "        # Now run the model with the same arguments and trace the execution. Because\n",
    "        # model is being run with replay, whenever we encounter a sample site in the\n",
    "        # model, instead of sampling from the corresponding distribution in the model,\n",
    "        # we instead reuse the corresponding sample from the guide. In probabilistic\n",
    "        # terms, this means our loss is constructed as an expectation w.r.t. the joint\n",
    "        # distribution defined by the guide.\n",
    "        model_trace = trace(replay(model, guide_trace)).get_trace(*args, **kwargs)\n",
    "        # We will accumulate the various terms of the ELBO in `elbo`.\n",
    "        elbo = 0.\n",
    "        # Loop over all the sample sites in the model and add the corresponding\n",
    "        # log p(z) term to the ELBO. Note that this will also include any observed\n",
    "        # data, i.e. sample sites with the keyword `obs=...`.\n",
    "        for site in model_trace.values():\n",
    "            if site[\"type\"] == \"sample\":\n",
    "                elbo = elbo + site[\"fn\"].log_prob(site[\"value\"]).sum()\n",
    "        # Loop over all the sample sites in the guide and add the corresponding\n",
    "        # -log q(z) term to the ELBO.\n",
    "        for site in guide_trace.values():\n",
    "            if site[\"type\"] == \"sample\":\n",
    "                elbo = elbo - site[\"fn\"].log_prob(site[\"value\"]).sum()\n",
    "        # Return (-elbo) since by convention we do gradient descent on a loss and\n",
    "        # the ELBO is a lower bound that needs to be maximized.\n",
    "        return -elbo\n",
    "\n",
    "\n",
    "    # This is a wrapper for compatibility with full Pyro.\n",
    "    def Trace_ELBO(**kwargs):\n",
    "        return elbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "code_folding": [
     12,
     3,
     38,
     4
    ]
   },
   "outputs": [],
   "source": [
    "# This is a Jit wrapper around elbo() that (1) delays tracing until the first\n",
    "# invocation, and (2) registers pyro.param() statements with torch.jit.trace.\n",
    "# This version does not support variable number of args or non-tensor kwargs.\n",
    "class JitTrace_ELBO:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.ignore_jit_warnings = kwargs.pop(\"ignore_jit_warnings\", False)\n",
    "        self._compiled = None\n",
    "        self._param_trace = None\n",
    "\n",
    "    def __call__(self, model, guide, *args):\n",
    "        # On first call, initialize params and save their names.\n",
    "        if self._param_trace is None:\n",
    "            with block(), trace() as tr, block(hide_fn=lambda m: m[\"type\"] != \"param\"):\n",
    "                elbo(model, guide, *args)\n",
    "            self._param_trace = tr\n",
    "\n",
    "        # Augment args with reads from the global param store.\n",
    "        unconstrained_params = tuple(param(name).unconstrained()\n",
    "                                     for name in self._param_trace)\n",
    "        params_and_args = unconstrained_params + args\n",
    "\n",
    "        # On first call, create a compiled elbo.\n",
    "        if self._compiled is None:\n",
    "\n",
    "            def compiled(*params_and_args):\n",
    "                unconstrained_params = params_and_args[:len(self._param_trace)]\n",
    "                args = params_and_args[len(self._param_trace):]\n",
    "                for name, unconstrained_param in zip(self._param_trace, unconstrained_params):\n",
    "                    constrained_param = param(name)  # assume param has been initialized\n",
    "                    assert constrained_param.unconstrained() is unconstrained_param\n",
    "                    self._param_trace[name][\"value\"] = constrained_param\n",
    "                return replay(elbo, guide_trace=self._param_trace)(model, guide, *args)\n",
    "\n",
    "            with validation_enabled(False), warnings.catch_warnings():\n",
    "                if self.ignore_jit_warnings:\n",
    "                    warnings.filterwarnings(\"ignore\", category=torch.jit.TracerWarning)\n",
    "                self._compiled = torch.jit.trace(compiled, params_and_args, check_trace=False)\n",
    "\n",
    "        return self._compiled(*params_and_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## 用 effect handlers 实现推断算法实战\n",
    "\n",
    "<big> Implementing inference algorithms with existing effect handlers: examples </big> \n",
    "\n",
    "It turns out that many inference operations, like our first version of `make_log_joint` above, have strikingly short implementations in terms of existing effect handlers in `pyro.poutine`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 例子: Variational inference with a Monte Carlo ELBO\n",
    "\n",
    "For example, here is an implementation of variational inference with a Monte Carlo ELBO that uses `poutine.trace`, `poutine.condition`, and `poutine.replay`.  This is very similar to the simple ELBO in [pyro.contrib.minipyro](https://github.com/pyro-ppl/pyro/blob/dev/pyro/contrib/minipyro.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def monte_carlo_elbo(model, guide, batch, *args, **kwargs):\n",
    "    # assuming batch is a dictionary, we use poutine.condition to fix values of observed variables\n",
    "    conditioned_model = poutine.condition(model, data=batch)\n",
    "    \n",
    "    # we'll approximate the expectation in the ELBO with a single sample:\n",
    "    # first, we run the guide forward unmodified and record values and distributions\n",
    "    # at each sample site using poutine.trace\n",
    "    guide_trace = poutine.trace(guide).get_trace(*args, **kwargs)\n",
    "    \n",
    "    # we use poutine.replay to set the values of latent variables in the model\n",
    "    # to the values sampled above by our guide, and use poutine.trace\n",
    "    # to record the distributions that appear at each sample site in in the model\n",
    "    model_trace = poutine.trace(\n",
    "        poutine.replay(conditioned_model, trace=guide_trace)\n",
    "    ).get_trace(*args, **kwargs)\n",
    "    \n",
    "    elbo = 0.\n",
    "    for name, node in model_trace.nodes.items():\n",
    "        if node[\"type\"] == \"sample\":\n",
    "            elbo = elbo + node[\"fn\"].log_prob(node[\"value\"]).sum()\n",
    "            if not node[\"is_observed\"]:\n",
    "                elbo = elbo - guide_trace.nodes[name][\"fn\"].log_prob(node[\"value\"]).sum()\n",
    "    return -elbo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We use `poutine.trace` and `poutine.block` to record `pyro.param` calls for optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def train(model, guide, data):\n",
    "    optimizer = pyro.optim.Adam({})\n",
    "    for batch in data:\n",
    "        # this poutine.trace will record all of the parameters that appear in the model and guide\n",
    "        # during the execution of monte_carlo_elbo\n",
    "        with poutine.trace() as param_capture:\n",
    "            # we use poutine.block here so that only parameters appear in the trace above\n",
    "            with poutine.block(hide_fn=lambda node: node[\"type\"] != \"param\"):\n",
    "                loss = monte_carlo_elbo(model, guide, batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        params = set(node[\"value\"].unconstrained()\n",
    "                     for node in param_capture.trace.nodes.values())\n",
    "        optimizer.step(params)\n",
    "        pyro.infer.util.zero_grads(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 例子: exact inference via sequential enumeration\n",
    "\n",
    "Here is an example of a very different inference algorithm--exact inference via enumeration--implemented with `pyro.poutine`.  A complete explanation of this algorithm is beyond the scope of this tutorial and may be found in Chapter 3 of the short online book [Design and Implementation of Probabilistic Programming Languages](http://dippl.org/chapters/03-enumeration.html).  This example uses `poutine.queue`, itself implemented using `poutine.trace`, `poutine.replay`, and `poutine.block`, to enumerate over possible values of all discrete variables in a model and compute a marginal distribution over all possible return values or the possible values at a particular sample site:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def sequential_discrete_marginal(model, data, site_name=\"_RETURN\"):\n",
    "    \n",
    "    from six.moves import queue  # queue data structures\n",
    "    q = queue.Queue()  # Instantiate a first-in first-out queue\n",
    "    q.put(poutine.Trace())  # seed the queue with an empty trace\n",
    "    \n",
    "    # as before, we fix the values of observed random variables with poutine.condition\n",
    "    # assuming data is a dictionary whose keys are names of sample sites in model\n",
    "    conditioned_model = poutine.condition(model, data=data)\n",
    "    \n",
    "    # we wrap the conditioned model in a poutine.queue,\n",
    "    # which repeatedly pushes and pops partially completed executions from a Queue()\n",
    "    # to perform breadth-first enumeration over the set of values of all discrete sample sites in model\n",
    "    enum_model = poutine.queue(conditioned_model, queue=q)\n",
    "    \n",
    "    # actually perform the enumeration by repeatedly tracing enum_model\n",
    "    # and accumulate samples and trace log-probabilities for postprocessing\n",
    "    samples, log_weights = [], []\n",
    "    while not q.empty():\n",
    "        trace = poutine.trace(enum_model).get_trace()\n",
    "        samples.append(trace.nodes[site_name][\"value\"])\n",
    "        log_weights.append(trace.log_prob_sum())\n",
    "        \n",
    "    # we take the samples and log-joints and turn them into a histogram:\n",
    "    samples = torch.stack(samples, 0)\n",
    "    log_weights = torch.stack(log_weights, 0)\n",
    "    log_weights = log_weights - dist.util.logsumexp(log_weights, dim=0)\n",
    "    return dist.Empirical(samples, log_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "(Note that `sequential_discrete_marginal` is very general, but is also quite slow. For high-performance parallel enumeration that applies to a less general class of models, see the enumeration tutorial.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "### 例子: implementing lazy evaluation with the `Messenger` API\n",
    "\n",
    "Now that we've learned more about the internals of `Messenger`, let's use it to implement a slightly more complicated effect: lazy evaluation. We first define a `LazyValue` class that we will use to build up a computation graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class LazyValue:\n",
    "    def __init__(self, fn, *args, **kwargs):\n",
    "        self._expr = (fn, args, kwargs)\n",
    "        self._value = None\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"({} {})\".format(str(self._expr[0]), \" \".join(map(str, self._expr[1])))\n",
    "        \n",
    "    def evaluate(self):\n",
    "        if self._value is None:\n",
    "            fn, args, kwargs = self._expr\n",
    "            fn = fn.evaluate() if isinstance(fn, LazyValue) else fn\n",
    "            args = tuple(arg.evaluate() if isinstance(arg, LazyValue) else arg\n",
    "                         for arg in args)\n",
    "            kwargs = {k: v.evaluate() if isinstance(v, LazyValue) else v\n",
    "                      for k, v in kwargs.items()}\n",
    "            self._value = fn(*args, **kwargs)\n",
    "        return self._value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "With `LazyValue`, implementing lazy evaluation as a `Messenger` compatible with other effect handlers is suprisingly easy. We just make each `msg[\"value\"]` a `LazyValue` and introduce a new operation type `\"apply\"` for deterministic operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class LazyMessenger(pyro.poutine.messenger.Messenger):\n",
    "    def _process_message(self, msg):\n",
    "        if msg[\"type\"] in (\"apply\", \"sample\") and not msg[\"done\"]:\n",
    "            msg[\"done\"] = True\n",
    "            msg[\"value\"] = LazyValue(msg[\"fn\"], *msg[\"args\"], **msg[\"kwargs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Finally, just like `torch.autograd` overloads `torch` tensor operations to record an autograd graph, we need to wrap any operations we'd like to be lazy.  We'll use `pyro.poutine.runtime.effectful` as a decorator to expose these operations to `LazyMessenger`. `effectful` constructs a message much like the one above and sends it up and down the effect handler stack, but allows us to set the type (in this case, to `\"apply\"` instead of `\"sample\"`) so that these operations aren't mistaken for `sample` statements by other effect handlers like `TraceMessenger`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "@effectful(type=\"apply\")\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "@effectful(type=\"apply\")\n",
    "def mul(x, y):\n",
    "    return x * y\n",
    "\n",
    "@effectful(type=\"apply\")\n",
    "def sigmoid(x):\n",
    "    return torch.sigmoid(x)\n",
    "\n",
    "@effectful(type=\"apply\")\n",
    "def normal(loc, scale):\n",
    "    return dist.Normal(loc, scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Applied to another model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((<function normal at 0x7fc41cbfdc80> (<function add at 0x7fc41cbf91e0> (<function mul at 0x7fc41cbfda60> ((<function normal at 0x7fc41cbfdc80> 8.5 1.0) ) 0.8) 1.0) (<function sigmoid at 0x7fc41cbfdb70> ((<function normal at 0x7fc41cbfdc80> 0.0 0.25) ))) )\n",
      "tensor(6.5436)\n"
     ]
    }
   ],
   "source": [
    "def biased_scale(guess):\n",
    "    weight = pyro.sample(\"weight\", normal(guess, 1.))\n",
    "    tolerance = pyro.sample(\"tolerance\", normal(0., 0.25))\n",
    "    return pyro.sample(\"measurement\", normal(add(mul(weight, 0.8), 1.), sigmoid(tolerance)))\n",
    "\n",
    "with LazyMessenger():\n",
    "    v = biased_scale(8.5)\n",
    "    print(v)\n",
    "    print(v.evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Together with other effect handlers like `TraceMessenger` and `ConditionMessenger`, with which it freely composes, `LazyMessenger` demonstrates how to use Poutine to quickly and concisely implement state-of-the-art PPL techniques like [delayed sampling with Rao-Blackwellization](https://arxiv.org/abs/1708.07787)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "<big> References: EH 参考资料 </big>\n",
    "\n",
    "Algebraic effects and handlers in programming language research\n",
    "\n",
    "This section contains some references to PL papers for readers interested in this direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "代数效应和处理程序始于2000年代初期，是编程语言社区中活跃的研究主题，它是一种通用抽象，for building modular implementations of nonstandard interpreters of particular statements in a programming language，例如`pyro.sample` 和 `pyro.param`。They were originally introduced to address the difficulty of composing nonstandard interpreters implemented with monads and monad transformers.\n",
    "\n",
    "- For an accessible introduction to the effect handlers literature, see the excellent review/tutorial paper [\"Handlers in Action\"](http://homepages.inf.ed.ac.uk/slindley/papers/handlers.pdf) by Ohad Kammar, Sam Lindley, and Nicolas Oury, and the references therein.\n",
    "\n",
    "- Algebraic effect handlers were originally introduced by Gordon Plotkin and Matija Pretnar in the paper [\"Handlers of Algebraic Effects\"](https://link.springer.com/chapter/10.1007/978-3-642-00590-9_7).\n",
    "\n",
    "- A useful mental model of effect handlers is as exception handlers that are capable of resuming computation in the `try` block after raising an exception and performing some processing in the `except` block. This metaphor is explored further in the experimental programming language [Eff](http://math.andrej.com/eff/) and its companion paper [\"Programming with Algebraic Effects and Handlers\"](https://arxiv.org/abs/1203.1539) by Andrej Bauer and Matija Pretnar.\n",
    "\n",
    "- Most effect handlers in Pyro are \"linear,\" meaning that they only resume once per effectful operation and do not alter the order of execution of the original program. One exception is `poutine.queue`, which uses an inefficient implementation strategy for multiple resumptions like the one described for delimited continuations in the paper [\"Capturing the Future by Replaying the Past\"](http://delivery.acm.org/10.1145/3240000/3236771/icfp18main-p36-p.pdf) by James Koppel, Gabriel Scherer, and Armando Solar-Lezama.  \n",
    "\n",
    "- More efficient implementation strategies for effect handlers in mainstream programming languages like Python or JavaScript is an area of active research. One promising line of work involves selective continuation-passing style transforms as in the paper [\"Type-Directed Compilation of Row-Typed Algebraic Effects\"](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/12/algeff.pdf) by Daan Leijen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
