{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# 贝叶斯回归-介绍(Part 1)\n",
    "\n",
    "回归是机器学习中最常见和最基本的监督学习任务之一。假设我们有如下形式的数据集 $\\mathcal{D}$：\n",
    "\n",
    "$$ \\mathcal{D}  = \\{ (X_i, y_i) \\} \\qquad \\text{for}\\qquad i=1,2,...,N$$\n",
    "\n",
    "线性回归的目标是根据数据拟合一个以下形式的函数：\n",
    "\n",
    "$$ y = w X + b + \\epsilon $$\n",
    "\n",
    "where $w$ and $b$ are learnable parameters and $\\epsilon$ represents observation noise. Specifically $w$ is a matrix of weights and $b$ is a bias vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "在本教程中，我们将首先在 PyTorch 中实现线性回归，并学习参数 $w$ 和 $b$ 的点估计。Then we will see how to incorporate uncertainty into our estimates by using Pyro to implement Bayesian regression. 此外，我们将学习 how to use the Pyro's utility functions to do predictions and serve our model using `TorchScript`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 4.6074\n",
      "[iteration 0201] loss: 2.5499\n",
      "[iteration 0401] loss: 1.4601\n",
      "[iteration 0601] loss: 1.4725\n",
      "[iteration 0801] loss: 1.4677\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-2.2916, -1.8635, -0.1926,  0.3305,  9.1682])\n",
      "AutoDiagonalNormal.scale tensor([0.0559, 0.1428, 0.0459, 0.0847, 0.0635])\n"
     ]
    }
   ],
   "source": [
    "# 学完本文，您将理解如下程序\n",
    "import os, torch, pyro\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro.distributions as dist\n",
    "from torch import nn\n",
    "from functools import partial\n",
    "from pyro.nn import PyroModule, PyroSample\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "pyro.enable_validation(True)\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "\n",
    "def get_data():\n",
    "    DATA_URL = \"https://d2hg8soec8ck9v.cloudfront.net/datasets/rugged_data.csv\"\n",
    "    data = pd.read_csv(DATA_URL, encoding=\"ISO-8859-1\")\n",
    "    df = data[[\"cont_africa\", \"rugged\", \"rgdppc_2000\"]]\n",
    "    df = df[np.isfinite(df.rgdppc_2000)]\n",
    "    df[\"rgdppc_2000\"] = np.log(df[\"rgdppc_2000\"])\n",
    "    df[\"cont_africa_x_rugged\"] = df[\"cont_africa\"] * df[\"rugged\"]\n",
    "    data = torch.tensor(df[[\"cont_africa\", \"rugged\", \"cont_africa_x_rugged\", \"rgdppc_2000\"]].values,\n",
    "                            dtype=torch.float)\n",
    "    x_data, y_data = data[:, :-1], data[:, -1]\n",
    "    return x_data, y_data\n",
    "\n",
    "x_data, y_data = get_data()\n",
    "\n",
    "num_iterations =1000\n",
    "\n",
    "class BayesianRegression(PyroModule):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.linear = PyroModule[nn.Linear](in_features, out_features)\n",
    "        self.linear.weight = PyroSample(dist.Normal(0., 1.).expand([out_features, in_features]).to_event(2))\n",
    "        self.linear.bias = PyroSample(dist.Normal(0., 10.).expand([out_features]).to_event(1))\n",
    "        \n",
    "    def forward(self, x, y=None):\n",
    "        sigma = pyro.sample(\"sigma\", dist.Uniform(0., 10.))\n",
    "        mean = self.linear(x).squeeze(-1)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            obs = pyro.sample(\"obs\", dist.Normal(mean, sigma), obs=y)\n",
    "        return mean\n",
    "\n",
    "model = BayesianRegression(3, 1)\n",
    "guide = AutoDiagonalNormal(model)\n",
    "adam = pyro.optim.Adam({\"lr\": 0.03})\n",
    "svi = SVI(model, guide, adam, loss=Trace_ELBO())\n",
    "\n",
    "pyro.clear_param_store()\n",
    "for j in range(num_iterations):\n",
    "    loss = svi.step(x_data, y_data)\n",
    "    if j % 200 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_data)))\n",
    "        \n",
    "guide.requires_grad_(False)\n",
    "\n",
    "for name, value in pyro.get_param_store().items():\n",
    "    print(name, pyro.param(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Setup\n",
    "\n",
    "首先，导入所需的模块。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%reset -s -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "# for CI testing\n",
    "smoke_test = ('CI' in os.environ)\n",
    "assert pyro.__version__.startswith('1.3.0')\n",
    "pyro.enable_validation(True)\n",
    "pyro.set_rng_seed(1)\n",
    "pyro.enable_validation(True)\n",
    "\n",
    "\n",
    "# Set matplotlib settings\n",
    "%matplotlib inline\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Dataset**\n",
    "\n",
    "以下示例来自于文献 \\[1\\].  我们希望探索 relationship between topographic heterogeneity of a nation as measured by the Terrain Ruggedness Index (数据中的 *rugged* 变量) and 人均GDP. 具体来说, it was noted by the authors in \\[2\\] that terrain ruggedness or bad geography is related to poorer economic performance outside of Africa, but rugged terrains have had a reverse effect on income for African nations. 让我们查看数据并研究这种关系，我们将关注数据集中的三个特征：\n",
    "\n",
    "  - `rugged`: quantifies the Terrain Ruggedness Index\n",
    "  - `cont_africa`: whether the given nation is in Africa\n",
    "  - `rgdppc_2000`: Real GDP per capita for the year 2000\n",
    "  \n",
    "The response variable GDP is highly skewed, so we will log-transform it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "DATA_URL = \"https://d2hg8soec8ck9v.cloudfront.net/datasets/rugged_data.csv\"\n",
    "data = pd.read_csv(DATA_URL, encoding=\"ISO-8859-1\")\n",
    "df = data[[\"cont_africa\", \"rugged\", \"rgdppc_2000\"]]\n",
    "df = df[np.isfinite(df.rgdppc_2000)]\n",
    "df[\"rgdppc_2000\"] = np.log(df[\"rgdppc_2000\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAGDCAYAAADQ9S0AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de5idZXnv8d9vkkwyhEAiBEQO4gGplCLKCEJaK5tqtaVbI2qtImhVsNHadm8Va4uH0nYXtFbdbRQURVAQBVOPRawbS03lkAgiohGtB8IhGWMCkzDkNPf+Y70rrJms8+E9re/nunIlsw7zPuudzLPudb/3cz+OCAEAAABobCTrAQAAAAB5R9AMAAAAtEDQDAAAALRA0AwAAAC0QNAMAAAAtEDQDAAAALRA0IxCsL3M9t22t9p+UYPH/Jvts9MeW7+V5XUAKD7bY7a/ZPtB259r8JhX2r4+7bH1W1leBwaHoBl12f6Z7Q22F9bc9jrb3xzgMZ9ge9r2yjp3/42kf46IfSPiX+s9PyJeEBGfHNT46un1PNl+t+1P1d6WxesAMNxsf9P2ZtvzZ931EkkHSzogIl5a77kR8emIeN7AB1kjmTvD9ktrbpub3HZkG88/Mnns3OptWbwOFAtBM5qZK+nPUjzeWZI2S3p5nYn78ZK+X+9Jrsjy/3La5wkA+iYJMn9LUkj6n7PufrykH0XErgbPnVvv9pT8StLf2J6T4RgwRAia0cx7Jb3F9uJ6d9o+xfatyWW7W22fUnPfN21fYHu17Unb19s+sMXxzpL015J2SvqDmu/1E0lPlPSlpDxjfvL9/872akkPS3pictvrap73ets/SI5/l+1nJLe/3fZPam5fXvOcV9v+lu33JVmXn9p+QY/n6YO277H9kO21tn8ruf35kt4h6Q+T1/XdmnP3uuTfI7b/2vbPbW+0fbnt/ZP7qpmSs23/wvYvbf9VzXFPtL0mOe4G2+9v8ToADKezJN0k6TJJe0rDbL9H0jv16Bz12mSOXG37n2z/StK7q/NmzfN+3fbXbf8qmXvekdx+ou1v295i+37b/2x7tOZ5YfsNrpTibbb9L7bdZNzXSdoh6cx6d9r+fdu3JXPgPbbfXXP3jcnfW5LXdnKd19HVe5ztBbY/ZXtT8lpvtX1w058ACoGgGc2skfRNSW+ZfYftx0j6iqQPSTpA0vslfcX2ATUPe4Wk10g6SNJove9T8/1+S9Jhkj4j6bOqTOKSpIh4kqRfSPqDpDxje3LXqySdI2mRpJ/P+n4vlfTu5Pvsp0r2ZFNy909UyarsL+k9kj5l+5Cap58kaZ2kAyVdJOnSFhN3w/OUuFXS8ZIeI+lKSZ+zvSAirpP095KuTl7X0+o899XJn1NV+eCwr6R/nvWY35R0tKTTJL3T9lOT2z8o6YMRsZ+kJ6lyXgFgtrMkfTr587vVAC8i3qWZc9SlyeNPkvTfqsztf1f7jWwvkvTvqgS0j5P0ZEnfSO7eLekvVJlbT1ZlzloxayynS3qmpKdJepmk320y7pB0vqR32Z5X5/5tyWtbLOn3Jf2JH10T8+zk78XJa/v2rNfRy3vc2aq8vxyePPcNkqaavA4UBEEzWnmnpD+1vXTW7b8v6e6IuCIidkXEVZJ+qJoMsaRPRMSPImJKlYDt+CbHOVvSv0XEZlUCyxfYPqjF2C6LiO8nx985677XSbooIm6Nih9HxM8lKSI+FxH3RcR0RFwt6W5JJ9Y89+cR8dGI2C3pk5IOUaWmr5lG50kR8amI2JSM8x8lzVclyG3HKyW9PyL+OyK2SvpLVcpXai+JvicipiLiu5K+q8qbjVTJ2D/Z9oERsTUibmrzmACGhO3fVKUE47MRsVaVpMIrWjztvoj4v8mcNjsYPF3SAxHxjxHxSERMRsTNkhQRayPipuR5P5N0saTfnvX8f4iILRHxC0k3qPn7hiLii5ImVJnzZ9/3zYj4XjLX3yHpqjrHa6SX97idqgTLT46I3cnrfqjN4yLHCJrRVETcKenLkt4+667HaVZ2N/n60JqvH6j598OqZEn3YntM0ktVyXIo+cT/C7WeuO9pct/hqkz+9Y53lu3bk8tmWyQdq0rmY69xR8TDyT/rjr3mcY3Ok2z/76RM5MHkePvPOl4zs8/zz1Wpoa4N4hud59dKeoqkHyaXB09v85gAhsfZkq6PiF8mX1+pmhKNBrqde59i+8u2H7D9kCpZ7NlzYVvvG7P8taS/krRg1vFOsn2D7QnbD6qS8e127pXaf4+7QtLXJH3G9n22L2qQCUfBEDSjHe+S9HrNnCzuUyU7UesISfd28f2Xq1JCsTKZTB9IjnVW86cpmtx3jyolCTPYfrykj0p6kyqrwRdLulNSs/KLdu11npKyk/NUucy4JDnegzXHa/YapL3P8xGSdkna0GowEXF3RPyRKpcOL5R0jWu6fAAYbknC4mWSfrtm7v0LSU+zXa9crKrjuTfxYVWytUclZWPvUB/m3oj4uqQfa+9SjyslfVHS4RGxv6SPqPu5V2rzPS4idkbEeyLiGEmnqJJ9b/V+hgIgaEZLEfFjSVdLenPNzV+V9BTbr3Clzc8fSjpGlWxrp86W9HFJv6HK5a3jJS2TdLzt3+hy2B9TZXHeCa54chIwL1RlspyQJNuvUSXT3LMG52mRKkHuhKS5tt+pygeEqg2SjnTj7h9XSfoLV9rx7atH6wvrrmSvZftM20sjYlrSluTm3R29KABl9iJV5oRj9Ojc+1RJ/6nug7wvS3qs7T93ZdH2ItsnJfctkvSQpK22f03Sn/Q0+pn+StLbZt22SNKvIuIR2ydq5tXLCUnTqqwVqafr9zjbp9r+DVe6ejykSrkGc28JEDSjXX+jSsApSYqITap8ev7fqiywe5uk02su8bXF9qGqLAb5QEQ8UPNnrSoLSbra5CMiPqfKApUrJU1K+ldJj4mIuyT9o6RvqxKw/oak1d0co4EZ50mVS3T/JulHqlzae0QzL21WNwvYZPs7db7fx1W51HejpJ8mz//TNsfyfEnft71VlUWBL4+IR9p8LoDyO1uVutxf1M6/qiw2fqW7aCcXEZOSnqtK7e8DqqwZOTW5+y2qBK6Tqlzxu7oPr6F63NWSbpl18wpVWtJNqrLu5LM1j39YlfeI1Ump3rNmfb9e3uMeK+kaVQLmH0j6D0mfavoMFIIjWl2hAAAAAIYbmWYAAACgBYJmAAAAoAWCZgAAAKAFgmYAAACgBYJmAAAAoIWO28lk4cADD4wjjzwy62EAQMfWrl37y4jYa3v1MmPOBlBkjebtQgTNRx55pNasWZP1MACgY7Znb8VbeszZAIqs0bxNeQYAAADQAkEzAAAA0AJBMwAAANACQTMAAADQAkEzAAAA0AJBMwAAANACQTMAAADQwsCCZtsft73R9p01t73U9vdtT9seH9SxAQAAgH4aZKb5MknPn3XbnZJeLOnGAR4XAAAA6KuB7QgYETfaPnLWbT+QJNuDOiwAAADQd4XYRntYTE+HNm3boR27dmt07hwdsHBUIyN8wAAAAMhaboNm2+dIOkeSjjjiiIxHM3jT06F1Gyb1+svXaP3mKR22ZEwfPWtcRx+8iMAZQO4N25wNYPjktntGRFwSEeMRMb506dKshzNwm7bt2BMwS9L6zVN6/eVrtGnbjoxHBgCtDducDWD45DZoHjY7du3eEzBXrd88pR27dmc0IgAAAFQNsuXcVZK+Lelo2+ttv9b2ctvrJZ0s6Su2vzao4xfN6Nw5OmzJ2IzbDlsyptG5czIaEQAAAKoG2T3jjxrctWpQxyyyAxaO6qNnje9V03zAwtGshwYAADD0crsQcNiMjFhHH7xIq1Yso3sGAABAzhA058jIiLV00fyshwEAAIBZWAgIAAAAtEDQDAAAALRA0AwAAAC0QNAMAAAAtEDQDAAAALRA0AwAAAC0QNAMAAAAtEDQDAAAALRA0AwAAAC0QNAMAAAAtEDQDAAAALRA0AwAAAC0QNAMAAAAtEDQDAAAALRA0AwAAAC0QNAMAAAAtEDQDAAAALRA0AwAAAC0QNAMAAAAtEDQDAAAALRA0AwAAAC0QNAMAAAAtEDQDAAAALRA0AwAAAC0MDfrAaBz09OhTdt2aMeu3RqdO0cHLBzVyIizHlamOCcAAGCQCJoLZno6tG7DpF5/+Rqt3zylw5aM6aNnjevogxcNbZDIOQEAAINGeUbBbNq2Y09wKEnrN0/p9Zev0aZtOzIeWXY4JwAAYNAImgtmx67de4LDqvWbp7Rj1+6MRpQ9zgkAABg0guaCGZ07R4ctGZtx22FLxjQ6d05GI8oe5wQAAAwaQXPBHLBwVB89a3xPkFit3z1g4WjGI8sO5wQAAAwaCwELZmTEOvrgRVq1YhmdIhKcEwAAMGgEzT3KotXZyIi1dNH8gR6jaDgnAABgkAiae0CrMyB99OQGAGSBmuYe0OoMSFf1g+rylau17MIbtHzlaq3bMKnp6ch6aACAkiNo7kGZWp1NT4cmJrfr3s0Pa2JyO0FITg37z4kPqgCArJS6PKPVZdxeL/NWW53VBs5FbHVGmUkx8HMq1wdVAECxlDbT3Ooybj8u85al1RnZu2Lg50RPbgBAdkobNLcKMPoRgNS2Olt93qlatWJZIbN+ZO+KgZ9TeT6oAgCKp7TlGa0CjE4CkGZlHN22OstTB4CylJmUHT8nenIDALJT2kxzq8u47V7mHcRq/bx1ACB7Vwz8nCqqH1QPXbKPli6aT8AMAEiFI/K/+n58fDzWrFnT0XNaLZpqd1HVxOR2LV+5eq/s3qoVy/bKMLebPe7ke6YlL5nvvIwjrzg/xWN7bUSMZz2ONHUzZwNAXjSat0tbntHqMm67l3nbLeNoJ0ivBjuStHTf+TO+b6e1qf0OnvKwo16/u0OUMcDMw88JAIBhVNryDKnxZdxqr9v7H6wErYfsP7bXZd7qY3ZH6BOvfqaefvjiPffVK+NotLDwl9u271WO8YeX3KS3Pf/olt+zkbyVd/RLP7tDlPUcAQCAbJQ6aK6nnWCq9jHPvuibOv8Ld+4JchvVkTbKSD+8fbd+uW37XsHgW6+5Q28+7ShJndemlrX1WL+6Q0xPhx546BFt275L559+jJ5++OLSnCMAAJCN0pZnNNIo4KytJ673mLdec4euPudZDS/zN+ps8NNfbtOTDlpYNxh80kH7avV5p3ZcOlC21mPVMopqVv9D37hbt92zRVLn3SHqlXhceMZxet/X1um2e7YU9hwBAIBsDV2muZ2As9FjJDVcrX/AwlFdfOYJMzobXHjGcfrQN+7WHLtup46xeXO66gBQpg0eusnqN1PvA895196hNzznSYU9RwAAIHtDl2lup9dtN/1wR0asQxYv0AUvPFb7jM7Rlqmdet/X1mli63aNjc7RR88a32uBW7etwqqtx/r1/brRr0V23WT1m2n0gad6zoatPRsAAOiP0gbNjYK6dgLOboPSxWOjeuz+C/Z63uKxUS0eG+3bhgxZb/DQzy4XrbL6nWr0gedxi8f02P0WFL57BgAAyEYp+zR30v6tUcDZbSa1jG3OZutnn+l+96zud9s6oFf0aQaAYhmqPs2tFvu10+u22364w9BHt58LEftdapJ1Fh4AAJTTwIJm2x+XdLqkjRFxbHLbYyRdLelIST+T9LKI2NzvY5etu8QgtcqM17u/m5rvRgYR5A7DBxcAAJCuQXbPuEzS82fd9nZJ34iIoyR9I/m678rUXWKQWvWsbnT/krF5+uhZ4zM6hfSaHa63CQ0AAEBeDCxojogbJf1q1s0vlPTJ5N+flPSiQRy7esm/X0FdWbXaJKXR/b+a2qGD95uvq895lm5826n6/IpTqBkGAACllnZN88ERcb8kRcT9tg8axEGoa21PqzKWZrscnnnpzTNqkA9cSDkEAAAor9xubmL7HNtrbK+ZmJjo+Plc8m+tVRlLo/t/+sttpdvCG0Bvep2zASDv0g6aN9g+RJKSvzc2emBEXBIR4xExvnTp0tQGmIbp6dDE5Hbdu/lhTUxu31NDnLZWZSz17r/4zBP0oW/cPeP7sMgSQJnnbACQ0i/P+KKksyX9Q/L3F1I+fuby1Ee4VRlLvfvnjEgTW7fP+D5lWWQ5DD22AQBAdwaWabZ9laRvSzra9nrbr1UlWH6u7bslPTf5eqi0WnyXtlZlLLPvXzxWzkWWrTqJAACA4TawTHNE/FGDu04b1DGLoOg9pPu5yDJPmd1WG+IAAIDhVsodAfOsnxuDZKUfm4fkqUxFKv6HGQAAMFi57Z5RVvSQrshbmQob4gAAgGbINKeoWo6w34K5+uy5J2uOpZGRkaFccJa3zG71w8zszPewfZgBAAD1ETSnJMtyhE5rh9OoNc5bmQob4gAAgGYoz0hJVuUInXaFSKuLRB7LVNgQBwBQRnnZH6LoyDSnJKtyhE67QqTVRYLMLgAAg5e3hfdFRqY5JVktNOs0WE8zuC97ZpdP9gCArOVt4X2RETSnJKtyhE6DdbpI9AebpQAA8iBvC++LrPRBc16yfbXlCKvPO1WrVixL5dJIp8F6HmuNu5Xlz55P9gCAPCAZ1j+lrmnOWx1PPzYF6eaYndQOl6XWOOufPZ/sAQB5QEvV/il10MzWyBWdButZBPf9lvXPPm8t9QAAw6ksybA8KHV5RifZvryUcZRZmuc460xvmcpcAADFVvaF92kpdaa53Wzfrl3TWrdxUudesTYXZRxllHa5RNaZXj7ZAwBQLqXONLeT7ZueDt334NSegFli0dYgpL0wLg+ZXj7ZAwBQHqXONLeT7du0bYc2Tm7PxaKt2dtXLxmbp81TO0uRqUy7XIJMLzDcZs+n/P4D6FWpg2ap9aK2Hbt2a9O2HZkv2qpXvvCRM0/Qh77xI11/18bCl4xkUS5RhgWNADqXdfccAOVU6vKMdozOnaNr196jC884bsal/ItfdUKql/LrlS+84VNrdcYJh+/5usglI3kolwAwHOiTDmAQSp9pbuWAhaP6i+cerX/6+jqdf/oxOmDhqA5aNF+P238s1YxEo/KFxWPzZnxd1D6/lEsASEvW3XMAlNPQB83VYO7vlh+XaTDXqHxhy9TOGV8Xuc8v5RIA0pB19xwA5TT05RlSProc1Ctf+MiZJ+jatffs+ZpyBgBojXIwAIPgiPxv4jE+Ph5r1qzJehgDV+buGcCwsr02IsazHkea8jBn0z0DQLcazdtDX56RJ/XKFyhnAIDOUQ4GoN8ozwAAAABaINPcBJf3AAAAIBE0N0RzfAAAAFRRntFAEZrjT0+HJia3697ND2ticrump/O/qBMAAKCIyDQ3kPfm+GTCAQAA0kOmuYFqc/xaaTXHbyeDXIRMOAAAQFkQNDcw6Ob4jQLjagZ5+crVWnbhDVq+crXWbZjcK3DOeyYcAACgTCjPaKC6vfaqFcv63j2jWWlFowzyqhXLZvQcZZtYAACA9JBpbmJQ22s3K61oN4PMNrEAAADpIdOcgWaBcbsZ5EFmwgEAADATmeYMNFtk2EkGeVCZcIl2dgAAALVKm2nO825+1cB4dk1zdYxZZ5BpZwcAADBTKYPmvAd9rQLjagY5K+0uRgQAABgWpSzPKEIP40GWVvSKdnYAAAAzlTJoJujrTZYbuwAAAORRKYPmXoO+YV8ERzs7AACAmUpZ09xsoV0rea+HTkMeFiMCAADkSSmD5l6CPhbBVWS9GBEAACBPSlme0QvqoQEAADBbKTPNzUosJDXt39zujnwAAAAYHqXMNDcqsdgytUPrNkxq+crVWnbhDVq+crXWbZicsdCPRXAAAIlF4QBmKmWmuVGJxdSO3S3rlcu0CC7PuyICQJ7ldVE48zqQnVIGzY1KLHZHtFWvXIZFcHmd8AGgCPK4KJx5HchWKcszGpVYLJg3PJt2FGFXxEHisiqAXuRxUfiwz+tA1kqZaW5UYiGp6/7NncjD5bM0Jvw8vM5G4yIbA6AXeVwUnsdAHhgmbQfNthdKeiQiCvHb2ajEYtD1yoMK2DoNUAc94ec5MM3jZVUAxdLLJlmDksdAHhgmDcszbI/YfoXtr9jeKOmHku63/X3b77V9VHrD7J9qMH3I/pUyjfsfnOro8n2ry/6DuHxWDVCbdf2YbdBdQPJ8mZBsDIBe1V6xXH3eqVq1YlnmSQG6OwHZapZpvkHSv0v6S0l3RsS0JNl+jKRTJf2D7VUR8anBD7O/us2StvO8QQRs3WROB90FZBCvs1/lHmRjAPRD3haFl6m7E1BEzRYC/k5EXBARd1QDZkmKiF9FxLURcYakqwc/xP7rNkvazvOqAVutXgO2bgPU6oR/6JJ9tHTR/L5OrP1+nd1k0xshGwOgrAY5rwNormHQHBE7XXGS7RfbXp7827WPSWeY/dVtENrO8wYRsA0iEO9Vv19nP8s98nhZFQAAFFvD8gzbz5O0UtLdku5Nbj5M0pNtr4iI67s9qO0/k/R6SZb00Yj4QLffqxvdXr5v53mDuHyWxwUp/X6d/S73yNtlVQAAUGzNapo/qEqJxs9qb7T9BElflfTUbg5o+1hVAuYTJe2QdJ3tr0TE3d18v250G4S2+7x+B2x5rWPr5+ukDhkAAORZs6B5rqT1dW6/V9K8Ho75VEk3RcTDkmT7PyQtl3RRD9+zYwfsO6orX3+S5tgaG52jxWOtg9Asg9eyZ07zmE0HAACoahY0f1zSrbY/I+me5LbDJb1c0qU9HPNOSX9n+wBJU5J+T9KaHr5fRxp1wFg81l5wVvbgNSt5zaYDAABIzRcC/h9Jr1Sl7vhkSack/35lcl9XIuIHki6U9HVJ10n6rqRdsx9n+xzba2yvmZiY6PZwe8lzf+Fhx6pwoLj6OWe36ocPAFlouiNgRNwl6a6kN3NExOZ+HDQiLlWSrbb996pTBhIRl0i6RJLGx8f7NmOy8UU+5XVLbgDt6decnefdRgEMt2Y7Ah5h+zPJboA3S7rF9sbktiN7Oajtg6rHkPRiSVf18v06kcf2bcOunz2aARQbVwMB5FWzzU2ulrRK0iERcVREHCXpEEn/KukzPR73Wtt3SfqSpDf2K4Pdjkb9hZeMzeNyYEZ4kwRQxdVAAHnVrDzjwIiYseNfROyW9BnbF/Ry0Ij4rV6e34t6C86WjM3T3RNbuRyYEd4kAVTRfhJAXjXLNK+1vTLZBfBxyZ+TbK+UdFtaAxyE2QvONk/tzF2mc5gWwlAyA6BqELuqAkA/NMs0nyXptZLeI+lQVTpnrJf0RfXWci538pbpHLaFMPRoBlBF+0kAedUwaI6IHZI+nPwptbxdDmxU47tqxbJS9ojmTRJALfrhA8ijZt0z5to+1/a/2b7D9neTf7/Bdi87AuZO3i4H5i3znQZ6NAMAgDxrVp5xhaQtqpRnVPsoHybpbEmfkvSHgx1aetLOdLbqSZy3zDcAAMCwaxY0PyMijp5123pJN9n+0QDHlIm0Lge2U69Mje9gsZEKAADoVLOgebPtl0q6NiKmJcn2iKSXSkqtr3LZtFOvnNca3zIEm8O2yBIAAPRHs6D55ZIulLTSdjVIXizphuQ+dKFZvXI7QWlWgWtZgs1hW2QJYG9lSAAASF+z7hk/U1K3bPsASY6IX6Y0rtJqVK88b+5Iy6A0rcC13htKWYLNYVxkCeBRZUkAAEhfs81NZHs/20+KiE21AbPt4wY/tHJq1Klj7ohbbrCSxnbT1TeU5StXa9mFN2j5ytVat2FS09PTpQg2G22kIqn0m8gARTKoDZ7anUeHaYMpAO1pmGm2/TJJH5C0MWkx9+qIuDW5+zJJzxj88MqnUb3y/Q9OtQxKB5klrc0u13tD+ey5J5eio0e9RZbvfclxetOVt2li63YyTkAODDIb3M48SjYaQD3NMs3vkHRCRBwv6TWSrrD94uS+XM8aWWcIWh2/Xk/idraS7nS76XbPQ212ef3m+sF7ROSql3W3aj+03Pi2U3XBC4/VRdet0233bMnF9ukABntVrZ15NI2regCKp9lCwDkRcb8kRcQttk+V9GXbh0nK7XWqrDME3R6/nTZznbSi62QctW8QW6Z2NswoH33wWO46eszWzgKf6oeWezc/rNdcduuM+4pYcgKUzSCvqrUzj7L2AUA9zYLmyaSe+SeSFBH3236OpH+V9OtpDK4bWS9Yqx5/6b7zdf7px2jx2Dw98OAjOni/+XrMwsbHb6fNXCet6Do5D7VvEB/55k904RnH6bxr79jrDSXvW9t2+oGFTWSAfBrk72Y78yhzA4B6mpVn/Mns+yNiUtLzJf3xIAfVi6wzBDt27dbSfefrLb97tC748l36w0tu0vlfuFP3b3mkZZlIO1tJt7vddCfnofZy5W33bNH7vrZOF7zwWN34tlO1asWy1Ov4ui2v6fSSat62TwdQMejfzVbzKHMDgHqaZZrviIi9opWI2Cnp05Jk2/Uek6WsMwSjc+fozacdtSdTK1WCt3M/tTbV9mydnIfZlysntm7XY/dfoMMWj6VeftFLeU2nH5jyuokMMOyy/t3M+vgA8qlZpvkG239q+4jaG22P2v4ftj8p6ezBDq9zWWcIDlg4qiccuDDzerhOzkPtG8Tq87LJLlf1sgCn04WSUvuZewDp6uZ3s5+LwJkbAMzWLNNcLcO4yvYTJG2RtEDSHEnXS/qniLh98EPsTNYZgpERa5/52dfDdXoe8lKv3Et5TScLJQeJ3caA9GW9CBxA+TXbEfARSStV2UZ7nqQDJU1FxJa0BtetrAPAAxfOz0XwlvV56EY7ZSWNgtKsPzBVx8YbN5C+rBeBAyi/ZpnmPZI65vsHPJbSyEPwVlStssWtgtKsPyjwxg1kI+tF4ADKr62gGZ3LOngrqlYfOPIelPLGDWQj60XgAMqv2UJAIBPNFuDkPSjtZjEigN5lvQgcQPk1zTTbfpGkJ0v6XkR8LZ0hIQ1FXayW92xSXhYjAsOGsjgAg9YwaLa9UpWd//5L0gW2T4yIC1Ib2YAVNWjsh14Wq2V93vIelPLGDWSHsrj+y3rOB/KkWab52ZKeFhG7be8j6T8llSJoHtYOB9XJb2rnLj3w4CNauu98rd881XZdcB7OWxGCUt64AZRBHuZ8IE+a1TTviIjdkhQRD/KBf9cAAB8PSURBVEsqzW9ILxtoFFV18lu+crWefdE3df4X7tRbfvdoPf3wxZLaqwvOy3lj0wEAGLys5/x+blYD9EOzTPOv2b4j+bclPSn52pIiIo4b+OgGpNPFZGW4PFVv8jvv2jt0/unH6Nwr1rZVF9zovE3t3K17Nz9c2HMDANhblguvyXIjj5oFzU9NbRQpq7eY7HnHHCTbewV/ZfnFbTT5LR6b13ZdcKNFeD/ZuFWvuezWwp4bAMDeslx4nff2ohhODcszIuLnEfFzSQ9KOij5s6Xm9sKa3ZroecccpDef9hS97OJva9mFN2j5ytVat2FyT4Y5DyUJvWrUCu2wJWNatWJZW4FuvZZO733JcfrQN+6WVNxzAwDYW5Zt/PLeXhTDqVn3jFFJl0h6kaSfqlKW8XjbqyS9ISIKGxnNXkxmWy+7+Nt1P9GW5Re3UdeJQ/YfazsrPPu8SdKbrrxNt93z6M7qRTw3AIC9ZbnwOu/tRTGcmpVn/LWkeZIOj4hJSbK9SNK/SDo/+VNYtR0O7t38cMPAuCy/uP2a/GrP28Tkdk1s3T7j/iKeGwBAfVl1A8p7e1EMp2ZB84slnZh0zpAkRcSk7RWSblLBg+ZazQLjMv3i9nvyK9O5QefKsEAWQD4Vob0ohk+zoHm6NmCuioittkvV96VZ8McvbmOcm+FVlgWyAPKLnvfIm2ZBc9heovr9macHNJ5MVIO/z684RY/snNYcS2Ojc2bcv3TR/D2ZtfsfnCJATDCpDSdWtgMAhk2zoHl/SWtVP2guVaa5atPWHQ0zZ2TW+o/L+8VVlgWyAAC0q1nLuSMj4okR8YQ6f56Y5iDT0Kq1XFlazw1SJ7s31e5QOLvNH/KvUQtDFoECAMqqYdBse47tfWu+fpbtZyd/FqUzvPS0ypyRWWuuURD8q231g2g+hBRblv1bAQDIQrPyjAslbZR0UfL1VZLulLRA0ncknTfYoaWrVWu5vLWey1tpQ6Mg+IIXHlt3t0A+hBQbi0ABAMOmYaZZ0mmS3l/z9ZaI+ANJz5O0bKCjykCrzFmeMmt5LG1oFATvkyyonJ1J5vJ+8VUXgR66ZB8tXTSfgBkAUGrNMs0jEbGr5uvzJCkiorZsoyxaZc7ylFnLY+eCRpn4LVM793xdm0mmx3NrebuaAADAMGsWNI/aXlTdDTAirpck2/urUqJROiMj1gELR/cEKpu27dgrcM5DO608ljYsGZunK193kjZObtembTt07dp79JplT9BF163b85jaTHKePoTkEd1aAADIl2ZB80clXW37DRHxC0my/XhJH07uK51+ByqDyhTmsb767omtM87bxa86QfstmLtnm+16meS8fAjJozxeTQDKgqs4ALrRMGiOiPfbfljSt2wvVKU38zZJ/xARH05rgGnqZ6AyyExh3kob6p23c69Yq8+vOIVMcpfyeDUBKAOu4nSHDxpA80yzIuIjkj6S1DC7WqpRVv0MVAaZKcxbaUOj87Zz17QOXbJPJmMqurxdTQDKgqs4neODBlDRrHvGHhGxtewBs9Tfjg6DzhTmqXMBnTD6L0/dWoAy4SpO5+irD1S0FTQPi34GKnkJJDvZpa9bBHj9V3s1YfV5p2rVimVkdYA+yMvcXCR80AAqmpZnDJt+lj3koe44rUtqeSsXKQsWSgL9l4e5uWgoFwMqHNE882j7xXVuflDS9yJi40BGNcv4+HisWbMmjUP1VaOFE50uqOh2AcbE5HYtX7l6r4mO2j0gPbbXRsR41uNIU97nbBa1dYaaZgybRvN2O5nm10o6WdINydfPkXSTpKfY/puIuKJvoyyZepnCTiefXiYrLqkBwN64itMZriYCFe3UNE9LempEnBERZ0g6RtJ2SScp2SUQ7et0QUUvCzAGXbuXRr00ACB7eVp8DmSlnaD5yIjYUPP1RklPiYhfSdrZ4DlooNPsby/Z4kEu0KtmwJevXK1lF96g5StXa92GSQJnAABQSu2UZ/yn7S9L+lzy9Usk3ZhseLJlYCMrqU4XVPSyAGOQl9TodQoAAIZJO5nmN0r6hKTjJT1d0iclvTEitkXEqd0c1PZf2P6+7TttX2V7QTffp4g6yf5OT4fmjEgXn3lC19niQV1So14aAAAMk5aZ5ogI29+StEOVrbRviVYtN5qwfaikN0s6JiKmbH9W0sslXdbt9yySdrO/tQsAl+47Xxe88Fg94cCF2mf+HB24MPt6MloQAQCAYdIy02z7ZZJuUaUs42WSbrb9kh6PO1fSmO25kvaRdF+P369Q2sn+1pY/3HbPFr3mslt15qU3y3LmAbPEhiYAAGC4tFPT/FeSnlntyWx7qaR/l3RNNweMiHttv0/SLyRNSbo+Iq6f/Tjb50g6R5KOOOKIbg5VaHkvf6AFEYBawz5nAyi/dmqaR2ZtYrKpzefVZXuJpBdKeoKkx0laaPvM2Y+LiEsiYjwixpcuXdrt4QqrCFu90oIIQNWwz9kAyq+d4Pc621+z/Wrbr5b0FUlf7eGYvyPppxExERE7JX1e0ik9fL9SovwBAAAgP9pZCPhW22dIWibJki6JiFU9HPMXkp5lex9VyjNOk5Tf/VYzQvkDAABAfrRT06yIuFbStf04YETcbPsaSd+RtEvSbZIu6cf3Lhu2egUAAMiHhkGz7UlVWsztdZcqnej26/agEfEuSe/q9vkAAABAmhoGzRGxKM2BoBimp0Obtu2gZAQAAAyVtsozAGnmhivrN0/tWZx49MGLCJwBAECpdd06DsOndsMVqdI3+vWXr9GmbTv6epzp6dDE5Hbdu/lhTUxu1/R01xtQAkAqmLeA8iPTjLalseEK2WwARcO8BQwHMs0FkYcsRhobrqSVza6Vh3MLoLiymLcApI9Mc040W2CXlyxGdcOV2ePo54YraW8fnpdzC6C40p63AGSDoDkHWgVujbIYq1YsS7WPcxobrlSz2bVvQIPcPjwv5xZAcaU9bwHIBuUZOdDq0l6WWYzZpQuStHTRfB26ZB8tXTS/79nYtLcPJ0MEoFdpz1sAskGmOQdaBW5ZZTGyKF1Ie/twMkQAepX2vAUgG2Sac6DVArusshhZLW6pbh8+qGx2LTJEAPohzXkLQDbINOdAqwV2WWUxhqF0gQwRAABoB0FzDrQTuFWzGGkaltKFLM4tAAAoFsozciKPl/YoXQAAAEUyyL0XyDSjIUoXAABAUQy6gQGZZjSVxww4AADAbINuYECmGZlqthMiAABAuwbdwICgGZlhC2sAANAvg25gQHkGMpNVH2gAGORiIQDZGHQDAzLNSM3sUoxh6AMNIH+4ygWU06AbGBA0IxX13qSufN1JQ9EHGkB3ulnz0M5zGl3lWrViGT3bG2D9CYpikHsvEDT3Qdkmk0G8nnpvUn/7lbt08atO0LlXrK27EyI6V7b/ixhe3WSD230OV7k6Q2YeqKCmuUfVyWT5ytVaduENWr5ytdZtmCxsfdygXk+9N6nr79qoAxeOatWKZVp93qlatWIZk3APyvZ/EcOtmzUP7T6nulioFle5GmP9CVBB0Nyjsk0mg3o9jd6kRkZGeuoDzWKeR5Xt/yKGWzfZ4Haf02ix0JKxecwndZCZByooz+hR2SaTQb2e6pvU7Mt7vZRicMlwprL9X8Rw66Z1VLvPqbdYaMnYPN09sZX5pI5Bt/HqF8rTMGhkmntUtst8g3o9tW9S/SrFILM6U9n+L2K4ddM6qpPnzN7tdPPUTuaTBgbdxqsfKE9DGsg092gQGdQsDfL19HtFK5nVmcr2fxHDpV6WsF7rKEmamNxeN5vYS7sp5pPGBt3Gqx/oiII0EDT3qAiTSSeK9HqKcskwLUX62QG1mpVa1QY89R53+R+fqH0XzNXOXdN7/s93EyQxnzQ3yDZe/cCHHqSB8ow+mH2Zr+hBSlFeTxEuGaatKD87oFa7pVazH7d03/na8NAjevHK/+r5kjzzSbFRnoY0kGlGYZFZBcqh3Szh7Me94TlP0luvuaMvl+SZT4qN8jSkgaC5YFgdPFPeLxkCaK3d0ojZj1s8Nq+vl+SZT4qLDz1IA+UZBcLq4O7RzxnIr0alEXNGNON3dvbjHt6xm0vy2IPyNAyaI/IfPIyPj8eaNWuyHkbmJia3a/nK1XtlY1gd3Bz9nNPDlZC92V4bEeNZjyNN3czZtf935s0d0dZHdumsj9+y1++spD2PGxudow0Pbed3G0BfNZq3Kc8oEFYHd4dWROngwwl6UVsaMTG5fU/ALO39O1v7e7t4bJRL8gBSQXlGH6R16Z/Vwd3hw0Y62GwG/dLJ7yyX5AGkZaiD5n4Eu2nWGdMSqTt82EgHH07QL/zOAsijoQ2a+xXsppldG8RW1MOADxvpINBBv/A7CyCPhramuV91rmln12iJ1DlaEaWDPqnol+rv7BfftExTO3ZrZESKsO5/cIrfXwCZGdqguV/BLluvFgMfNgaPDyfotw0Pbdc/fX2dzj7lCTrv2jtYYAogU0NbntGvS8lcRgQexaIs9Ev1auAZJxy+J2CWWGAKIDtDm2nu16VksmsA0H/Vq4H93vUPALo1tEFzP4NdLv0DQH9VrwZumdpJCRyAXBja8gwp+0vJbO0MpIfft2KpXg28du09uvCM4yiBA5C5oc00Z43d04D08PtWPNWrgX+3/DhNT0/rs+eerIigBA5AZoY605wldk8D0sPvWzFVrwYevP+YHrd4jAWmADJF0JwRdk8D0sPvGwCgVwTNGWH3NCA9/L6hU9TAA5iNoDkj9HcG0sPvGzpRrYFfvnK1ll14g5avXK11GyYJnIEhx0LAjNDfGUgPv2/oRKMa+FUrltFeFBhiBM0Zor8zkB5+39AuauAB1EN5BgAANaiBB1APQTMAIFeyXoRHDTyAeijPAADkRh42oqEGHkA9qWeabR9t+/aaPw/Z/vO0xwEAyJ+8bERTrYFnQxUAValnmiNinaTjJcn2HEn3SlqV9jgAAPnDIjwAeZV1TfNpkn4SET/PeBwAgBxgER6AvMo6aH65pKvq3WH7HNtrbK+ZmJhIeVgAgE70a85mER6AvHJENjsc2R6VdJ+kX4+IDc0eOz4+HmvWrElnYADQR7bXRsR41uNIU69z9vR0aNO2HSzCQ9v4P4N+ajRvZ9k94wWSvtMqYAYADJdBbURDYFVOeei4guGQZXnGH6lBaQYAAP3s11wNrJavXK1lF96g5StXa92GydR7QKP/8tJxBeWXSdBsex9Jz5X0+SyODwDIt34HuQRW5UXHFaQlk6A5Ih6OiAMi4sEsjg8AyJ/azPIDDz3S1yCXwKq86LiCtGTdPQMAAE1Ph362aZvuvPdBrd88pe27dmvpvjPrmnsJcgmsyouOK0gL22gDADK3ZWqHNjz0iM7/wp17FnO99yXH6aLr1um2e7ZI6i3IrQZWsxeLEVgVH9ueIy0EzQCAzE3t2K23XnPHjHKMt15zhy544bF6zWW39hzkEliV26A6rgC1CJoBAJnbHVG35vhJSxdq9Xmn9iXIJbDqD1r3YVgRNAMAMrdgXqXmuDZwPmzJmBaMztFBixZkODLUoicyhhkLAQEAmTtw4fy6i7kOXFjJDHfbs7mfvZ5B6z4MNzLNAIDMNas57ja7SVa0/2jdh2FGphkAkAvVmuNDl+yjpYvm7wlsu81ukhXtP1r3YZgRNAMAcq3b7CZZ0f6jJzKGGeUZAIBcq2Y3Zy8SHBudo4nJ7Q27ODR6Xr+zosPUTYLWfRhmZJoBALlWL7t5+R+fqA0Pbdfylau17MIbtHzlaq3bMDljoV8aWdFq3XSzcZRNozIaoOwckf9f7PHx8VizZk3Ww0CODFNmB8Vme21EjGc9jjQNYs6e/TsfCr145X/tlUVetWLZjF7Mg54rJiYrgXurcQAojkbzNuUZKBxWxCNNfEBLT7NzPXtjkns3P1y3Xnlq527du/nhGc8fZPBK3TQwPCjPQOGwIh5pGcZL71np9Fw36uKw4cFHdOd9D+nnm7Zp/eaHtWvX9EDHTTcJYHgQNKNwyOwgLXxAS0+n57pevfK/vOLpmo7QBV++Sy/5yLf1io/drHUbB/shh24SwPCgPAOFk9aKeIAPaOnp9FzP7uIgST/95Ta9/fPfmxF4n3vF2oHWF9NNAhgeZJpROGR2kBYuvaenm3Nd28VhdO4cLZg3J5MPOXSTAIYDQTMKpzazs/q8U7VqxTIWAWIg+ICWnl7P9QELR3XQovl8yAEwMJRnoJAGvSIekLj0nqbquf7im5Zpasdu7Y7QgnntB7sjI9bj9h/Txa86QedesXZGZx0+5ADoB4JmAGiCD2jp2vDQ9q7bSc6dO6KnPnY/PuQAGAjKMwAAudCPbiXUFwMYFDLNAIBc6KZbCZvPAEgLQTMAIBc6bSfJ7qAA0kR5BgAgFzrtoMHmMwDSRKYZAJALnXYrKdvmM5SaAPlG0AwAyI1OupWUaXdQSk2A/KM8AwBQSGXafKaTUpPp6dDE5Hbdu/lhTUxu1/R0pD1cYCiRaQYAFFKZNp9pt9SEjDSQHTLNAIDCKktf5mqpSa16pSYsfgSyQ9AMAEAbBlkW0W6pSdkWPwJFQnkGAAAtDLosot1SkzItfgSKhkwzAAAtpFEW0U6pSZkWPwJFQ6YZAIAW8lIWUabFj0DREDQDANBCnsoiOullDaB/KM8AAKAFyiIAkGkGAKAFyiIAEDQDANAGyiKA4UbQDAAYCtPToU3bdpApBtAVgmYAQOmx/TSAXrEQEABQemw/DaBXBM0AgNLLS59lAMVF0AwAKL1qn+VabD8NoBMEzQCA0qPPMoBesRAQAFAKzbpj0GcZQK8ImgEAhddOdwz6LAPoBeUZAIDCozsGgEEjaAYAFB7dMQAMGkEzAKDw6I4BYNAImgEAhUd3DACDxkJAAEDh0R0DwKARNAMASoHuGAAGifIMAAAAoIVMgmbbi21fY/uHtn9g++QsxgEAAAC0I6vyjA9Kui4iXmJ7VNI+GY0DAAAAaCn1oNn2fpKeLenVkhQROyTRfR4AAAC5lUV5xhMlTUj6hO3bbH/M9sLZD7J9ju01ttdMTEykP0oAQNuYswGUXRZB81xJz5D04Yh4uqRtkt4++0ERcUlEjEfE+NKlS9MeIwCgA8zZAMoui6B5vaT1EXFz8vU1qgTRAAAAQC6lHjRHxAOS7rF9dHLTaZLuSnscAAAAQLuy6p7xp5I+nXTO+G9Jr8loHAAAAEBLmQTNEXG7pPEsjg0AAAB0ih0BAQAAgBYImgEAAIAWCJoBAACAFhwRWY+hJdsTkn7exVMPlPTLPg8nS7yefOP15FtWr+fxETFUjYvbnLOL+v+riONmzOko4pilYo570GOuO28XImjulu01EVGaBYe8nnzj9eRb2V5P0RX151HEcTPmdBRxzFIxx53VmCnPAAAAAFogaAYAAABaKHvQfEnWA+gzXk++8XryrWyvp+iK+vMo4rgZczqKOGapmOPOZMylrmkGAAAA+qHsmWYAAACgZ6UNmm0/3/Y62z+2/fasx9ML2x+3vdH2nVmPpR9sH277Bts/sP1923+W9Zh6YXuB7Vtsfzd5Pe/Jekz9YHuO7dtsfznrsfTK9s9sf8/27bbXZD2eYVfE+blo83BR59kiz6dFmzOLOi/aXmz7Gts/TP5/n5zasctYnmF7jqQfSXqupPWSbpX0RxFxV6YD65LtZ0vaKunyiDg26/H0yvYhkg6JiO/YXiRpraQXFfjnY0kLI2Kr7XmSviXpzyLipoyH1hPb/0vSuKT9IuL0rMfTC9s/kzQeEUXrRVo6RZ2fizYPF3WeLfJ8WrQ5s6jzou1PSvrPiPiY7VFJ+0TEljSOXdZM84mSfhwR/x0ROyR9RtILMx5T1yLiRkm/ynoc/RIR90fEd5J/T0r6gaRDsx1V96Jia/LlvORPoT+N2j5M0u9L+ljWY0HpFHJ+Lto8XNR5tqjzKXNmOmzvJ+nZki6VpIjYkVbALJU3aD5U0j01X69XASaLYWT7SElPl3RztiPpTXJZ7nZJGyV9PSIK/XokfUDS2yRNZz2QPglJ19tea/ucrAcz5JifU1a0ebag82kR58wizotPlDQh6RNJKczHbC9M6+BlDZpd57bcf1IdNrb3lXStpD+PiIeyHk8vImJ3RBwv6TBJJ9rO/eXbRmyfLmljRKzNeix9tCwiniHpBZLemFxqRzaYn1NUxHm2aPNpgefMIs6LcyU9Q9KHI+LpkrZJSm1dRFmD5vWSDq/5+jBJ92U0FtSR1KpdK+nTEfH5rMfTL8llom9Ken7GQ+nFMkn/M6l3+4yk/2H7U9kOqTcRcV/y90ZJq1QpEUA2mJ9TUvR5tkDzaSHnzILOi+slra+5+nCNKkF0KsoaNN8q6SjbT0iKxF8u6YsZjwmJZKHHpZJ+EBHvz3o8vbK91Pbi5N9jkn5H0g+zHVX3IuIvI+KwiDhSld+d/xcRZ2Y8rK7ZXpgshFJyGe95kgrRAaGkmJ9TUNR5tojzaRHnzKLOixHxgKR7bB+d3HSapNQWt85N60Bpiohdtt8k6WuS5kj6eER8P+Nhdc32VZKeI+lA2+slvSsiLs12VD1ZJulVkr6X1K1J0jsi4qsZjqkXh0j6ZNIVYETSZyOiEC2HhsTBklZVYgjNlXRlRFyX7ZCGV1Hn5wLOw0WdZ5lP01HkefFPJX06+dD935Jek9aBS9lyDgAAAOinspZnAAAAAH1D0AwAAAC0QNAMAAAAtEDQDAAAALRA0AwAAAC0QNA8xGwfYPv25M8Dtu+t+Xq0z8d6o+1XdvD4J9ueSsbyA9uX2c6sRaLtv7X953k/pu1v2T5+UGMCkC3m7fYxb6PfStmnGe2JiE2Sjpck2++WtDUi3tfu823PiYjdNV/PjYhdDY71L10McV1EHJ9Mut+QdIakq7v4PgBQCszbQHbINKMu22fbviXJGKy0PWJ7ru0tySfpWySdaHu97fNtr5a03PYbbN9q+7u2P5fs6DTj03fyqfofku+/zvYpzcaSTOi3Sjo0ef7rbH+gZqzX2f7N5N/n2v6R7W/a/lj1cbaPsn1zcswLbG+pef7bk9vvsP3OmtvfmYzv65KOqrm97viT8/P+mu/1uuT2Q5Pn3G77TtunJI+9wvb3ktve3OLn0eiY+yTn+Q7bn5G0oOY5L7D9bdvfsX21KztALU7Oz5OTx3zOdmqN4QEMDvM28zYGi6AZe7F9rKTlkk6JiONVuSLx8uTu/SV9JyJOjIhvJ7dti4hlEfE5SZ+LiGdGxNMk/UTSqxsdJiJOlPRWSe9s8JjqeMYkPVOVHcSaPe5wSW+XdJIqW4IeU3P3/5X0vuSYG2qe83uSjkiec7ykU5LJ8URVMiTHS3qJpBPbGP85kjYmtz9T0httHyHpTElfSs7l0yTdIekESQdGxG9ExLGSLm/22poc802SNkfEcZIulPT05HUdlJyL0yLiGckx/ywitkh6s6TLXLnsuk9EfKKNYwPIMeZt5m0MHuUZqOd3VJk81riyxeaYpHuS+3ZIWjXr8bWX3o6z/TeSFktaJKnR9qefT/5eK+nIBo852pXtX58i6ao2tto9SdL/i4jNkmT7GlUm1up9v5f8+0pJf5v8+3mSXiDptuTrfZPjHSjp2oiYkjRl+0ttjP95kp5qu/aN6ihVsi0X214g6V8j4ru2f5y8vg9K+qqk61u8tkbHfLakiyQpIm6zXT1Hp6jy5vNfyc9wVNK3ksddZ/tlkj4o6bg2jgsg/5i3mbcxYATNqMeSPh4R58+4sVKjNhV7772+rebfl0t6QUTcmVzmelaDY2xP/t6txv8Pq7Vxj5N0o+3fi4ivStqlmVdJqpe23PRV1WdJfxsRl8640X6LpGZ7zNcbvyWtiIhv7HUQ+zmSfl/Sp23/n4j4tO3jVJn436xKduScFmNtdM7qjdOSrouIV9UZyxxJvyZpStISSfe1OC6A/GPeZt7GgFGegXr+XdLLbB8o7VmtfUSL51QtlPSA7XmSXtGPwUTEfZL+MvkjST+T9HRXHKnKJTNJulnSqUn91zxJL675NreoculSevSSpVS5dPha2wslyfZhyeu+UdKLbS+wvZ+k09sY6tckrUjepGT7aNtjth8v6YGIuETSZcnYl6py2e5zkt4l6RntnY293Cjplcnxnibp15Pb/0vSb9t+YnLfQtvV+r63SLpd0lmSPuEMV7cD6BvmbeZtDBgnHXuJiO/Zfo+kf7c9ImmnpDeovU+271RlovuFpDtVs8ChR9dIerftkyX9h6R7JX0vOcbtybh/Yfu9yfHvlfR9SQ8mz3+zpCtsn6fKZbUHk+d81favSbopuRw2KekVEXGL7VWSvqvKZH9jG2O8WJXLircn32ujpBdKOk3S/7K9U9JWVWrlDpd0qSsPDEnndXda9M+SPmn7DknfkbQmeV0bbL9W0tV+tA3VO5KJ9mxJJ0bEVts3qfKmdkGXxweQA8zbzNsYPO99xQYoLtv7JpPKPElfkPThiPhSkpF4OCLC9pmSlkfEGdmOFgDAvI2iINOMsrkgqUNbIOk6Pbqg5ZmSPpBkYDZLol0PAOQD8zYKgUwzAAAA0AILAQEAAIAWCJoBAACAFgiaAQAAgBYImgEAAIAWCJoBAACAFgiaAQAAgBb+P9auI8HBM/tHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6), sharey=True)\n",
    "african_nations = df[df[\"cont_africa\"] == 1]\n",
    "non_african_nations = df[df[\"cont_africa\"] == 0]\n",
    "sns.scatterplot(non_african_nations[\"rugged\"], \n",
    "            non_african_nations[\"rgdppc_2000\"], \n",
    "            ax=ax[0])\n",
    "ax[0].set(xlabel=\"Terrain Ruggedness Index\",\n",
    "          ylabel=\"log GDP (2000)\",\n",
    "          title=\"Non African Nations\")\n",
    "sns.scatterplot(african_nations[\"rugged\"], \n",
    "                african_nations[\"rgdppc_2000\"], \n",
    "                ax=ax[1])\n",
    "ax[1].set(xlabel=\"Terrain Ruggedness Index\",\n",
    "          ylabel=\"log GDP (2000)\",\n",
    "          title=\"African Nations\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": false
   },
   "source": [
    "## 线性回归\n",
    "\n",
    "我们想根据数据集中的两个特征预测一个国家的人均GDP的对数， 这两个特征包括 whether the nation is in Africa, and its Terrain Ruggedness Index. \n",
    "\n",
    "We will create a trivial class called `PyroModule[nn.Linear]` that subclasses [PyroModule](http://docs.pyro.ai/en/dev/nn.html#module-pyro.nn.module) and `torch.nn.Linear`. `PyroModule` 非常类似于 PyTorch's `nn.Module`, but additionally supports [Pyro primitives](http://docs.pyro.ai/en/dev/primitives.html#primitives) as attributes that can be modified by Pyro's [effect handlers](http://pyro.ai/examples/effect_handlers.html) (see the [next section](#Model) on how we can have module attributes that are `pyro.sample` primitives). Some general notes:\n",
    "\n",
    "- PyTorch模块中可学习的参数是 `nn.Parameter` 的实例, in this case the `weight` and `bias` parameters of the `nn.Linear` class. When declared inside a `PyroModule` as attributes, these are automatically registered in Pyro's param store. While this model does not require us to constrain the value of these parameters during optimization, this can also be easily achieved in `PyroModule` using the [PyroParam](http://docs.pyro.ai/en/dev/nn.html#pyro.nn.module.PyroParam) statement. \n",
    "- 请注意，虽然 `PyroModule[nn.Linear]` 的 `forward` 方法继承自 `nn.Linear`, 也可以轻松重写. e.g. in the case of logistic regression, we apply a sigmoid transformation to the linear predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from pyro.nn import PyroModule\n",
    "\n",
    "assert issubclass(PyroModule[nn.Linear], nn.Linear)\n",
    "assert issubclass(PyroModule[nn.Linear], PyroModule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Training with PyTorch Optimizers\n",
    "\n",
    "Note that in addition to the two features `rugged` and `cont_africa`, we also include an interaction term in our model, which lets us separately model the effect of ruggedness on the GDP for nations within and outside Africa.\n",
    "\n",
    "我们使用均方误差（MSE）作为损失 and Adam as our optimizer from the `torch.optim` module. We would like to optimize the parameters of our model, namely the `weight` and `bias` parameters of the network, which corresponds to our regression coefficents and the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Dataset: Add a feature to capture the interaction between \"cont_africa\" and \"rugged\"\n",
    "df[\"cont_africa_x_rugged\"] = df[\"cont_africa\"] * df[\"rugged\"]\n",
    "data = torch.tensor(df[[\"cont_africa\", \"rugged\", \"cont_africa_x_rugged\", \"rgdppc_2000\"]].values,\n",
    "                        dtype=torch.float)\n",
    "x_data, y_data = data[:, :-1], data[:, -1]\n",
    "\n",
    "# Regression model\n",
    "linear_reg_model = PyroModule[nn.Linear](3, 1)\n",
    "\n",
    "# Define loss and optimize\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "optim = torch.optim.Adam(linear_reg_model.parameters(), lr=0.05)\n",
    "num_iterations = 1500 if not smoke_test else 2\n",
    "\n",
    "def train():\n",
    "    # run the model forward on the data\n",
    "    y_pred = linear_reg_model(x_data).squeeze(-1)\n",
    "    # calculate the mse loss\n",
    "    loss = loss_fn(y_pred, y_data)\n",
    "    # initialize gradients to zero\n",
    "    optim.zero_grad()\n",
    "    # backpropagate\n",
    "    loss.backward()\n",
    "    # take a gradient step\n",
    "    optim.step()\n",
    "    return loss\n",
    "\n",
    "for j in range(num_iterations):\n",
    "    loss = train()\n",
    "    if (j + 1) % 50 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss.item()))\n",
    "\n",
    "            \n",
    "# Inspect learned parameters\n",
    "print(\"Learned parameters:\")\n",
    "for name, param in linear_reg_model.named_parameters():\n",
    "    print(name, param.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Plotting the Regression Fit\n",
    "\n",
    "Let us plot the regression fit for our model, separately for countries outside and within Africa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fit = df.copy()\n",
    "fit[\"mean\"] = linear_reg_model(x_data).detach().cpu().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6), sharey=True)\n",
    "african_nations = fit[fit[\"cont_africa\"] == 1]\n",
    "non_african_nations = fit[fit[\"cont_africa\"] == 0]\n",
    "fig.suptitle(\"Regression Fit\", fontsize=16)\n",
    "ax[0].plot(non_african_nations[\"rugged\"], non_african_nations[\"rgdppc_2000\"], \"o\")\n",
    "ax[0].plot(non_african_nations[\"rugged\"], non_african_nations[\"mean\"], linewidth=2)\n",
    "ax[0].set(xlabel=\"Terrain Ruggedness Index\",\n",
    "          ylabel=\"log GDP (2000)\",\n",
    "          title=\"Non African Nations\")\n",
    "ax[1].plot(african_nations[\"rugged\"], african_nations[\"rgdppc_2000\"], \"o\")\n",
    "ax[1].plot(african_nations[\"rugged\"], african_nations[\"mean\"], linewidth=2)\n",
    "ax[1].set(xlabel=\"Terrain Ruggedness Index\",\n",
    "          ylabel=\"log GDP (2000)\",\n",
    "          title=\"African Nations\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We notice that the relationship between terrain ruggedness has an inverse relationship with GDP for non-African nations, but it positively affects the GDP for African nations. It is however unclear how robust this trend is. In particular, we would like to understand how the regression fit would vary due to parameter uncertainty. To address this, we will build a simple bayesian model for linear regression. [Bayesian modeling](http://mlg.eng.cam.ac.uk/zoubin/papers/NatureReprint15.pdf) offers a systematic framework for reasoning about model uncertainty. Instead of just learning point estimates, we're going to learn a _distribution_ over parameters that are consistent with the observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true
   },
   "source": [
    "## 使用 SVI 做贝叶斯回归\n",
    "\n",
    "Bayesian Regression with Pyro's Stochastic Variational Inference (SVI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true
   },
   "source": [
    "### Model\n",
    "\n",
    "In order to make our linear regression Bayesian, we need to put priors on the parameters $w$ and $b$. These are distributions that represent our prior belief about reasonable values for $w$ and $b$ (before observing any data).\n",
    "\n",
    "Making a Bayesian model for linear regression is very intuitive using `PyroModule` as earlier. Note the following:\n",
    "\n",
    " - The `BayesianRegression` module internally uses the same `PyroModule[nn.Linear]` module. However, note that we replace the `weight` and the `bias` of the this module with `PyroSample` statements. These statements allow us to place a prior over the `weight` and `bias` parameters, instead of treating them as fixed learnable parameters. For the bias component, we set a reasonably wide prior since it is likely to be substantially above 0.\n",
    " - The `BayesianRegression.forward` method specifies the generative process. We generate the mean value of the response by calling the `linear` module (which, as you saw, samples the `weight` and `bias` parameters from the prior and returns a value for the mean response). Finally we use the `obs` argument to the `pyro.sample` statement to condition on the observed data `y_data` with a learned observation noise `sigma`. The model returns the regression line given by the variable `mean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from pyro.nn import PyroSample\n",
    "\n",
    "\n",
    "class BayesianRegression(PyroModule):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.linear = PyroModule[nn.Linear](in_features, out_features)\n",
    "        self.linear.weight = PyroSample(dist.Normal(0., 1.).expand([out_features, in_features]).to_event(2))\n",
    "        self.linear.bias = PyroSample(dist.Normal(0., 10.).expand([out_features]).to_event(1))\n",
    "        \n",
    "    def forward(self, x, y=None):\n",
    "        sigma = pyro.sample(\"sigma\", dist.Uniform(0., 10.))\n",
    "        mean = self.linear(x).squeeze(-1)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            obs = pyro.sample(\"obs\", dist.Normal(mean, sigma), obs=y)\n",
    "        return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Using an AutoGuide\n",
    "\n",
    "In order to do inference, i.e. learn the posterior distribution over our unobserved parameters, we will use Stochastic Variational Inference (SVI). The guide determines a family of distributions, and `SVI` aims to find an approximate posterior distribution from this family that has the lowest KL divergence from the true posterior. \n",
    "\n",
    "Users can write arbitrarily flexible custom guides in Pyro, but in this tutorial, we will restrict ourselves to Pyro's [autoguide library](http://docs.pyro.ai/en/dev/infer.autoguide.html). In the next [tutorial](bayesian_regression_ii.ipynb), we will explore how to write guides by hand.\n",
    "\n",
    "To begin with, we will use the `AutoDiagonalNormal` guide that models the distribution of unobserved parameters in the model as a Gaussian with diagonal covariance, i.e. it assumes that there is no correlation amongst the latent variables (quite a strong modeling assumption as we shall see in [Part II](bayesian_regression_ii.ipynb)). Under the hood, this defines a `guide` that uses a `Normal` distribution with learnable parameters corresponding to each `sample` statement in the model. e.g. in our case, this distribution should have a size of `(5,)` correspoding to the 3 regression coefficients for each of the terms, and 1 component contributed each by the intercept term and `sigma` in the model. \n",
    "\n",
    "Autoguide also supports learning MAP estimates with `AutoDelta` or composing guides with `AutoGuideList` (see the [docs](http://docs.pyro.ai/en/dev/infer.autoguide.html) for more information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "\n",
    "model = BayesianRegression(3, 1)\n",
    "guide = AutoDiagonalNormal(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Optimizing the Evidence Lower Bound\n",
    "\n",
    "We will use stochastic variational inference (SVI) (for an introduction to SVI, see [SVI Part I](svi_part_i.ipynb)) for doing inference. Just like in the non-Bayesian linear regression model, each iteration of our training loop will take a gradient step, with the difference that in this case, we'll use the Evidence Lower Bound (ELBO) objective instead of the MSE loss by constructing a `Trace_ELBO` object that we pass to `SVI`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from pyro.infer import SVI, Trace_ELBO\n",
    "\n",
    "\n",
    "adam = pyro.optim.Adam({\"lr\": 0.03})\n",
    "svi = SVI(model, guide, adam, loss=Trace_ELBO())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Note that we use the `Adam` optimizer from Pyro's `optim` module and not the `torch.optim` module as earlier. Here `Adam` is a thin wrapper around `torch.optim.Adam` (see [here](svi_part_i.ipynb#Optimizers) for a discussion). Optimizers in `pyro.optim` are used to optimize and update parameter values in Pyro's parameter store. In particular, you will notice that we do not need to pass in learnable parameters to the optimizer since that is determined by the guide code and happens behind the scenes within the `SVI` class automatically. To take an ELBO gradient step we simply call the step method of SVI. The data argument we pass to `SVI.step` will be passed to both `model()` and `guide()`. The complete training loop is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pyro.clear_param_store()\n",
    "for j in range(num_iterations):\n",
    "    # calculate the loss and take a gradient step\n",
    "    loss = svi.step(x_data, y_data)\n",
    "    if j % 100 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We can examine the optimized parameter values by fetching from Pyro's param store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "guide.requires_grad_(False)\n",
    "\n",
    "for name, value in pyro.get_param_store().items():\n",
    "    print(name, pyro.param(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "As you can see, instead of just point estimates, we now have uncertainty estimates (`AutoDiagonalNormal.scale`) for our learned parameters. Note that Autoguide packs the latent variables into a single tensor, in this case, one entry per variable sampled in our model. Both the `loc` and `scale` parameters have size `(5,)`, one for each of the latent variables in the model, as we had remarked earlier.\n",
    "\n",
    "To look at the distribution of the latent parameters more clearly, we can make use of the `AutoDiagonalNormal.quantiles` method which will unpack the latent samples from the autoguide, and automatically constrain them to the site's support (e.g. the variable `sigma` must lie in `(0, 10)`). We see that the median values for the parameters are quite close to the Maximum Likelihood point estimates we obtained from our first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "guide.quantiles([0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Model Evaluation\n",
    "\n",
    "To evaluate our model, we'll generate some predictive samples and look at the posteriors. For this we will make use of the [Predictive](http://docs.pyro.ai/en/stable/inference_algos.html#pyro.infer.predictive.Predictive) utility class.\n",
    "\n",
    "  - We generate 800 samples from our trained model. Internally, this is done by first generating samples for the unobserved sites in the `guide`, and then running the model forward by conditioning the sites to values sampled from the `guide`. Refer to the [Model Serving](#Model-Serving-via-TorchScript) section for insight on how the `Predictive` class works.\n",
    "  - Note that in `return_sites`, we specify both the outcome (`\"obs\"` site) as well as the return value of the model (`\"_RETURN\"`) which captures the regression line. Additionally, we would also like to capture the regression coefficients (given by `\"linear.weight\"`) for further analysis.\n",
    "  - The remaining code is simply used to plot the 90% CI for the two variables from our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from pyro.infer import Predictive\n",
    "\n",
    "\n",
    "def summary(samples):\n",
    "    site_stats = {}\n",
    "    for k, v in samples.items():\n",
    "        site_stats[k] = {\n",
    "            \"mean\": torch.mean(v, 0),\n",
    "            \"std\": torch.std(v, 0),\n",
    "            \"5%\": v.kthvalue(int(len(v) * 0.05), dim=0)[0],\n",
    "            \"95%\": v.kthvalue(int(len(v) * 0.95), dim=0)[0],\n",
    "        }\n",
    "    return site_stats\n",
    "\n",
    "\n",
    "predictive = Predictive(model, guide=guide, num_samples=800, \n",
    "                        return_sites=(\"linear.weight\", \"obs\", \"_RETURN\"))\n",
    "samples = predictive(x_data)\n",
    "pred_summary = summary(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "mu = pred_summary[\"_RETURN\"]\n",
    "y = pred_summary[\"obs\"]\n",
    "predictions = pd.DataFrame({\n",
    "    \"cont_africa\": x_data[:, 0],\n",
    "    \"rugged\": x_data[:, 1],\n",
    "    \"mu_mean\": mu[\"mean\"],\n",
    "    \"mu_perc_5\": mu[\"5%\"],\n",
    "    \"mu_perc_95\": mu[\"95%\"],\n",
    "    \"y_mean\": y[\"mean\"],\n",
    "    \"y_perc_5\": y[\"5%\"],\n",
    "    \"y_perc_95\": y[\"95%\"],\n",
    "    \"true_gdp\": y_data,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6), sharey=True)\n",
    "african_nations = predictions[predictions[\"cont_africa\"] == 1]\n",
    "non_african_nations = predictions[predictions[\"cont_africa\"] == 0]\n",
    "african_nations = african_nations.sort_values(by=[\"rugged\"])\n",
    "non_african_nations = non_african_nations.sort_values(by=[\"rugged\"])\n",
    "fig.suptitle(\"Regression line 90% CI\", fontsize=16)\n",
    "ax[0].plot(non_african_nations[\"rugged\"],\n",
    "           non_african_nations[\"mu_mean\"])\n",
    "ax[0].fill_between(non_african_nations[\"rugged\"], \n",
    "                   non_african_nations[\"mu_perc_5\"],\n",
    "                   non_african_nations[\"mu_perc_95\"],\n",
    "                   alpha=0.5)\n",
    "ax[0].plot(non_african_nations[\"rugged\"], \n",
    "           non_african_nations[\"true_gdp\"],\n",
    "           \"o\")\n",
    "ax[0].set(xlabel=\"Terrain Ruggedness Index\",\n",
    "          ylabel=\"log GDP (2000)\",\n",
    "          title=\"Non African Nations\")\n",
    "idx = np.argsort(african_nations[\"rugged\"])\n",
    "ax[1].plot(african_nations[\"rugged\"], \n",
    "           african_nations[\"mu_mean\"])\n",
    "ax[1].fill_between(african_nations[\"rugged\"],\n",
    "                   african_nations[\"mu_perc_5\"],\n",
    "                   african_nations[\"mu_perc_95\"],\n",
    "                   alpha=0.5)\n",
    "ax[1].plot(african_nations[\"rugged\"], \n",
    "           african_nations[\"true_gdp\"],\n",
    "           \"o\")\n",
    "ax[1].set(xlabel=\"Terrain Ruggedness Index\",\n",
    "          ylabel=\"log GDP (2000)\",\n",
    "          title=\"African Nations\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The above figure shows the uncertainty in our estimate of the regression line, and the 90% CI around the mean. We can also see that most of the data points actually lie outside the 90% CI, and this is expected because we have not plotted the outcome variable which will be affected by `sigma`! Let us do so next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6), sharey=True)\n",
    "fig.suptitle(\"Posterior predictive distribution with 90% CI\", fontsize=16)\n",
    "ax[0].plot(non_african_nations[\"rugged\"], \n",
    "           non_african_nations[\"y_mean\"])\n",
    "ax[0].fill_between(non_african_nations[\"rugged\"], \n",
    "                   non_african_nations[\"y_perc_5\"],\n",
    "                   non_african_nations[\"y_perc_95\"],\n",
    "                   alpha=0.5)\n",
    "ax[0].plot(non_african_nations[\"rugged\"], \n",
    "           non_african_nations[\"true_gdp\"],\n",
    "           \"o\")\n",
    "ax[0].set(xlabel=\"Terrain Ruggedness Index\",\n",
    "          ylabel=\"log GDP (2000)\",\n",
    "          title=\"Non African Nations\")\n",
    "idx = np.argsort(african_nations[\"rugged\"])\n",
    "\n",
    "ax[1].plot(african_nations[\"rugged\"], \n",
    "           african_nations[\"y_mean\"])\n",
    "ax[1].fill_between(african_nations[\"rugged\"],\n",
    "                   african_nations[\"y_perc_5\"],\n",
    "                   african_nations[\"y_perc_95\"],\n",
    "                   alpha=0.5)\n",
    "ax[1].plot(african_nations[\"rugged\"], \n",
    "           african_nations[\"true_gdp\"],\n",
    "           \"o\")\n",
    "ax[1].set(xlabel=\"Terrain Ruggedness Index\",\n",
    "          ylabel=\"log GDP (2000)\",\n",
    "          title=\"African Nations\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We observe that the outcome from our model and the 90% CI accounts for the majority of the data points that we observe in practice. It is usually a good idea to do such posterior predictive checks to see if our model gives valid predictions. \n",
    "\n",
    "Finally, let us revisit our earlier question of how robust the relationship between terrain ruggedness and GDP is against any uncertainty in the parameter estimates from our model. For this, we plot the distribution of the slope of the log GDP given terrain ruggedness for nations within and outside Africa. As can be seen below, the probability mass for African nations is largely concentrated in the positive region and vice-versa for other nations, lending further credence to the original hypothesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "weight = samples[\"linear.weight\"]\n",
    "weight = weight.reshape(weight.shape[0], 3)\n",
    "gamma_within_africa = weight[:, 1] + weight[:, 2]\n",
    "gamma_outside_africa = weight[:, 1]\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "sns.distplot(gamma_within_africa, kde_kws={\"label\": \"African nations\"},)\n",
    "sns.distplot(gamma_outside_africa, kde_kws={\"label\": \"Non-African nations\"})\n",
    "fig.suptitle(\"Density of Slope : log(GDP) vs. Terrain Ruggedness\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Model Serving via TorchScript\n",
    "\n",
    "Finally, note that the `model`, `guide` and the `Predictive` utility class are all `torch.nn.Module` instances, and can be serialized as [TorchScript](https://pytorch.org/docs/stable/jit.html). \n",
    "\n",
    "Here, we show how we can serve a Pyro model as a [torch.jit.ModuleScript](https://pytorch.org/docs/stable/jit.html#torch.jit.ScriptModule), which can be run separately as a C++ program without a Python runtime.\n",
    "\n",
    "To do so, we will rewrite our own simple version of the `Predictive` utility class using Pyro's [effect handling library](http://pyro.ai/examples/effect_handlers.html). This uses:\n",
    "\n",
    " - the `trace` poutine to capture the execution trace from running the model/guide code.\n",
    " - the `replay` poutine to condition the sites in the model to values sampled from the guide trace.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pyro import poutine\n",
    "from pyro.poutine.util import prune_subsample_sites\n",
    "import warnings\n",
    "\n",
    "\n",
    "class Predict(torch.nn.Module):\n",
    "    def __init__(self, model, guide):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.guide = guide\n",
    "        \n",
    "    def forward(self, *args, **kwargs):\n",
    "        samples = {}\n",
    "        guide_trace = poutine.trace(self.guide).get_trace(*args, **kwargs)\n",
    "        model_trace = poutine.trace(poutine.replay(self.model, guide_trace)).get_trace(*args, **kwargs)\n",
    "        for site in prune_subsample_sites(model_trace).stochastic_nodes:\n",
    "            samples[site] = model_trace.nodes[site]['value']\n",
    "        return tuple(v for _, v in sorted(samples.items()))\n",
    "\n",
    "predict_fn = Predict(model, guide)\n",
    "predict_module = torch.jit.trace_module(predict_fn, {\"forward\": (x_data,)}, check_trace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We use [torch.jit.trace_module](https://pytorch.org/docs/stable/jit.html#torch.jit.trace_module) to trace the `forward` method of this module and save it using [torch.jit.save](https://pytorch.org/docs/stable/jit.html#torch.jit.save). This saved model `reg_predict.pt` can be loaded with PyTorch's C++ API using `torch::jit::load(filename)`, or using the Python API as we do below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "torch.jit.save(predict_module, '/tmp/reg_predict.pt')\n",
    "pred_loaded = torch.jit.load('/tmp/reg_predict.pt')\n",
    "pred_loaded(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Let us check that our `Predict` module was indeed serialized correctly, by generating samples from the loaded module and regenerating the previous plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "weight = []\n",
    "for _ in range(800):\n",
    "    # index = 1 corresponds to \"linear.weight\"\n",
    "    weight.append(pred_loaded(x_data)[1])\n",
    "weight = torch.stack(weight).detach()\n",
    "weight = weight.reshape(weight.shape[0], 3)\n",
    "gamma_within_africa = weight[:, 1] + weight[:, 2]\n",
    "gamma_outside_africa = weight[:, 1]\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "sns.distplot(gamma_within_africa, kde_kws={\"label\": \"African nations\"},)\n",
    "sns.distplot(gamma_outside_africa, kde_kws={\"label\": \"Non-African nations\"})\n",
    "fig.suptitle(\"Loaded TorchScript Module : log(GDP) vs. Terrain Ruggedness\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "In the next section, we'll look at how to write guides for variational inference as well as compare the results with inference via HMC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 参考文献\n",
    "\n",
    "1. McElreath, D., *Statistical Rethinking, Chapter 7*, 2016\n",
    "2. Nunn, N. & Puga, D., *[Ruggedness: The blessing of bad geography in Africa\"](https://diegopuga.org/papers/rugged.pdf)*, Review of Economics and Statistics 94(1), Feb. 2012"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
