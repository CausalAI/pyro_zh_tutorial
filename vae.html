

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>变分自编码器 &mdash; Pyro Tutorials 编译 1.3.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/pyro.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="贝叶斯回归简介(Part I)" href="bayesian_regression.html" />
    <link rel="prev" title="Poutine: Pyro 中使用 Effect Handlers 编程手册" href="effect_handlers.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html">
          

          
            
            <img src="_static/pyro_logo_wide.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                1.3.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Introduction:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="intro_part_i.html">Pyro 模型介绍</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro_part_ii.html">Pyro 推断简介</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_i.html">SVI Part I: 随机变分推断基础</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_ii.html">SVI Part II: 条件独立, 子采样和 Amortization</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_iii.html">SVI Part III: ELBO 梯度估计</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_shapes.html">Pyro中随机函数的维度</a></li>
</ul>
<p class="caption"><span class="caption-text">Advanced:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="enumeration.html">离散潜变量模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_objectives.html">自定义 SVI 目标函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="jit.html">Pyro 模型中使用 PyTorch JIT Compiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="minipyro.html">Mini-Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="effect_handlers.html">Poutine: Pyro 中使用 Effect Handlers 编程手册</a></li>
</ul>
<p class="caption"><span class="caption-text">Examples:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">变分自编码器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#VAE-数学简介">VAE 数学简介</a></li>
<li class="toctree-l2"><a class="reference internal" href="#VAE-in-Pyro">VAE in Pyro</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Inference">Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Code-and-Sample-results">Code and Sample results</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="bayesian_regression.html">贝叶斯回归简介(Part I)</a></li>
<li class="toctree-l1"><a class="reference internal" href="bayesian_regression_ii.html">贝叶斯回归推断算法(Part II)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dmm.html">深度马尔可夫模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="air.html">Attend Infer Repeat</a></li>
<li class="toctree-l1"><a class="reference internal" href="ss-vae.html">半监督变分自编码器</a></li>
<li class="toctree-l1"><a class="reference internal" href="stable.html">随机波动率的 Levy 稳定分布模型</a></li>
</ul>
<p class="caption"><span class="caption-text">Contributed:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="gmm.html">离散潜变量-高斯混合模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="gp.html">高斯过程</a></li>
<li class="toctree-l1"><a class="reference internal" href="gplvm.html">高斯过程潜变量模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="bo.html">贝叶斯优化</a></li>
<li class="toctree-l1"><a class="reference internal" href="easyguide.html">用 EasyGuide 构建 guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecasting_i.html">Forecasting I: univariate, heavy tailed</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecasting_ii.html">Forecasting II: 状态空间模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecasting_iii.html">Forecasting III: 层级模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="tracking_1d.html">跟踪未知数量的对象</a></li>
<li class="toctree-l1"><a class="reference internal" href="csis.html">Compiled Sequential 重要采样</a></li>
<li class="toctree-l1"><a class="reference internal" href="RSA-implicature.html">理性言论行动框架</a></li>
<li class="toctree-l1"><a class="reference internal" href="RSA-hyperbole.html">用 RSA 理解 Hyperbole</a></li>
<li class="toctree-l1"><a class="reference internal" href="ekf.html">卡尔曼滤子</a></li>
<li class="toctree-l1"><a class="reference internal" href="working_memory.html">设计自适应实验以研究工作记忆</a></li>
<li class="toctree-l1"><a class="reference internal" href="elections.html">贝叶斯最优实验设计预测美国总统选举</a></li>
<li class="toctree-l1"><a class="reference internal" href="dirichlet_process_mixture.html">Dirichlet 过程混合模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="boosting_bbvi.html">Boosting 黑盒变分推断</a></li>
</ul>
<p class="caption"><span class="caption-text">Code Examples:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="capture_recapture.html">Capture-Recapture Models (CJS Models)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cevae.html">因果VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="hmm.html">隐马尔可夫模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="lda.html">LDA主题模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="mcmc.html">Markov Chain Monte Carlo</a></li>
<li class="toctree-l1"><a class="reference internal" href="neutra.html">NeuTraReparam</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_gamma.html">稀疏 Gamma 深度指数族分布</a></li>
<li class="toctree-l1"><a class="reference internal" href="dkl.html">Deep Kernel Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="einsum.html">Plated Einsum</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecast_simple.html">多元预测</a></li>
<li class="toctree-l1"><a class="reference internal" href="timeseries.html">高斯过程时间序列模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="smcfilter.html">序贯蒙特卡洛滤波</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Pyro Tutorials 编译</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>变分自编码器</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/vae.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container,
div.nbinput.container div.prompt,
div.nbinput.container div.input_area,
div.nbinput.container div[class*=highlight],
div.nbinput.container div[class*=highlight] pre,
div.nboutput.container,
div.nboutput.container div.prompt,
div.nboutput.container div.output_area,
div.nboutput.container div[class*=highlight],
div.nboutput.container div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    min-width: 5ex;
    padding-top: 0.3rem;
    padding-right: 0.3rem;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 0.3rem;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="变分自编码器">
<h1>变分自编码器<a class="headerlink" href="#变分自编码器" title="Permalink to this headline">¶</a></h1>
<p>Variatational Autoencoder(VAE)</p>
<p>++++ 学完本教程，您将理解如下代码(See the full code on <a class="reference external" href="https://github.com/pyro-ppl/pyro/blob/dev/examples/vae/vae.py">Github</a>.)：</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">torch</span><span class="o">,</span> <span class="nn">pyro</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">dset</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">pyro.distributions</span> <span class="k">as</span> <span class="nn">dist</span>
<span class="kn">import</span> <span class="nn">pyro.contrib.examples.util</span>  <span class="c1"># patches torchvision</span>
<span class="kn">from</span> <span class="nn">pyro.infer</span> <span class="k">import</span> <span class="n">SVI</span><span class="p">,</span> <span class="n">Trace_ELBO</span>
<span class="kn">from</span> <span class="nn">pyro.optim</span> <span class="k">import</span> <span class="n">Adam</span>
<span class="k">assert</span> <span class="n">pyro</span><span class="o">.</span><span class="n">__version__</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;1.3.0&#39;</span><span class="p">)</span>
<span class="n">pyro</span><span class="o">.</span><span class="n">enable_validation</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pyro</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">enable_validation</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">pyro</span><span class="o">.</span><span class="n">set_rng_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span> <span class="c1"># 用于构建模型分布的 decoder</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">z_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc21</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softplus</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
        <span class="n">loc_img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc21</span><span class="p">(</span><span class="n">hidden</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">loc_img</span>

<span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span> <span class="c1"># 用于构建指导分布的 encoder</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc21</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc22</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softplus</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">z_loc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc21</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span>
        <span class="n">z_scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc22</span><span class="p">(</span><span class="n">hidden</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">z_loc</span><span class="p">,</span> <span class="n">z_scale</span>

<span class="k">class</span> <span class="nc">VAE</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z_dim</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">z_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="n">z_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">use_cuda</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_cuda</span> <span class="o">=</span> <span class="n">use_cuda</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">z_dim</span> <span class="o">=</span> <span class="n">z_dim</span>

    <span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span> <span class="c1"># 模型分布  p(x|z)p(z)</span>
        <span class="n">pyro</span><span class="o">.</span><span class="n">module</span><span class="p">(</span><span class="s2">&quot;decoder&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">z_loc</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">z_dim</span><span class="p">)))</span>
            <span class="n">z_scale</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">new_ones</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">z_dim</span><span class="p">)))</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;latent&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">z_loc</span><span class="p">,</span> <span class="n">z_scale</span><span class="p">)</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">loc_img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;obs&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">loc_img</span><span class="p">)</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">obs</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">guide</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span> <span class="c1"># 指导分布 q(z|x)</span>
        <span class="n">pyro</span><span class="o">.</span><span class="n">module</span><span class="p">(</span><span class="s2">&quot;encoder&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">z_loc</span><span class="p">,</span> <span class="n">z_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;latent&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">z_loc</span><span class="p">,</span> <span class="n">z_scale</span><span class="p">)</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">reconstruct_img</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">z_loc</span><span class="p">,</span> <span class="n">z_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">z_loc</span><span class="p">,</span> <span class="n">z_scale</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
        <span class="n">loc_img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="c1"># 注意在图像空间中我们没有抽样</span>
        <span class="k">return</span> <span class="n">loc_img</span>

<span class="k">def</span> <span class="nf">setup_data_loaders</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">root</span> <span class="o">=</span> <span class="s1">&#39;./data&#39;</span>
    <span class="n">download</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">trans</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
    <span class="n">train_set</span> <span class="o">=</span> <span class="n">dset</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">root</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">trans</span><span class="p">,</span>
                           <span class="n">download</span><span class="o">=</span><span class="n">download</span><span class="p">)</span>
    <span class="n">test_set</span> <span class="o">=</span> <span class="n">dset</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">root</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">trans</span><span class="p">)</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;num_workers&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;pin_memory&#39;</span><span class="p">:</span> <span class="n">use_cuda</span><span class="p">}</span>
    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_set</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">test_set</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">test_loader</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">svi</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">use_cuda</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">svi</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">normalizer_train</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">total_epoch_loss_train</span> <span class="o">=</span> <span class="n">epoch_loss</span> <span class="o">/</span> <span class="n">normalizer_train</span>
    <span class="k">return</span> <span class="n">total_epoch_loss_train</span>

<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">svi</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">test_loss</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">use_cuda</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">svi</span><span class="o">.</span><span class="n">evaluate_loss</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">normalizer_test</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">total_epoch_loss_test</span> <span class="o">=</span> <span class="n">test_loss</span> <span class="o">/</span> <span class="n">normalizer_test</span>
    <span class="k">return</span> <span class="n">total_epoch_loss_test</span>

<span class="c1"># 模型训练</span>
<span class="n">LEARNING_RATE</span> <span class="o">=</span> <span class="mf">1.0e-3</span>
<span class="n">USE_CUDA</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">NUM_EPOCHS</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">TEST_FREQUENCY</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">train_loader</span><span class="p">,</span> <span class="n">test_loader</span> <span class="o">=</span> <span class="n">setup_data_loaders</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="n">USE_CUDA</span><span class="p">)</span>
<span class="n">pyro</span><span class="o">.</span><span class="n">clear_param_store</span><span class="p">()</span>
<span class="n">vae</span> <span class="o">=</span> <span class="n">VAE</span><span class="p">(</span><span class="n">use_cuda</span><span class="o">=</span><span class="n">USE_CUDA</span><span class="p">)</span>
<span class="n">adam_args</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="n">LEARNING_RATE</span><span class="p">}</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">adam_args</span><span class="p">)</span>
<span class="n">svi</span> <span class="o">=</span> <span class="n">SVI</span><span class="p">(</span><span class="n">vae</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">vae</span><span class="o">.</span><span class="n">guide</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">Trace_ELBO</span><span class="p">())</span>

<span class="n">train_elbo</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_elbo</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_EPOCHS</span><span class="p">):</span>
    <span class="n">total_epoch_loss_train</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">svi</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="n">USE_CUDA</span><span class="p">)</span>
    <span class="n">train_elbo</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="n">total_epoch_loss_train</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[epoch </span><span class="si">%03d</span><span class="s2">]  average training loss: </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">total_epoch_loss_train</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">TEST_FREQUENCY</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># report test diagnostics</span>
        <span class="n">total_epoch_loss_test</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">svi</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="n">USE_CUDA</span><span class="p">)</span>
        <span class="n">test_elbo</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="n">total_epoch_loss_test</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[epoch </span><span class="si">%03d</span><span class="s2">] average test loss: </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">total_epoch_loss_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[epoch 000]  average training loss: 190.9630
[epoch 000] average test loss: 155.7649
[epoch 001]  average training loss: 146.2289
[epoch 002]  average training loss: 132.9159
[epoch 003]  average training loss: 124.6936
[epoch 004]  average training loss: 119.5353
</pre></div></div>
</div>
<div class="section" id="VAE-数学简介">
<h2>VAE 数学简介<a class="headerlink" href="#VAE-数学简介" title="Permalink to this headline">¶</a></h2>
<p>变分自编码器（VAE）可以说是实现深度概率建模的最简单情形. 注意到我们这里措辞非常小心，VAE 不是一个模型 。 准确的来说 VAE is a particular setup for doing variational inference for a certain class of models. 模型的类别非常广泛，基本上包含任何具备潜变量的密度估计模型。这种模型的基本结构非常简单(see Fig. 1).</p>
<center><figure><img name=vae.png src="_static/img/vae_model.png" style="width: 200px;"><figcaption> <font size="+1"><b>Figure 1</b>: the class of deep models we're interested in.</font></figcaption></figure></center><br><div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># # 画图</span>
<span class="c1"># from graphviz import Digraph</span>
<span class="c1"># g = Digraph(&#39;G&#39;)</span>
<span class="c1"># with g.subgraph(name=&#39;cluster_0&#39;) as c:</span>
<span class="c1">#     c.edges([(&#39;z&#39;, &#39;x&#39;)])</span>
<span class="c1">#     c.attr(label=&#39;#N&#39;)</span>
<span class="c1"># g.edge(&#39;theta&#39;, &#39;x&#39;)</span>
<span class="c1"># g.attr(label=&quot;Figure 1: the class of deep models we&#39;re interested in.&quot;)</span>
<span class="c1"># g</span>
</pre></div>
</div>
</div>
<p>在这里，我们以图模型描述了我们感兴趣的那种模型的结构。We have <span class="math notranslate nohighlight">\(N\)</span> observed datapoints <span class="math notranslate nohighlight">\(\{ \bf x_i \}\)</span>. Each datapoint is generated by a (local) latent random variable <span class="math notranslate nohighlight">\(\bf z_i\)</span>. There is also a parameter <span class="math notranslate nohighlight">\(\theta\)</span>, which is global in the sense that all the datapoints depend on it (这就是为什么它在矩形外部绘制). Note that since <span class="math notranslate nohighlight">\(\theta\)</span> is a parameter, it’s not something we’re being Bayesian about. Finally, what’s of particular importance here is that we allow for
each <span class="math notranslate nohighlight">\(\bf x_i\)</span> to depend on <span class="math notranslate nohighlight">\(\bf z_i\)</span> in a complex, non-linear way. In practice this dependency will be parameterized by a (deep) neural network with parameters <span class="math notranslate nohighlight">\(\theta\)</span>. It’s this non-linearity that makes inference for this class of models particularly challenging.</p>
<p>（我们可以灵活的设置模型分布）Of course this non-linear structure is also one reason why this class of models offers a very flexible approach to modeling complex data. Indeed it’s worth emphasizing that each of the components of the model can be ‘reconfigured’ in a variety of different ways. For example:</p>
<ul class="simple">
<li><p>the neural network in <span class="math notranslate nohighlight">\(p_\theta({\bf x} | {\bf z})\)</span> can be varied in all the usual ways (number of layers, type of non-linearities, number of hidden units, etc.)</p></li>
<li><p>we can choose observation likelihoods that suit the dataset at hand: gaussian, bernoulli, categorical, etc.</p></li>
<li><p>we can choose the number of dimensions in the latent space</p></li>
</ul>
<p>（模型分布的分解形式）The graphical model representation is a useful way to think about the structure of the model, but it can also be fruitful to look at an explicit factorization of the joint probability density:</p>
<div class="math notranslate nohighlight">
\[p({\bf x}, {\bf z}) = \prod_{i=1}^N p_\theta({\bf x}_i | {\bf z}_i) p({\bf z}_i)\]</div>
<p>The fact that <span class="math notranslate nohighlight">\(p({\bf x}, {\bf z})\)</span> breaks up into a product of terms like this makes it clear what we mean when we call <span class="math notranslate nohighlight">\(\bf z_i\)</span> a local random variable. For any particular <span class="math notranslate nohighlight">\(i\)</span>, only the single datapoint <span class="math notranslate nohighlight">\(\bf x_i\)</span> depends on <span class="math notranslate nohighlight">\(\bf z_i\)</span>. As such the <span class="math notranslate nohighlight">\(\{\bf z_i\}\)</span> describe local structure, i.e. structure that is private to each data point. This factorized structure also means that we can do subsampling during the course of learning. As such this sort of model
is amenable to the large data setting. (有关此主题和相关主题的更多讨论，请参见`SVI Part II &lt;svi_part_ii.ipynb&gt;`__.)</p>
<p>这就是模型的全部内容。由于观测值以复杂的非线性方式依赖于潜变量，因此我们期望潜变量后验分布具有复杂的结构，为了在此模型中进行推断，我们需要指定一组灵活的指导分布（即变分分布）。由于我们希望能够扩展到大型数据集，因此我们的指南将使用 amortization 来控制变量参数的数量（有关 amortization 的一般性讨论，请参见 <a class="reference internal" href="svi_part_ii.html"><span class="doc">SVI Part II</span></a>）。</p>
<p>（指导分布的设置）Recall that the job of the guide is to ‘guess’ good values for the latent random variables—good in the sense that they’re true to the model prior <em>and</em> true to the data. If we weren’t making use of amortization, we would introduce variational parameters <span class="math notranslate nohighlight">\(\{ \lambda_i \}\)</span> for <em>each</em> datapoint <span class="math notranslate nohighlight">\(\bf x_i\)</span>. These variational parameters would represent our belief about ‘good’ values of <span class="math notranslate nohighlight">\(\bf z_i\)</span>; for example, they could encode the mean and variance of a gaussian
distribution in <span class="math notranslate nohighlight">\({\bf z}_i\)</span> space. Amortization means that, rather than introducing variational parameters <span class="math notranslate nohighlight">\(\{ \lambda_i \}\)</span>, we instead learn a <em>function</em> that maps each <span class="math notranslate nohighlight">\(\bf x_i\)</span> to an appropriate <span class="math notranslate nohighlight">\(\lambda_i\)</span>. Since we need this function to be flexible, we parameterize it as a neural network. We thus end up with a parameterized family of distributions over the latent <span class="math notranslate nohighlight">\(\bf z\)</span> space that can be instantiated for all <span class="math notranslate nohighlight">\(N\)</span> datapoint <span class="math notranslate nohighlight">\({\bf x}_i\)</span> (see Fig. 2).</p>
<center><figure><img src="_static/img/vae_guide.png" style="width: 200px;"><figcaption> <font size="+1"><b>Figure 2</b>: a graphical representation of the guide. </font></figcaption></figure></center><br><p>（变分推断的目标）Note that the guide <span class="math notranslate nohighlight">\(q_{\phi}({\bf z} | {\bf x})\)</span> is parameterized by a global parameter <span class="math notranslate nohighlight">\(\phi\)</span> shared by all the datapoints. The goal of inference will be to find ‘good’ values for <span class="math notranslate nohighlight">\(\theta\)</span> and <span class="math notranslate nohighlight">\(\phi\)</span> so that two conditions are satisfied:</p>
<ul class="simple">
<li><p>the log evidence <span class="math notranslate nohighlight">\(\log p_\theta({\bf x})\)</span> is large. this means our model is a good fit to the data</p></li>
<li><p>the guide <span class="math notranslate nohighlight">\(q_{\phi}({\bf z} | {\bf x})\)</span> provides a good approximation to the posterior</p></li>
</ul>
<p>有关随机变分推理的介绍，请参见 <a class="reference internal" href="svi_part_i.html"><span class="doc">SVI Part I</span></a>.</p>
<p>（解码器）At this point we can zoom out and consider the high level structure of our setup. For concreteness, let’s suppose the <span class="math notranslate nohighlight">\(\{ \bf x_i \}\)</span> are images so that the model is a generative model of images. Once we’ve learned a good value of <span class="math notranslate nohighlight">\(\theta\)</span> we can generate images from the model as follows:</p>
<ul class="simple">
<li><p>sample <span class="math notranslate nohighlight">\(\bf z\)</span> according to the prior <span class="math notranslate nohighlight">\(p({\bf z})\)</span></p></li>
<li><p>sample <span class="math notranslate nohighlight">\(\bf x\)</span> according to the likelihood <span class="math notranslate nohighlight">\(p_\theta({\bf x}|{\bf z})\)</span></p></li>
</ul>
<p>Each image is being represented by a latent code <span class="math notranslate nohighlight">\(\bf z\)</span> and that code gets mapped to images using the likelihood, which depends on the <span class="math notranslate nohighlight">\(\theta\)</span> we’ve learned. This is why the likelihood is often called the decoder in this context: its job is to decode <span class="math notranslate nohighlight">\(\bf z\)</span> into <span class="math notranslate nohighlight">\(\bf x\)</span>. Note that since this is a probabilistic model, there is uncertainty about the <span class="math notranslate nohighlight">\(\bf z\)</span> that encodes a given datapoint <span class="math notranslate nohighlight">\(\bf x\)</span>.</p>
<p>（自编码器）Once we’ve learned good values for <span class="math notranslate nohighlight">\(\theta\)</span> and <span class="math notranslate nohighlight">\(\phi\)</span> we can also go through the following exercise.</p>
<ul class="simple">
<li><p>we start with a given image <span class="math notranslate nohighlight">\(\bf x\)</span></p></li>
<li><p>using our guide we encode it as <span class="math notranslate nohighlight">\(\bf z\)</span></p></li>
<li><p>using the model likelihood we decode <span class="math notranslate nohighlight">\(\bf z\)</span> and get a reconstructed image <span class="math notranslate nohighlight">\({\bf x}_\rm{reco}\)</span></p></li>
</ul>
<p>If we’ve learned good values for <span class="math notranslate nohighlight">\(\theta\)</span> and <span class="math notranslate nohighlight">\(\phi\)</span>, <span class="math notranslate nohighlight">\(\bf x\)</span> and <span class="math notranslate nohighlight">\({\bf x}_\rm{reco}\)</span> should be similar. 这阐明了“autoencoder”一词的由来：模型分布是解码器，指导分布是编码器。在一起，它们可以被视为自编码器。</p>
</div>
<div class="section" id="VAE-in-Pyro">
<h2>VAE in Pyro<a class="headerlink" href="#VAE-in-Pyro" title="Permalink to this headline">¶</a></h2>
<p>让我们看看如何在 Pyro 中实现 VAE。我们要建模的数据集是MNIST，这是手写数字图像的集合。由于这是一个受欢迎的基准数据集，因此我们可以利用PyTorch便利的数据加载器功能来减少我们需要编写的样板代码量：</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">dset</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>

<span class="kn">import</span> <span class="nn">pyro</span>
<span class="kn">import</span> <span class="nn">pyro.distributions</span> <span class="k">as</span> <span class="nn">dist</span>
<span class="kn">import</span> <span class="nn">pyro.contrib.examples.util</span>  <span class="c1"># patches torchvision</span>
<span class="kn">from</span> <span class="nn">pyro.infer</span> <span class="k">import</span> <span class="n">SVI</span><span class="p">,</span> <span class="n">Trace_ELBO</span>
<span class="kn">from</span> <span class="nn">pyro.optim</span> <span class="k">import</span> <span class="n">Adam</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">assert</span> <span class="n">pyro</span><span class="o">.</span><span class="n">__version__</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;1.3.0&#39;</span><span class="p">)</span>
<span class="n">pyro</span><span class="o">.</span><span class="n">enable_validation</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pyro</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">enable_validation</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">pyro</span><span class="o">.</span><span class="n">set_rng_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># Enable smoke test - run the notebook cells on CI.</span>
<span class="n">smoke_test</span> <span class="o">=</span> <span class="s1">&#39;CI&#39;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># for loading and batching MNIST dataset</span>
<span class="k">def</span> <span class="nf">setup_data_loaders</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">root</span> <span class="o">=</span> <span class="s1">&#39;./data&#39;</span>
    <span class="n">download</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">trans</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
    <span class="n">train_set</span> <span class="o">=</span> <span class="n">dset</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">root</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">trans</span><span class="p">,</span>
                           <span class="n">download</span><span class="o">=</span><span class="n">download</span><span class="p">)</span>
    <span class="n">test_set</span> <span class="o">=</span> <span class="n">dset</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">root</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">trans</span><span class="p">)</span>

    <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;num_workers&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;pin_memory&#39;</span><span class="p">:</span> <span class="n">use_cuda</span><span class="p">}</span>
    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_set</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">test_set</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">test_loader</span>
</pre></div>
</div>
</div>
<p>The main thing to draw attention to here is that we use <code class="docutils literal notranslate"><span class="pre">transforms.ToTensor()</span></code> to normalize the pixel intensities to the range <span class="math notranslate nohighlight">\([0.0, 1.0]\)</span>.</p>
<p>（定义用于构建模型分布的 decoder）Next we define a PyTorch module that encapsulates our decoder network:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># setup the two linear transformations used</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">z_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc21</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>
        <span class="c1"># setup the non-linearities</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softplus</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="c1"># define the forward computation on the latent z</span>
        <span class="c1"># first compute the hidden units</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
        <span class="c1"># return the parameter for the output Bernoulli</span>
        <span class="c1"># each is of size batch_size x 784</span>
        <span class="n">loc_img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc21</span><span class="p">(</span><span class="n">hidden</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">loc_img</span>
</pre></div>
</div>
</div>
<p>Given a latent code <span class="math notranslate nohighlight">\(z\)</span>, the forward call of <code class="docutils literal notranslate"><span class="pre">Decoder</span></code> returns the parameters for a Bernoulli distribution in image space. Since each image is of size <span class="math notranslate nohighlight">\(28\times28=784\)</span>, <code class="docutils literal notranslate"><span class="pre">loc_img</span></code> is of size <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> x 784.</p>
<p>（定义用于构建指导分布的 encoder）Next we define a PyTorch module that encapsulates our encoder network:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># setup the three linear transformations used</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc21</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc22</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">)</span>
        <span class="c1"># setup the non-linearities</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softplus</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># define the forward computation on the image x</span>
        <span class="c1"># first shape the mini-batch to have pixels in the rightmost dimension</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>
        <span class="c1"># then compute the hidden units</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="c1"># then return a mean vector and a (positive) square root covariance</span>
        <span class="c1"># each of size batch_size x z_dim</span>
        <span class="n">z_loc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc21</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span>
        <span class="n">z_scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc22</span><span class="p">(</span><span class="n">hidden</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">z_loc</span><span class="p">,</span> <span class="n">z_scale</span>
</pre></div>
</div>
</div>
<p>Given an image <span class="math notranslate nohighlight">\(\bf x\)</span> the forward call of <code class="docutils literal notranslate"><span class="pre">Encoder</span></code> returns a mean and covariance that together parameterize a (diagonal) Gaussian distribution in latent space.</p>
<p>（把解码器变成模型分布）With our encoder and decoder networks in hand, we can now write down the stochastic functions that represent our model and guide. First the model:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># define the model p(x|z)p(z)</span>
<span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="c1"># register PyTorch module `decoder` with Pyro</span>
    <span class="n">pyro</span><span class="o">.</span><span class="n">module</span><span class="p">(</span><span class="s2">&quot;decoder&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="c1"># setup hyperparameters for prior p(z)</span>
        <span class="n">z_loc</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">z_dim</span><span class="p">)))</span>
        <span class="n">z_scale</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">new_ones</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">z_dim</span><span class="p">)))</span>
        <span class="c1"># sample from prior (value will be sampled by guide when computing the ELBO)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;latent&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">z_loc</span><span class="p">,</span> <span class="n">z_scale</span><span class="p">)</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="c1"># decode the latent code z</span>
        <span class="n">loc_img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="c1"># score against actual images</span>
        <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;obs&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">loc_img</span><span class="p">)</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">obs</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">))</span>
</pre></div>
</div>
</div>
<p>Note that <code class="docutils literal notranslate"><span class="pre">model()</span></code> is a callable that takes in a mini-batch of images <code class="docutils literal notranslate"><span class="pre">x</span></code> as input. This is a <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code> of size <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> x 784.</p>
<p>The first thing we do inside of <code class="docutils literal notranslate"><span class="pre">model()</span></code> is register the (previously instantiated) decoder module with Pyro. Note that we give it an appropriate (and unique) name. This call to <code class="docutils literal notranslate"><span class="pre">pyro.module</span></code> lets Pyro know about all the parameters inside of the decoder network.</p>
<p>Next we setup the hyperparameters for our prior, which is just a unit normal gaussian distribution. Note that: - we specifically designate independence amongst the data in our mini-batch (i.e. the leftmost dimension) via <code class="docutils literal notranslate"><span class="pre">pyro.plate</span></code>. Also, note the use of <code class="docutils literal notranslate"><span class="pre">.to_event(1)</span></code> when sampling from the latent <code class="docutils literal notranslate"><span class="pre">z</span></code> - this ensures that instead of treating our sample as being generated from a univariate normal with <code class="docutils literal notranslate"><span class="pre">batch_size</span> <span class="pre">=</span> <span class="pre">z_dim</span></code>, we treat them as being generated from a multivariate normal
distribution with diagonal covariance. As such, the log probabilities along each dimension is summed out when we evaluate <code class="docutils literal notranslate"><span class="pre">.log_prob</span></code> for a “latent” sample. Refer to the <a class="reference internal" href="tensor_shapes.html"><span class="doc">Tensor Shapes</span></a> tutorial for more details. - since we’re processing an entire mini-batch of images, we need the leftmost dimension of <code class="docutils literal notranslate"><span class="pre">z_loc</span></code> and <code class="docutils literal notranslate"><span class="pre">z_scale</span></code> to equal the mini-batch size - in case we’re on GPU, we use <code class="docutils literal notranslate"><span class="pre">new_zeros</span></code> and <code class="docutils literal notranslate"><span class="pre">new_ones</span></code> to ensure that newly created tensors are on the same
GPU device.</p>
<p>Next we sample the latent <code class="docutils literal notranslate"><span class="pre">z</span></code> from the prior, making sure to give the random variable a unique Pyro name <code class="docutils literal notranslate"><span class="pre">'latent'</span></code>. Then we pass <code class="docutils literal notranslate"><span class="pre">z</span></code> through the decoder network, which returns <code class="docutils literal notranslate"><span class="pre">loc_img</span></code>. We then score the observed images in the mini-batch <code class="docutils literal notranslate"><span class="pre">x</span></code> against the Bernoulli likelihood parametrized by <code class="docutils literal notranslate"><span class="pre">loc_img</span></code>. Note that we flatten <code class="docutils literal notranslate"><span class="pre">x</span></code> so that all the pixels are in the rightmost dimension.</p>
<p>（把编码器编码成指导分布）That’s all there is to it! Note how closely the flow of Pyro primitives in <code class="docutils literal notranslate"><span class="pre">model</span></code> follows the generative story of our model, e.g. as encapsulated by Figure 1. Now we move on to the guide:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># define the guide (i.e. variational distribution) q(z|x)</span>
<span class="k">def</span> <span class="nf">guide</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="c1"># register PyTorch module `encoder` with Pyro</span>
    <span class="n">pyro</span><span class="o">.</span><span class="n">module</span><span class="p">(</span><span class="s2">&quot;encoder&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="c1"># use the encoder to get the parameters used to define q(z|x)</span>
        <span class="n">z_loc</span><span class="p">,</span> <span class="n">z_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># sample the latent code z</span>
        <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;latent&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">z_loc</span><span class="p">,</span> <span class="n">z_scale</span><span class="p">)</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
<p>Just like in the model, we first register the PyTorch module we’re using (namely <code class="docutils literal notranslate"><span class="pre">encoder</span></code>) with Pyro. We take the mini-batch of images <code class="docutils literal notranslate"><span class="pre">x</span></code> and pass it through the encoder. Then using the parameters output by the encoder network we use the normal distribution to sample a value of the latent for each image in the mini-batch. Crucially, we use the same name for the latent random variable as we did in the model: <code class="docutils literal notranslate"><span class="pre">'latent'</span></code>. Also, note the use of <code class="docutils literal notranslate"><span class="pre">pyro.plate</span></code> to designate independence of the
mini-batch dimension, and <code class="docutils literal notranslate"><span class="pre">.to_event(1)</span></code> to enforce dependence on <code class="docutils literal notranslate"><span class="pre">z_dims</span></code>, exactly as we did in the model.</p>
<p>（组合模型分布，指导分布，已经模型参数）Now that we’ve defined the full model and guide we can move on to inference. But before we do so let’s see how we package the model and guide in a PyTorch module:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">VAE</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="c1"># by default our latent space is 50-dimensional</span>
    <span class="c1"># and we use 400 hidden units</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z_dim</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># create the encoder and decoder networks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">z_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="n">z_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">use_cuda</span><span class="p">:</span>
            <span class="c1"># calling cuda() here will put all the parameters of</span>
            <span class="c1"># the encoder and decoder networks into gpu memory</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_cuda</span> <span class="o">=</span> <span class="n">use_cuda</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">z_dim</span> <span class="o">=</span> <span class="n">z_dim</span>

    <span class="c1"># define the model p(x|z)p(z)</span>
    <span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># register PyTorch module `decoder` with Pyro</span>
        <span class="n">pyro</span><span class="o">.</span><span class="n">module</span><span class="p">(</span><span class="s2">&quot;decoder&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="c1"># setup hyperparameters for prior p(z)</span>
            <span class="n">z_loc</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">z_dim</span><span class="p">)))</span>
            <span class="n">z_scale</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">new_ones</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">z_dim</span><span class="p">)))</span>
            <span class="c1"># sample from prior (value will be sampled by guide when computing the ELBO)</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;latent&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">z_loc</span><span class="p">,</span> <span class="n">z_scale</span><span class="p">)</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
            <span class="c1"># decode the latent code z</span>
            <span class="n">loc_img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="c1"># score against actual images</span>
            <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;obs&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">loc_img</span><span class="p">)</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">obs</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">))</span>

    <span class="c1"># define the guide (i.e. variational distribution) q(z|x)</span>
    <span class="k">def</span> <span class="nf">guide</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># register PyTorch module `encoder` with Pyro</span>
        <span class="n">pyro</span><span class="o">.</span><span class="n">module</span><span class="p">(</span><span class="s2">&quot;encoder&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="c1"># use the encoder to get the parameters used to define q(z|x)</span>
            <span class="n">z_loc</span><span class="p">,</span> <span class="n">z_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="c1"># sample the latent code z</span>
            <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;latent&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">z_loc</span><span class="p">,</span> <span class="n">z_scale</span><span class="p">)</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

    <span class="c1"># define a helper function for reconstructing images</span>
    <span class="k">def</span> <span class="nf">reconstruct_img</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># encode image x</span>
        <span class="n">z_loc</span><span class="p">,</span> <span class="n">z_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># sample in latent space</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">z_loc</span><span class="p">,</span> <span class="n">z_scale</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
        <span class="c1"># decode the image (note we don&#39;t sample in image space)</span>
        <span class="n">loc_img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loc_img</span>
</pre></div>
</div>
</div>
<p>The point we’d like to make here is that the two <code class="docutils literal notranslate"><span class="pre">Module</span></code>s <code class="docutils literal notranslate"><span class="pre">encoder</span></code> and <code class="docutils literal notranslate"><span class="pre">decoder</span></code> are attributes of <code class="docutils literal notranslate"><span class="pre">VAE</span></code> (which itself inherits from <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code>). This has the consequence they are both automatically registered as belonging to the <code class="docutils literal notranslate"><span class="pre">VAE</span></code> module. So, for example, when we call <code class="docutils literal notranslate"><span class="pre">parameters()</span></code> on an instance of <code class="docutils literal notranslate"><span class="pre">VAE</span></code>, PyTorch will know to return all the relevant parameters. It also means that if we’re running on a GPU, the call to <code class="docutils literal notranslate"><span class="pre">cuda()</span></code> will move all the parameters of all the
(sub)modules into GPU memory.</p>
</div>
<div class="section" id="Inference">
<h2>Inference<a class="headerlink" href="#Inference" title="Permalink to this headline">¶</a></h2>
<p>We’re now ready for inference. Refer to the full code in the next section.</p>
<p>First we instantiate an instance of the <code class="docutils literal notranslate"><span class="pre">VAE</span></code> module.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">vae</span> <span class="o">=</span> <span class="n">VAE</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>Then we setup an instance of the Adam optimizer.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">({</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">1.0e-3</span><span class="p">})</span>
</pre></div>
</div>
</div>
<p>Then we setup our inference algorithm, which is going to learn good parameters for the model and guide by maximizing the ELBO:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">svi</span> <span class="o">=</span> <span class="n">SVI</span><span class="p">(</span><span class="n">vae</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">vae</span><span class="o">.</span><span class="n">guide</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">Trace_ELBO</span><span class="p">())</span>
</pre></div>
</div>
</div>
<p>That’s all there is to it. Now we just have to define our training loop:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">svi</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="c1"># initialize loss accumulator</span>
    <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="c1"># do a training epoch over each mini-batch x returned</span>
    <span class="c1"># by the data loader</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="c1"># if on GPU put mini-batch into CUDA memory</span>
        <span class="k">if</span> <span class="n">use_cuda</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="c1"># do ELBO gradient and accumulate loss</span>
        <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">svi</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># return epoch loss</span>
    <span class="n">normalizer_train</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">total_epoch_loss_train</span> <span class="o">=</span> <span class="n">epoch_loss</span> <span class="o">/</span> <span class="n">normalizer_train</span>
    <span class="k">return</span> <span class="n">total_epoch_loss_train</span>
</pre></div>
</div>
</div>
<p>Note that all the mini-batch logic is handled by the data loader. The meat of the training loop is <code class="docutils literal notranslate"><span class="pre">svi.step(x)</span></code>. There are two things we should draw attention to here:</p>
<ul class="simple">
<li><p>any arguments to <code class="docutils literal notranslate"><span class="pre">step</span></code> are passed to the model and the guide. consequently <code class="docutils literal notranslate"><span class="pre">model</span></code> and <code class="docutils literal notranslate"><span class="pre">guide</span></code> need to have the same call signature</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">step</span></code> returns a noisy estimate of the loss (i.e. minus the ELBO). this estimate is not normalized in any way, so e.g. it scales with the size of the mini-batch</p></li>
</ul>
<p>The logic for adding evaluation logic is analogous:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">svi</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="c1"># initialize loss accumulator</span>
    <span class="n">test_loss</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="c1"># compute the loss over the entire test set</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
        <span class="c1"># if on GPU put mini-batch into CUDA memory</span>
        <span class="k">if</span> <span class="n">use_cuda</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="c1"># compute ELBO estimate and accumulate loss</span>
        <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">svi</span><span class="o">.</span><span class="n">evaluate_loss</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">normalizer_test</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">total_epoch_loss_test</span> <span class="o">=</span> <span class="n">test_loss</span> <span class="o">/</span> <span class="n">normalizer_test</span>
    <span class="k">return</span> <span class="n">total_epoch_loss_test</span>
</pre></div>
</div>
</div>
<p>Basically the only change we need to make is that we call evaluate_loss instead of step. This function will compute an estimate of the ELBO but won’t take any gradient steps.</p>
<p>The final piece of code we’d like to highlight is the helper method <code class="docutils literal notranslate"><span class="pre">reconstruct_img</span></code> in the VAE class: This is just the image reconstruction experiment we described in the introduction translated into code. We take an image and pass it through the encoder. Then we sample in latent space using the gaussian distribution provided by the encoder. Finally we decode the latent code into an image: we return the mean vector <code class="docutils literal notranslate"><span class="pre">loc_img</span></code> instead of sampling with it. Note that since the <code class="docutils literal notranslate"><span class="pre">sample()</span></code>
statement is stochastic, we’ll get different draws of z every time we run the reconstruct_img function. If we’ve learned a good model and guide—in particular if we’ve learned a good latent representation—this plurality of z samples will correspond to different styles of digit writing, and the reconstructed images should exhibit an interesting variety of different styles.</p>
</div>
<div class="section" id="Code-and-Sample-results">
<h2>Code and Sample results<a class="headerlink" href="#Code-and-Sample-results" title="Permalink to this headline">¶</a></h2>
<p>Training corresponds to maximizing the evidence lower bound (ELBO) over the training dataset. We train for 100 iterations and evaluate the ELBO for the test dataset, see Figure 3.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Run options</span>
<span class="n">LEARNING_RATE</span> <span class="o">=</span> <span class="mf">1.0e-3</span>
<span class="n">USE_CUDA</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># Run only for a single iteration for testing</span>
<span class="n">NUM_EPOCHS</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">smoke_test</span> <span class="k">else</span> <span class="mi">100</span>
<span class="n">TEST_FREQUENCY</span> <span class="o">=</span> <span class="mi">5</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">train_loader</span><span class="p">,</span> <span class="n">test_loader</span> <span class="o">=</span> <span class="n">setup_data_loaders</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="n">USE_CUDA</span><span class="p">)</span>

<span class="c1"># clear param store</span>
<span class="n">pyro</span><span class="o">.</span><span class="n">clear_param_store</span><span class="p">()</span>

<span class="c1"># setup the VAE</span>
<span class="n">vae</span> <span class="o">=</span> <span class="n">VAE</span><span class="p">(</span><span class="n">use_cuda</span><span class="o">=</span><span class="n">USE_CUDA</span><span class="p">)</span>

<span class="c1"># setup the optimizer</span>
<span class="n">adam_args</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="n">LEARNING_RATE</span><span class="p">}</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">adam_args</span><span class="p">)</span>

<span class="c1"># setup the inference algorithm</span>
<span class="n">svi</span> <span class="o">=</span> <span class="n">SVI</span><span class="p">(</span><span class="n">vae</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">vae</span><span class="o">.</span><span class="n">guide</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">Trace_ELBO</span><span class="p">())</span>

<span class="n">train_elbo</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_elbo</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c1"># training loop</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_EPOCHS</span><span class="p">):</span>
    <span class="n">total_epoch_loss_train</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">svi</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="n">USE_CUDA</span><span class="p">)</span>
    <span class="n">train_elbo</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="n">total_epoch_loss_train</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[epoch </span><span class="si">%03d</span><span class="s2">]  average training loss: </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">total_epoch_loss_train</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">TEST_FREQUENCY</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># report test diagnostics</span>
        <span class="n">total_epoch_loss_test</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">svi</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="n">USE_CUDA</span><span class="p">)</span>
        <span class="n">test_elbo</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="n">total_epoch_loss_test</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[epoch </span><span class="si">%03d</span><span class="s2">] average test loss: </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">total_epoch_loss_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Downloading https://d2hg8soec8ck9v.cloudfront.net/datasets/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "1539b0da8cf944af8aeb49401f60fce0", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw
Downloading https://d2hg8soec8ck9v.cloudfront.net/datasets/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "ef6bc6c8bdf04b3eb613a84c21a3dd30", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw
Downloading https://d2hg8soec8ck9v.cloudfront.net/datasets/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "bd830ef4c5424b7b9b95ca7a31496cd4", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw
Downloading https://d2hg8soec8ck9v.cloudfront.net/datasets/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "fd18fd628654409d9881814821562961", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw
Processing...
Done!
[epoch 000]  average training loss: 191.0216
[epoch 000] average test loss: 156.0872
[epoch 001]  average training loss: 146.8141
[epoch 002]  average training loss: 133.2540
[epoch 003]  average training loss: 124.6775
[epoch 004]  average training loss: 119.5152
[epoch 005]  average training loss: 116.1240
[epoch 005] average test loss: 113.7908
[epoch 006]  average training loss: 113.7285
[epoch 007]  average training loss: 112.0445
[epoch 008]  average training loss: 110.7292
[epoch 009]  average training loss: 109.7455
[epoch 010]  average training loss: 108.9070
[epoch 010] average test loss: 107.7720
[epoch 011]  average training loss: 108.2513
[epoch 012]  average training loss: 107.6953
[epoch 013]  average training loss: 107.2849
[epoch 014]  average training loss: 106.8870
[epoch 015]  average training loss: 106.4983
[epoch 015] average test loss: 105.9786
[epoch 016]  average training loss: 106.1872
[epoch 017]  average training loss: 105.9363
[epoch 018]  average training loss: 105.7087
[epoch 019]  average training loss: 105.4600
[epoch 020]  average training loss: 105.2648
[epoch 020] average test loss: 104.7753
[epoch 021]  average training loss: 105.0442
[epoch 022]  average training loss: 104.9031
[epoch 023]  average training loss: 104.7304
[epoch 024]  average training loss: 104.6027
[epoch 025]  average training loss: 104.4586
[epoch 025] average test loss: 104.2971
[epoch 026]  average training loss: 104.3756
[epoch 027]  average training loss: 104.2278
[epoch 028]  average training loss: 104.1049
[epoch 029]  average training loss: 104.0565
[epoch 030]  average training loss: 103.8851
[epoch 030] average test loss: 103.5858
[epoch 031]  average training loss: 103.7705
[epoch 032]  average training loss: 103.7331
[epoch 033]  average training loss: 103.6272
[epoch 034]  average training loss: 103.5645
[epoch 035]  average training loss: 103.4693
[epoch 035] average test loss: 103.1316
[epoch 036]  average training loss: 103.3898
[epoch 037]  average training loss: 103.3199
[epoch 038]  average training loss: 103.2840
[epoch 039]  average training loss: 103.1866
[epoch 040]  average training loss: 103.1108
[epoch 040] average test loss: 103.0911
[epoch 041]  average training loss: 103.0730
[epoch 042]  average training loss: 103.0086
[epoch 043]  average training loss: 102.9338
[epoch 044]  average training loss: 102.8886
[epoch 045]  average training loss: 102.8416
[epoch 045] average test loss: 102.8022
[epoch 046]  average training loss: 102.7832
[epoch 047]  average training loss: 102.7389
[epoch 048]  average training loss: 102.6800
[epoch 049]  average training loss: 102.6738
[epoch 050]  average training loss: 102.5855
[epoch 050] average test loss: 102.5790
[epoch 051]  average training loss: 102.5615
[epoch 052]  average training loss: 102.4934
[epoch 053]  average training loss: 102.4610
[epoch 054]  average training loss: 102.4274
[epoch 055]  average training loss: 102.3712
[epoch 055] average test loss: 102.3923
[epoch 056]  average training loss: 102.3328
[epoch 057]  average training loss: 102.2912
[epoch 058]  average training loss: 102.1891
[epoch 059]  average training loss: 102.2194
[epoch 060]  average training loss: 102.1762
[epoch 060] average test loss: 102.1223
[epoch 061]  average training loss: 102.1585
[epoch 062]  average training loss: 102.0887
[epoch 063]  average training loss: 102.0703
[epoch 064]  average training loss: 102.0091
[epoch 065]  average training loss: 101.9924
[epoch 065] average test loss: 102.0361
[epoch 066]  average training loss: 101.9461
[epoch 067]  average training loss: 101.8985
[epoch 068]  average training loss: 101.8809
[epoch 069]  average training loss: 101.8587
[epoch 070]  average training loss: 101.8102
[epoch 070] average test loss: 102.1124
[epoch 071]  average training loss: 101.7739
[epoch 072]  average training loss: 101.7548
[epoch 073]  average training loss: 101.7252
[epoch 074]  average training loss: 101.7424
[epoch 075]  average training loss: 101.6693
[epoch 075] average test loss: 101.8703
[epoch 076]  average training loss: 101.6238
[epoch 077]  average training loss: 101.5941
[epoch 078]  average training loss: 101.5562
[epoch 079]  average training loss: 101.5380
[epoch 080]  average training loss: 101.4967
[epoch 080] average test loss: 101.6312
[epoch 081]  average training loss: 101.4572
[epoch 082]  average training loss: 101.4549
[epoch 083]  average training loss: 101.3729
[epoch 084]  average training loss: 101.3880
[epoch 085]  average training loss: 101.3953
[epoch 085] average test loss: 101.5520
[epoch 086]  average training loss: 101.3212
[epoch 087]  average training loss: 101.3289
[epoch 088]  average training loss: 101.3108
[epoch 089]  average training loss: 101.2534
[epoch 090]  average training loss: 101.2607
[epoch 090] average test loss: 101.2997
[epoch 091]  average training loss: 101.2435
[epoch 092]  average training loss: 101.1965
[epoch 093]  average training loss: 101.1350
[epoch 094]  average training loss: 101.1215
[epoch 095]  average training loss: 101.0969
[epoch 095] average test loss: 101.2543
[epoch 096]  average training loss: 101.1045
[epoch 097]  average training loss: 101.0621
[epoch 098]  average training loss: 101.0410
[epoch 099]  average training loss: 101.0019
</pre></div></div>
</div>
<center><figure><figcaption><p>Figure 3: How the test ELBO evolves over the course of training.</p>
</figcaption></figure></center><p>Next we show a set of randomly sampled images from the model. These are generated by drawing random samples of <code class="docutils literal notranslate"><span class="pre">z</span></code> and generating an image for each one, see Figure 4.</p>
<center>
<figure>
    <table>
        <tr>
            <td>
                <imgm src="_static/img/vae_plots/vae_embeddings_pt1.jpg"  style="width: 350px;">
            </td>
            <td>
                <img src="_static/img/vae_plots/vae_embeddings_pt2.jpg" style="width: 350px;">
            </td>
        </tr>
    </table>
    <figcaption>
        <font size="+1"><b>Figure 4:</b> Samples from generative model.</font>
    </figcaption>
</figure>
</center><p>We also study the 50-dimensional latent space of the entire test dataset by encoding all MNIST images and embedding their means into a 2-dimensional T-SNE space. We then color each embedded image by its class. The resulting Figure 5 shows separation by class with variance within each class-cluster.</p>
<center>
<figure>
<img src="_static/img/vae_plots/VAE_embedding.png"  style="width: 550px;">
<figcaption>
<font size="+1"><b>Figure 5:</b> T-SNE Embedding of the latent z. The colors correspond to different classes of digits.</font>
</figcaption>
</figure>
</center><p>See the full code on <a class="reference external" href="https://github.com/pyro-ppl/pyro/blob/dev/examples/vae/vae.py">Github</a>.</p>
<blockquote>
<div><p>参考文献</p>
</div></blockquote>
<p>[1] <code class="docutils literal notranslate"><span class="pre">Auto-Encoding</span> <span class="pre">Variational</span> <span class="pre">Bayes</span></code>,     Diederik P Kingma, Max Welling</p>
<p>[2] <code class="docutils literal notranslate"><span class="pre">Stochastic</span> <span class="pre">Backpropagation</span> <span class="pre">and</span> <span class="pre">Approximate</span> <span class="pre">Inference</span> <span class="pre">in</span> <span class="pre">Deep</span> <span class="pre">Generative</span> <span class="pre">Models</span></code>,      Danilo Jimenez Rezende, Shakir Mohamed, Daan Wierstra</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="bayesian_regression.html" class="btn btn-neutral float-right" title="贝叶斯回归简介(Part I)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="effect_handlers.html" class="btn btn-neutral float-left" title="Poutine: Pyro 中使用 Effect Handlers 编程手册" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright Uber Technologies, Inc; 编译 by Heyang Gong

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>