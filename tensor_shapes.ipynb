{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<big> **Note** </big> \n",
    "\n",
    "<small> Pyro 中分布具备维度概念，并且随机函数的维度不是数据的维度！</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Pyro中随机函数的维度\n",
    "\n",
    "\n",
    "本教程介绍 Pyro‘s organization of tensor dimensions. 开始之前，您应该熟悉PyTorch 广播语义, see [PyTorch broadcasting semantics](http://pytorch.org/docs/master/notes/broadcasting.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**学完本文，您将学会:**\n",
    "\n",
    "- 训练模型和 debug 的时候，设置 `pyro.enable_validation(True)`.\n",
    "- 张量按照最右边的维度进行 Broadcasting: `torch.ones(3,4,5) + torch.ones(5)`.\n",
    "- 样本维度 =  `batch_shape + event_shape`.\n",
    "- 对于样本 $x$ `model.log_prob(x).shape == batch_shape` \n",
    "- Use `.expand()` to draw a batch of samples, or rely on `plate` to expand automatically.\n",
    "- 使用 `my_dist.to_event(n)` 将右起 n 个维度声明为 dependent，从而是实现随机函数 reshape.\n",
    "- Use `with pyro.plate('name', size):` to declare a dimension as conditionally independent.\n",
    "- 所有的维度必须被申明为 dependent 或者条件独立.\n",
    "- Try to support batching on the left. This lets Pyro auto-parallelize.\n",
    "  - use negative indices like `x.sum(-1)` rather than `x.sum(2)`\n",
    "  - use ellipsis notation like `pixel = image[..., i, j]`\n",
    "  - use [Vindex](http://docs.pyro.ai/en/dev/ops.html#pyro.ops.indexing.Vindex) if `i,j` are enumerated, `pixel = Vindex(image)[..., i, j]`\n",
    "- When debugging, examine all shapes in a trace using [Trace.format_shapes()](http://docs.pyro.ai/en/dev/poutine.html#pyro.poutine.Trace.format_shapes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os, torch, pyro\n",
    "from torch.distributions import constraints\n",
    "from pyro.distributions import Bernoulli, Categorical, MultivariateNormal, Normal\n",
    "from pyro.distributions.util import broadcast_shape\n",
    "from pyro.infer import Trace_ELBO, TraceEnum_ELBO, config_enumerate\n",
    "import pyro.poutine as poutine\n",
    "from pyro.optim import Adam\n",
    "\n",
    "smoke_test = ('CI' in os.environ)\n",
    "assert pyro.__version__.startswith('1.3.0')\n",
    "pyro.enable_validation(True)    # <---- This is always a good idea!\n",
    "\n",
    "# We'll ue this helper to check our models are correct.\n",
    "def test_model(model, guide, loss):\n",
    "    pyro.clear_param_store()\n",
    "    loss.loss(model, guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true
   },
   "source": [
    "## 随机函数的维度 \n",
    "\n",
    "Pytorch 中的 `Tensor` 只有一个维度属性 `.shape`，但是 Pyro 中 `Distribution` 有两个维度属性: `.batch_shape` 和 `.event_shape`. 他们两个一起定义了一个样本的维度。\n",
    "\n",
    "```py\n",
    "x = d.sample()\n",
    "assert x.shape == d.batch_shape + d.event_shape \n",
    "# 两个元组的并，不要误解成对应每个维度相加\n",
    "```\n",
    "\n",
    "数学上来说，随机变量 $X \\sim p(x; \\theta)$ 的某个事件是 $X=x$，因此维度就是 `event_shape`。而我们需要一个 batch 不同参数 $\\theta$ 的 r.v. $X$ (称之为 batch r.v.)，所以 `batch_shape` 就是不同参数同一类型的随机变量数量的维度。于是最后的一个 “batch r.v.(batch of 同种类型随机变量)” 样本的维度就是 `batch_shape` 并上 `event_shape`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Indices over `.batch_shape` 意味着随机变量之间的条件独立性, 而 indices over `.event_shape` 意味着随机向量分量之间的相依性 (即从分布中抽出一个样本). 因为一个随机向量样本对应这一个概率值, 所以 `.log_prob()` 方法为 each event of shape `.event_shape` 产生一个概率值，所以 `.log_prob()` 方法输出的维度就是 `.batch_shape`:\n",
    "\n",
    "```py\n",
    "# 每个样本对应一个概率值，batch_shape 就是 batch r.v. 的维度。\n",
    "assert d.log_prob(x).shape == d.batch_shape\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "请注意 `Distribution.sample()` 方法也有参数 `sample_shape`, 它用于表示batch r.v. 的独立同分布采样维度，所以\n",
    "\n",
    "```py\n",
    "x2 = d.sample(sample_shape)\n",
    "assert x2.shape == sample_shape + batch_shape + event_shape\n",
    "```\n",
    "\n",
    "也就是说 Pyro 中每个分布(也就是随机函数)都具备两个维度 batch_shape 和 event_shape，抽样之后我们还可以得到一个 `sample_shape`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "我们来举个例子，某个班级每个学生身高和体重组成一个随机向量，那么 `event_shape = (2, )`；而一个学校有多个不同的班级，其中每个班级具备不同的身高体重分布参数，那么 `batch_shape = 班级数量`；最后这个学校全体学生来自于某个总体，那么此时从该总体中可以抽样得到 `sample_shape` 个样本。\n",
    "\n",
    "In summary\n",
    "```\n",
    "      |      iid     | independent | dependent\n",
    "------+--------------+-------------+------------\n",
    "shape = sample_shape + batch_shape + event_shape\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 简单例子 \n",
    "\n",
    "最简单的分布形状是一个单变量分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "d = Bernoulli(0.5)\n",
    "assert d.batch_shape == ()\n",
    "assert d.event_shape == ()\n",
    "x = d.sample()\n",
    "assert x.shape == ()\n",
    "assert d.log_prob(x).shape == ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "通过传入批量参数可得到 batched 分布(batch r.v.)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "d = Bernoulli(0.5 * torch.ones(3,4))\n",
    "assert d.batch_shape == (3, 4)\n",
    "assert d.event_shape == ()\n",
    "x = d.sample()\n",
    "assert x.shape == (3, 4)\n",
    "assert d.log_prob(x).shape == (3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Another way to batch distributions is via the `.expand()` method. This only works if \n",
    "parameters are identical along the leftmost dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "d = Bernoulli(torch.tensor([0.1, 0.2, 0.3, 0.4])).expand([3, 4])\n",
    "assert d.batch_shape == (3, 4)\n",
    "assert d.event_shape == ()\n",
    "x = d.sample()\n",
    "assert x.shape == (3, 4)\n",
    "assert d.log_prob(x).shape == (3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "多元分布具有非空 `.event_shape`. 对于这些分布,  `.sample()` 和 `.log_prob(x)` 的维度会不一样:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "d = MultivariateNormal(torch.zeros(3), torch.eye(3, 3))\n",
    "assert d.batch_shape == ()\n",
    "assert d.event_shape == (3,)\n",
    "x = d.sample()\n",
    "assert x.shape == (3,)            # == batch_shape + event_shape\n",
    "assert d.log_prob(x).shape == ()  # == batch_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "下一小节提示：\n",
    "\n",
    "```python\n",
    "x = pyro.sample(\"x\", dist.Normal(0, 1).expand([10]).to_event(1))\n",
    "\n",
    "with pyro.plate(\"x_plate\", 10):\n",
    "    x = pyro.sample(\"x\", dist.Normal(0, 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 变换`event_shape`\n",
    "\n",
    "在 Pyro 中，您可以使用 [.to_event(n)](http://docs.pyro.ai/en/dev/distributions.html#pyro.distributions.torch_distribution.TorchDistributionMixin.to_event) 将一维分布转化成多维分布(也就是随便变量 stack 成随机向量)，其中 `n` 表示从右边开始数 n 个维度，声明 `dependent` (也就是他们为随机向量). 所以 `to_event(0)` 相当于分布没有维度变换，而 `to_event(1)` 表示随机向量的维度为原来分布 `batch_shape` 的最后一个维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "d = Bernoulli(0.5 * torch.ones(3,4)).to_event(1)\n",
    "assert d.batch_shape == (3,)\n",
    "assert d.event_shape == (4,)\n",
    "x = d.sample()\n",
    "assert x.shape == (3, 4)\n",
    "assert d.log_prob(x).shape == (3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "在使用Pyro程序时，请记住样本具有维度 `batch_shape + event_shape`, 而 `.log_prob(x)` 具有维度`batch_shape`. You'll need to ensure that `batch_shape` is carefully controlled by either trimming it down with `.to_event(n)` or by declaring dimensions as independent via `pyro.plate`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "实际应用中：It is always safe to assume dependence。在 Pyro 中我们经常将某些维度声明为 dependent，即使他们实际上是独立的, e.g.\n",
    "\n",
    "```python\n",
    "x = pyro.sample(\"x\", dist.Normal(0, 1).expand([10]).to_event(1))\n",
    "assert x.shape == (10,)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "这很有用，原因有两个：\n",
    "\n",
    "- (容易构造多元分布) it allows us to easily swap in a `MultivariateNormal` distribution later. \n",
    "- (简化代码，避免使用 `plate`) it simplifies the code a bit since we don't need a `plate` (see below) as in\n",
    "\n",
    "```python\n",
    "with pyro.plate(\"x_plate\", 10):\n",
    "    x = pyro.sample(\"x\", dist.Normal(0, 1))  # .expand([10]) is automatic\n",
    "    assert x.shape == (10,)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "这两个版本之间的区别是： 第二个版本 with `plate` informs Pyro that it can 使用了条件独立性信息 when estimating gradients, 而第一个版本 Pyro 必须假定分量之间是相关的 (even though the normals are in fact conditionally independent). 这类似于图模型中的 $d$-分离: it is always safe to add edges and assume variables *may* be dependent (i.e. to widen the model class), but it is unsafe to assume independence when variables are actually dependent (i.e. narrowing the model class so the true model lies outside of the class, as in mean field). \n",
    "\n",
    "实际上，Pyro的 SVI 推理算法对 `Normal` distributions 使用了重参数化技巧，因此两个梯度估计量具有相同的性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "下节内容提示:\n",
    "\n",
    "```python\n",
    "x_axis = pyro.plate(\"x_axis\", 3, dim=-2)\n",
    "y_axis = pyro.plate(\"y_axis\", 2, dim=-3)\n",
    "with x_axis:\n",
    "    x = pyro.sample(\"x\", Normal(0, 1))\n",
    "with y_axis:\n",
    "    y = pyro.sample(\"y\", Normal(0, 1))\n",
    "with x_axis, y_axis:\n",
    "    xy = pyro.sample(\"xy\", Normal(0, 1))\n",
    "    z = pyro.sample(\"z\", Normal(0, 1).expand([5]).to_event(1))\n",
    "assert x.shape == (3, 1)        # batch_shape == (3,1)     event_shape == ()\n",
    "assert y.shape == (2, 1, 1)     # batch_shape == (2,1,1)   event_shape == ()\n",
    "assert xy.shape == (2, 3, 1)    # batch_shape == (2,3,1)   event_shape == ()\n",
    "assert z.shape == (2, 3, 1, 5)  # batch_shape == (2,3,1)   event_shape == (5,)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 变换`batch_shape`\n",
    "\n",
    "用 `plate` 声明条件独立性来变换 `batch_shape`.\n",
    " \n",
    " \n",
    "Pyro模型可以使用上下文管理器 [pyro.plate](http://docs.pyro.ai/en/dev/primitives.html#pyro.plate) to declare that certain batch dimensions are independent. 然后，推理算法可以利用这种独立性，e.g. construct lower variance gradient estimators or to enumerate in linear space rather than exponential space. An example of an independent dimension is the index over data in a minibatch: each datum should be independent of all others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "最简单的方式 to declare a dimension as independent is to declare the rightmost batch dimension as independent via a simple\n",
    "\n",
    "```python\n",
    "with pyro.plate(\"my_plate\"):\n",
    "    # within this context, batch dimension -1 is independent\n",
    "```\n",
    "\n",
    "我们推荐 always providing an optional size argument to aid in debugging shapes\n",
    "\n",
    "```python\n",
    "with pyro.plate(\"my_plate\", len(my_data)):\n",
    "    # within this context, batch dimension -1 is independent\n",
    "```\n",
    "\n",
    "Starting with Pyro 0.2 you can additionally nest `plates`, e.g. if you have per-pixel independence:\n",
    "\n",
    "```python\n",
    "with pyro.plate(\"x_axis\", 320):\n",
    "    # within this context, batch dimension -1 is independent\n",
    "    with pyro.plate(\"y_axis\", 200):\n",
    "        # within this context, batch dimensions -2 and -1 are independent\n",
    "```\n",
    "\n",
    "注意我们总是用负数 -2, -1 来表示从右边索引。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Finally if you want to mix and match `plate`s for e.g. noise that depends only on `x`, some noise that depends only on `y`, and some noise that depends on both, you can declare multiple `plates` and use them as reusable context managers. In this case Pyro cannot automatically allocate a dimension, so you need to provide a `dim` argument (again counting from the right):\n",
    "\n",
    "```python\n",
    "x_axis = pyro.plate(\"x_axis\", 3, dim=-2)\n",
    "y_axis = pyro.plate(\"y_axis\", 2, dim=-3)\n",
    "with x_axis:\n",
    "    # within this context, batch dimension -2 is independent\n",
    "with y_axis:\n",
    "    # within this context, batch dimension -3 is independent\n",
    "with x_axis, y_axis:\n",
    "    # within this context, batch dimensions -3 and -2 are independent\n",
    "```\n",
    "Let's take a closer look at batch sizes within `plate`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def model1():\n",
    "    a = pyro.sample(\"a\", Normal(0, 1))\n",
    "    b = pyro.sample(\"b\", Normal(torch.zeros(2), 1).to_event(1))\n",
    "    with pyro.plate(\"c_plate\", 2):\n",
    "        c = pyro.sample(\"c\", Normal(torch.zeros(2), 1))\n",
    "    with pyro.plate(\"d_plate\", 3):\n",
    "        d = pyro.sample(\"d\", Normal(torch.zeros(3,4,5), 1).to_event(2))\n",
    "    assert a.shape == ()       # batch_shape == ()     event_shape == ()\n",
    "    assert b.shape == (2,)     # batch_shape == ()     event_shape == (2,)\n",
    "    assert c.shape == (2,)     # batch_shape == (2,)   event_shape == ()\n",
    "    assert d.shape == (3,4,5)  # batch_shape == (3,)   event_shape == (4,5) \n",
    "\n",
    "    x_axis = pyro.plate(\"x_axis\", 3, dim=-2)\n",
    "    y_axis = pyro.plate(\"y_axis\", 2, dim=-3)\n",
    "    with x_axis:\n",
    "        x = pyro.sample(\"x\", Normal(0, 1))\n",
    "    with y_axis:\n",
    "        y = pyro.sample(\"y\", Normal(0, 1))\n",
    "    with x_axis, y_axis:\n",
    "        xy = pyro.sample(\"xy\", Normal(0, 1))\n",
    "        z = pyro.sample(\"z\", Normal(0, 1).expand([5]).to_event(1))\n",
    "    assert x.shape == (3, 1)        # batch_shape == (3,1)     event_shape == ()\n",
    "    assert y.shape == (2, 1, 1)     # batch_shape == (2,1,1)   event_shape == ()\n",
    "    assert xy.shape == (2, 3, 1)    # batch_shape == (2,3,1)   event_shape == ()\n",
    "    assert z.shape == (2, 3, 1, 5)  # batch_shape == (2,3,1)   event_shape == (5,)\n",
    "    \n",
    "test_model(model1, model1, Trace_ELBO())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "It is helpful to visualize the `.shape`s of each sample site by aligning them at the boundary between `batch_shape` and `event_shape`: dimensions to the right will be summed out in `.log_prob()` and dimensions to the left will remain. \n",
    "\n",
    "```\n",
    "batch dims | event dims\n",
    "-----------+-----------\n",
    "           |        a = sample(\"a\", Normal(0, 1))\n",
    "           |2       b = sample(\"b\", Normal(zeros(2), 1)\n",
    "           |                        .to_event(1))\n",
    "           |        with plate(\"c\", 2):\n",
    "          2|            c = sample(\"c\", Normal(zeros(2), 1))\n",
    "           |        with plate(\"d\", 3):\n",
    "          3|4 5         d = sample(\"d\", Normal(zeros(3,4,5), 1)\n",
    "           |                       .to_event(2))\n",
    "           |\n",
    "           |        x_axis = plate(\"x\", 3, dim=-2)\n",
    "           |        y_axis = plate(\"y\", 2, dim=-3)\n",
    "           |        with x_axis:\n",
    "        3 1|            x = sample(\"x\", Normal(0, 1))\n",
    "           |        with y_axis:\n",
    "      2 1 1|            y = sample(\"y\", Normal(0, 1))\n",
    "           |        with x_axis, y_axis:\n",
    "      2 3 1|            xy = sample(\"xy\", Normal(0, 1))\n",
    "      2 3 1|5           z = sample(\"z\", Normal(0, 1).expand([5])\n",
    "           |                       .to_event(1))\n",
    "```\n",
    "\n",
    "\n",
    "为了自动的检查程序中样本的维度，you can trace the program 并且使用方法 [Trace.format_shapes()](http://docs.pyro.ai/en/dev/poutine.html#pyro.poutine.Trace.format_shapes) 来打印每个 sample site 的三种维度: \n",
    "\n",
    "- 分布的维度(both `site[\"fn\"].batch_shape` and `site[\"fn\"].event_shape`),\n",
    "- the value shape(`site[\"value\"].shape`), \n",
    "- 如果对数概率被计算来，那么也返回 `log_prob` 维度 (`site[\"log_prob\"].shape`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace Shapes:            \n",
      " Param Sites:            \n",
      "Sample Sites:            \n",
      "       a dist       |    \n",
      "        value       |    \n",
      "     log_prob       |    \n",
      "       b dist       | 2  \n",
      "        value       | 2  \n",
      "     log_prob       |    \n",
      " c_plate dist       |    \n",
      "        value     2 |    \n",
      "     log_prob       |    \n",
      "       c dist     2 |    \n",
      "        value     2 |    \n",
      "     log_prob     2 |    \n",
      " d_plate dist       |    \n",
      "        value     3 |    \n",
      "     log_prob       |    \n",
      "       d dist     3 | 4 5\n",
      "        value     3 | 4 5\n",
      "     log_prob     3 |    \n",
      "  x_axis dist       |    \n",
      "        value     3 |    \n",
      "     log_prob       |    \n",
      "  y_axis dist       |    \n",
      "        value     2 |    \n",
      "     log_prob       |    \n",
      "       x dist   3 1 |    \n",
      "        value   3 1 |    \n",
      "     log_prob   3 1 |    \n",
      "       y dist 2 1 1 |    \n",
      "        value 2 1 1 |    \n",
      "     log_prob 2 1 1 |    \n",
      "      xy dist 2 3 1 |    \n",
      "        value 2 3 1 |    \n",
      "     log_prob 2 3 1 |    \n",
      "       z dist 2 3 1 | 5  \n",
      "        value 2 3 1 | 5  \n",
      "     log_prob 2 3 1 |    \n"
     ]
    }
   ],
   "source": [
    "trace = poutine.trace(model1).get_trace()\n",
    "trace.compute_log_prob()  # optional, but allows printing of log_prob shapes\n",
    "print(trace.format_shapes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## `plate`内部张量子采样 \n",
    "\n",
    "[plate](http://docs.pyro.ai/en/dev/primitives.html#pyro.plate) 的主要用途之一是对数据进行子采样。\n",
    "因为 `plate` 内部数据是条件独立的, 所以子采样之后计算的损失期望估计不会变。\n",
    "\n",
    " 要对样本数据进行子采样，您需要同时将原始数据大小和子样本大小告知 Pyro。然后 Pyro 将选择一个随机数据子集并产生一组索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data = torch.arange(100.)\n",
    "\n",
    "def model2():\n",
    "    mean = pyro.param(\"mean\", torch.zeros(len(data)))\n",
    "    with pyro.plate(\"data\", len(data), subsample_size=10) as ind:\n",
    "        assert len(ind) == 10    # ind is a LongTensor that indexes the subsample.\n",
    "        batch = data[ind]        # Select a minibatch of data.\n",
    "        mean_batch = mean[ind]   # Take care to select the relevant per-datum parameters.\n",
    "        # Do stuff with batch:\n",
    "        x = pyro.sample(\"x\", Normal(mean_batch, 1), obs=batch)\n",
    "        assert len(x) == 10\n",
    "        \n",
    "test_model(model2, guide=lambda: None, loss=Trace_ELBO())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true
   },
   "source": [
    "## 广播和并行计算\n",
    "\n",
    "- Broadcasting to allow parallel enumeration \n",
    "\n",
    "Pyro 0.2 introduces the ability to enumerate discrete latent variables in parallel. This can significantly reduce the variance of gradient estimators when learning a posterior via [SVI](http://docs.pyro.ai/en/dev/inference_algos.html#pyro.infer.svi.SVI).\n",
    "\n",
    "To use parallel enumeration, Pyro needs to allocate tensor dimension that it can use for enumeration. To avoid conflicting with other dimensions that we want to use for `plate`s, we need to declare a budget of the maximum number of tensor dimensions we'll use. This budget is called `max_plate_nesting` and is an argument to [SVI](http://docs.pyro.ai/en/dev/inference_algos.html) (the argument is simply passed through to [TraceEnum_ELBO](http://docs.pyro.ai/en/dev/inference_algos.html#pyro.infer.traceenum_elbo.TraceEnum_ELBO)). Usually Pyro can determine this budget on its own (it runs the `(model,guide)` pair once and record what happens), but in case of dynamic model structure you may need to declare `max_plate_nesting` manually.\n",
    "\n",
    "To understand `max_plate_nesting` and how Pyro allocates dimensions for enumeration, let's revisit `model1()` from above. This time we'll map out three types of dimensions:\n",
    "enumeration dimensions on the left (Pyro takes control of these), batch dimensions in the middle, and event dimensions on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "```\n",
    "      max_plate_nesting = 3\n",
    "           |<--->|\n",
    "enumeration|batch|event\n",
    "-----------+-----+-----\n",
    "           |. . .|      a = sample(\"a\", Normal(0, 1))\n",
    "           |. . .|2     b = sample(\"b\", Normal(zeros(2), 1)\n",
    "           |     |                      .to_event(1))\n",
    "           |     |      with plate(\"c\", 2):\n",
    "           |. . 2|          c = sample(\"c\", Normal(zeros(2), 1))\n",
    "           |     |      with plate(\"d\", 3):\n",
    "           |. . 3|4 5       d = sample(\"d\", Normal(zeros(3,4,5), 1)\n",
    "           |     |                     .to_event(2))\n",
    "           |     |\n",
    "           |     |      x_axis = plate(\"x\", 3, dim=-2)\n",
    "           |     |      y_axis = plate(\"y\", 2, dim=-3)\n",
    "           |     |      with x_axis:\n",
    "           |. 3 1|          x = sample(\"x\", Normal(0, 1))\n",
    "           |     |      with y_axis:\n",
    "           |2 1 1|          y = sample(\"y\", Normal(0, 1))\n",
    "           |     |      with x_axis, y_axis:\n",
    "           |2 3 1|          xy = sample(\"xy\", Normal(0, 1))\n",
    "           |2 3 1|5         z = sample(\"z\", Normal(0, 1).expand([5]))\n",
    "           |     |                     .to_event(1))\n",
    "```\n",
    "Note that it is safe to overprovision `max_plate_nesting=4` but we cannot underprovision `max_plate_nesting=2` (or Pyro will error). Let's see how this works in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "@config_enumerate\n",
    "def model3():\n",
    "    p = pyro.param(\"p\", torch.arange(6.) / 6)\n",
    "    locs = pyro.param(\"locs\", torch.tensor([-1., 1.]))\n",
    "\n",
    "    a = pyro.sample(\"a\", Categorical(torch.ones(6) / 6))\n",
    "    b = pyro.sample(\"b\", Bernoulli(p[a]))  # Note this depends on a.\n",
    "    with pyro.plate(\"c_plate\", 4):\n",
    "        c = pyro.sample(\"c\", Bernoulli(0.3))\n",
    "        with pyro.plate(\"d_plate\", 5):\n",
    "            d = pyro.sample(\"d\", Bernoulli(0.4))\n",
    "            e_loc = locs[d.long()].unsqueeze(-1)\n",
    "            e_scale = torch.arange(1., 8.)\n",
    "            e = pyro.sample(\"e\", Normal(e_loc, e_scale)\n",
    "                            .to_event(1))  # Note this depends on d.\n",
    "\n",
    "    #                   enumerated|batch|event dims\n",
    "    assert a.shape == (         6, 1, 1   )  # Six enumerated values of the Categorical.\n",
    "    assert b.shape == (      2, 1, 1, 1   )  # Two enumerated Bernoullis, unexpanded.\n",
    "    assert c.shape == (   2, 1, 1, 1, 1   )  # Only two Bernoullis, unexpanded.\n",
    "    assert d.shape == (2, 1, 1, 1, 1, 1   )  # Only two Bernoullis, unexpanded.\n",
    "    assert e.shape == (2, 1, 1, 1, 5, 4, 7)  # This is sampled and depends on d.\n",
    "\n",
    "    assert e_loc.shape   == (2, 1, 1, 1, 1, 1, 1,)\n",
    "    assert e_scale.shape == (                  7,)\n",
    "            \n",
    "test_model(model3, model3, TraceEnum_ELBO(max_plate_nesting=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Let's take a closer look at those dimensions. First note that Pyro allocates enumeration dims starting from the right at `max_plate_nesting`: Pyro allocates dim -3 to enumerate `a`, then dim -4 to enumerate `b`, then dim -5 to enumerate `c`, and finally dim -6 to enumerate `d`. Next note that samples only have extent (size > 1) in the new enumeration dimension. This helps keep tensors small and computation cheap. (Note that the `log_prob` shape will be broadcast up to contain both enumeratin shape and batch shape, so e.g. `trace.nodes['d']['log_prob'].shape == (2, 1, 1, 1, 5, 4)`.)\n",
    "\n",
    "We can draw a similar map of the tensor dimensions:\n",
    "```\n",
    "     max_plate_nesting = 2\n",
    "            |<->|\n",
    "enumeration batch event\n",
    "------------|---|-----\n",
    "           6|1 1|     a = pyro.sample(\"a\", Categorical(torch.ones(6) / 6))\n",
    "         2 1|1 1|     b = pyro.sample(\"b\", Bernoulli(p[a]))\n",
    "            |   |     with pyro.plate(\"c_plate\", 4):\n",
    "       2 1 1|1 1|         c = pyro.sample(\"c\", Bernoulli(0.3))\n",
    "            |   |         with pyro.plate(\"d_plate\", 5):\n",
    "     2 1 1 1|1 1|             d = pyro.sample(\"d\", Bernoulli(0.4))\n",
    "     2 1 1 1|1 1|1            e_loc = locs[d.long()].unsqueeze(-1)\n",
    "            |   |7            e_scale = torch.arange(1., 8.)\n",
    "     2 1 1 1|5 4|7            e = pyro.sample(\"e\", Normal(e_loc, e_scale)\n",
    "            |   |                             .to_event(1))\n",
    "```\n",
    "To automatically examine this model with enumeration semantics, we can create an enumerated trace and then use [Trace.format_shapes()](http://docs.pyro.ai/en/dev/poutine.html#pyro.poutine.Trace.format_shapes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace Shapes:                \n",
      " Param Sites:                \n",
      "            p             6  \n",
      "         locs             2  \n",
      "Sample Sites:                \n",
      "       a dist             |  \n",
      "        value       6 1 1 |  \n",
      "     log_prob       6 1 1 |  \n",
      "       b dist       6 1 1 |  \n",
      "        value     2 1 1 1 |  \n",
      "     log_prob     2 6 1 1 |  \n",
      " c_plate dist             |  \n",
      "        value           4 |  \n",
      "     log_prob             |  \n",
      "       c dist           4 |  \n",
      "        value   2 1 1 1 1 |  \n",
      "     log_prob   2 1 1 1 4 |  \n",
      " d_plate dist             |  \n",
      "        value           5 |  \n",
      "     log_prob             |  \n",
      "       d dist         5 4 |  \n",
      "        value 2 1 1 1 1 1 |  \n",
      "     log_prob 2 1 1 1 5 4 |  \n",
      "       e dist 2 1 1 1 5 4 | 7\n",
      "        value 2 1 1 1 5 4 | 7\n",
      "     log_prob 2 1 1 1 5 4 |  \n"
     ]
    }
   ],
   "source": [
    "trace = poutine.trace(poutine.enum(model3, first_available_dim=-3)).get_trace()\n",
    "trace.compute_log_prob()  # optional, but allows printing of log_prob shapes\n",
    "print(trace.format_shapes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Writing parallelizable code \n",
    "\n",
    "\n",
    "It can be tricky to write Pyro models that correctly handle parallelized sample sites. Two tricks help: [broadcasting](http://pytorch.org/docs/master/notes/broadcasting.html) and [ellipsis slicing](http://python-reference.readthedocs.io/en/dev/docs/brackets/ellipsis.html). Let's look at a contrived model to see how these work in practice. 我们的目标是写一个模型 that works both with and without enumeration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "width, height = 8, 10\n",
    "sparse_pixels = torch.LongTensor([[3, 2], [3, 5], [3, 9], [7, 1]])\n",
    "enumerated = None  # set to either True or False below\n",
    "\n",
    "def fun(observe):\n",
    "    p_x = pyro.param(\"p_x\", torch.tensor(0.1), constraint=constraints.unit_interval)\n",
    "    p_y = pyro.param(\"p_y\", torch.tensor(0.1), constraint=constraints.unit_interval)\n",
    "    x_axis = pyro.plate('x_axis', width, dim=-2)\n",
    "    y_axis = pyro.plate('y_axis', height, dim=-1)\n",
    "\n",
    "    # Note that the shapes of these sites depend on whether Pyro is enumerating.\n",
    "    with x_axis:\n",
    "        x_active = pyro.sample(\"x_active\", Bernoulli(p_x))\n",
    "    with y_axis:\n",
    "        y_active = pyro.sample(\"y_active\", Bernoulli(p_y))\n",
    "    if enumerated:\n",
    "        assert x_active.shape  == (2, 1, 1)\n",
    "        assert y_active.shape  == (2, 1, 1, 1)\n",
    "    else:\n",
    "        assert x_active.shape  == (width, 1)\n",
    "        assert y_active.shape  == (height,)\n",
    "\n",
    "    # The first trick is to broadcast. This works with or without enumeration.\n",
    "    p = 0.1 + 0.5 * x_active * y_active\n",
    "    if enumerated:\n",
    "        assert p.shape == (2, 2, 1, 1)\n",
    "    else:\n",
    "        assert p.shape == (width, height)\n",
    "    dense_pixels = p.new_zeros(broadcast_shape(p.shape, (width, height)))\n",
    "\n",
    "    # The second trick is to index using ellipsis slicing.\n",
    "    # This allows Pyro to add arbitrary dimensions on the left.\n",
    "    for x, y in sparse_pixels:\n",
    "        dense_pixels[..., x, y] = 1\n",
    "    if enumerated:\n",
    "        assert dense_pixels.shape == (2, 2, width, height)\n",
    "    else:\n",
    "        assert dense_pixels.shape == (width, height)\n",
    "\n",
    "    with x_axis, y_axis:    \n",
    "        if observe:\n",
    "            pyro.sample(\"pixels\", Bernoulli(p), obs=dense_pixels)\n",
    "\n",
    "def model4():\n",
    "    fun(observe=True)\n",
    "\n",
    "def guide4():\n",
    "    fun(observe=False)\n",
    "\n",
    "# Test without enumeration.\n",
    "enumerated = False\n",
    "test_model(model4, guide4, Trace_ELBO())\n",
    "\n",
    "# Test with enumeration.\n",
    "enumerated = True\n",
    "test_model(model4, config_enumerate(guide4, \"parallel\"),\n",
    "           TraceEnum_ELBO(max_plate_nesting=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### `plate`内部自动广播\n",
    "\n",
    "所有的 model/guide 定义中，我们依赖于 [pyro.plate](http://docs.pyro.ai/en/dev/primitives.html#pyro.plate) 自动扩展样本维度，来满足 `pyro.sample` 语句中关于 batch shape 的约束。However this broadcasting is equivalent to hand-annotated `.expand()` statements.\n",
    "\n",
    "我们将使用 [previous section](#Writing-parallelizable-code) 中的 `model4` 对此进行演示。 请注意对先前代码的以下更改：\n",
    "\n",
    " - For the purpose of this example, we will only consider \"parallel\" enumeration, but broadcasting should work as expected without enumeration or with \"sequential\" enumeration.\n",
    " - We have separated out the sampling function which returns the tensors corresponding to the active pixels. Modularizing the model code into components is a common practice, and helps with maintainability of large models.\n",
    " - We would also like to use the `pyro.plate` construct to parallelize the ELBO estimator over [num_particles](http://docs.pyro.ai/en/dev/inference_algos.html#pyro.infer.elbo.ELBO). This is done by wrapping the contents of model/guide inside an outermost `pyro.plate` context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "num_particles = 100  # Number of samples for the ELBO estimator\n",
    "width = 8\n",
    "height = 10\n",
    "sparse_pixels = torch.LongTensor([[3, 2], [3, 5], [3, 9], [7, 1]])\n",
    "\n",
    "def sample_pixel_locations_no_broadcasting(p_x, p_y, x_axis, y_axis):\n",
    "    with x_axis:\n",
    "        x_active = pyro.sample(\"x_active\", Bernoulli(p_x).expand([num_particles, width, 1]))\n",
    "    with y_axis:\n",
    "        y_active = pyro.sample(\"y_active\", Bernoulli(p_y).expand([num_particles, 1, height]))\n",
    "    return x_active, y_active\n",
    "\n",
    "def sample_pixel_locations_full_broadcasting(p_x, p_y, x_axis, y_axis):\n",
    "    with x_axis:\n",
    "        x_active = pyro.sample(\"x_active\", Bernoulli(p_x))\n",
    "    with y_axis:\n",
    "        y_active = pyro.sample(\"y_active\", Bernoulli(p_y))\n",
    "    return x_active, y_active \n",
    "\n",
    "def sample_pixel_locations_partial_broadcasting(p_x, p_y, x_axis, y_axis):\n",
    "    with x_axis:\n",
    "        x_active = pyro.sample(\"x_active\", Bernoulli(p_x).expand([width, 1]))\n",
    "    with y_axis:\n",
    "        y_active = pyro.sample(\"y_active\", Bernoulli(p_y).expand([height]))\n",
    "    return x_active, y_active \n",
    "\n",
    "def fun(observe, sample_fn):\n",
    "    p_x = pyro.param(\"p_x\", torch.tensor(0.1), constraint=constraints.unit_interval)\n",
    "    p_y = pyro.param(\"p_y\", torch.tensor(0.1), constraint=constraints.unit_interval)\n",
    "    x_axis = pyro.plate('x_axis', width, dim=-2)\n",
    "    y_axis = pyro.plate('y_axis', height, dim=-1)\n",
    "\n",
    "    with pyro.plate(\"num_particles\", 100, dim=-3):\n",
    "        x_active, y_active = sample_fn(p_x, p_y, x_axis, y_axis)\n",
    "        # Indices corresponding to \"parallel\" enumeration are appended \n",
    "        # to the left of the \"num_particles\" plate dim.\n",
    "        assert x_active.shape  == (2, 1, 1, 1)\n",
    "        assert y_active.shape  == (2, 1, 1, 1, 1)\n",
    "        p = 0.1 + 0.5 * x_active * y_active\n",
    "        assert p.shape == (2, 2, 1, 1, 1)\n",
    "\n",
    "        dense_pixels = p.new_zeros(broadcast_shape(p.shape, (width, height)))\n",
    "        for x, y in sparse_pixels:\n",
    "            dense_pixels[..., x, y] = 1\n",
    "        assert dense_pixels.shape == (2, 2, 1, width, height)\n",
    "\n",
    "        with x_axis, y_axis:    \n",
    "            if observe:\n",
    "                pyro.sample(\"pixels\", Bernoulli(p), obs=dense_pixels)\n",
    "\n",
    "def test_model_with_sample_fn(sample_fn):\n",
    "    def model():\n",
    "        fun(observe=True, sample_fn=sample_fn)\n",
    "\n",
    "    @config_enumerate\n",
    "    def guide():\n",
    "        fun(observe=False, sample_fn=sample_fn)\n",
    "\n",
    "    test_model(model, guide, TraceEnum_ELBO(max_plate_nesting=3))\n",
    "\n",
    "test_model_with_sample_fn(sample_pixel_locations_no_broadcasting)\n",
    "test_model_with_sample_fn(sample_pixel_locations_full_broadcasting)\n",
    "test_model_with_sample_fn(sample_pixel_locations_partial_broadcasting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "In the first sampling function, we had to do some manual book-keeping and expand the `Bernoulli` distribution's batch shape to account for the conditionally independent dimensions added by the `pyro.plate` contexts. In particular, note how `sample_pixel_locations` needs knowledge of `num_particles`, `width` and `height` and is accessing these variables from the global scope, which is not ideal. \n",
    "\n",
    " - The second argument to `pyro.plate`, i.e. the optional `size` argument needs to be provided for implicit broadasting, so that it can infer the batch shape requirement for each of the sample sites. \n",
    " - The existing `batch_shape` of the sample site must be broadcastable with the size of the `pyro.plate` contexts. In our particular example, `Bernoulli(p_x)` has an empty batch shape which is universally broadcastable.\n",
    "\n",
    "Note how simple it is to achieve parallelization via tensorized operations using `pyro.plate`! `pyro.plate` also helps in code modularization because model components can be written agnostic of the `plate` contexts in which they may subsequently get embedded in."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "200.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
